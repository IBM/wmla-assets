{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "\n",
    "#hostname='haswell01.eng.platformlab.ibm.com'\n",
    "hostname='wml1x184.eng.platformlab.ibm.com'\n",
    "commonHeaders={'accept': 'application/json'}\n",
    "req = requests.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hpo task: Admin-hpo-9551207096118021, State: FINISHED\n"
     ]
    }
   ],
   "source": [
    "getTuneStatusUrl = 'https://{}:49443/platform/rest/deeplearning/v1/hypersearch'.format(hostname)\n",
    "r = req.get(getTuneStatusUrl, headers=commonHeaders, verify=False, auth=('Admin', 'Admin'))\n",
    "if not r.ok:\n",
    "    print('check hpo task status failed: code=%s, %s'%(res.status_code, res.content))\n",
    "else:\n",
    "    if len(r.json()) == 0:\n",
    "        print('There is no hpo task been created')\n",
    "    for item in r.json():\n",
    "        print('Hpo task: %s, State: %s'%(item['hpoName'], item['state']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/sm/_vlrb66910jg32402zz_j6mw0000gp/T/tmpkunixa3w.modelDir.tar\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import tempfile\n",
    "import os\n",
    "def make_tarfile(output_filename, source_dir):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        tar.add(source_dir, arcname=os.path.basename(source_dir))\n",
    "MODEL_DIR_SUFFIX = \".modelDir.tar\"\n",
    "tempFile = tempfile.mktemp(MODEL_DIR_SUFFIX)\n",
    "#make_tarfile(tempFile, '/Users/donglin/Documents/office/work/DLI/design/HPO/kyw/tf-model')\n",
    "make_tarfile(tempFile, '/Users/jysjiang/Documents/WMLA/RFE/Wells-Fargo-WML-A/tf-model/')\n",
    "print(tempFile)\n",
    "files = {'file': open(tempFile, 'rb')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data =  {\n",
    "        'modelSpec': # Define the model training related parameters\n",
    "        {\n",
    "            # Spark instance group which will be used to run the HPO sub-trainings. The Spark instance group selected\n",
    "            # here should match the sub-training args, for example, if the sub-training args try to run a EDT job,\n",
    "            # then we should put a Spark instance group with capability to run EDT job here.\n",
    "            'sigName': 'sig0',\n",
    "            \n",
    "            # These are the arguments we'll pass to the execution engine; they follow the same conventions\n",
    "            # of the dlicmd.py command line launcher\n",
    "            #\n",
    "            # See:\n",
    "            #   https://www.ibm.com/support/knowledgecenter/en/SSFHA8_1.2.1/cm/dlicmd.html\n",
    "            # In this example, args after --model-dir are all the required parameter for the original model itself.\n",
    "            'args': '--exec-start tensorflow --python-version 2.7 --cs-datastore-meta type=fs \\\n",
    "                     --gpuPerWorker 1 --model-main convolutional_network.py \\\n",
    "                     --trainImagesFile /dlfs/autotest_testgrid/dataset/wmla_data/tf-mnist/train-images-idx3-ubyte.gz \\\n",
    "                     --trainLabelsFile /dlfs/autotest_testgrid/dataset/wmla_data/tf-mnist/train-labels-idx1-ubyte.gz \\\n",
    "                     --testImagesFile /dlfs/autotest_testgrid/dataset/wmla_data/tf-mnist/t10k-images-idx3-ubyte.gz \\\n",
    "                     --testLabelsFile /dlfs/autotest_testgrid/dataset/wmla_data/tf-mnist/t10k-labels-idx1-ubyte.gz'\n",
    "        },\n",
    "        'algoDef': # Define the parameters for search algorithms\n",
    "        {\n",
    "            # Name of the search algorithm, one of Random, Bayesian, Tpe, Hyperband\n",
    "            'algorithm': 'ExperimentGridSearch', \n",
    "            # Max running time of the hpo task in minutes, -1 means unlimited\n",
    "            'maxRunTime': -1,  \n",
    "            # Max number of training job to submitted for hpo task, -1 means unlimitedâ€™,\n",
    "            'maxJobNum': 2,            \n",
    "            # Max number of training job to run in parallel, default 1. It depends on both the\n",
    "            # avaiable resource and if the search algorithm support to run in parallel, current only Random\n",
    "            # fully supports to run in parallel, Hyperband and Tpe supports to to in parellel in some phase,\n",
    "            # Bayesian runs in sequence now.\n",
    "            'maxParalleJobNum': 1, \n",
    "            # Name of the target metric that we are trying to optimize when searching hyper-parameters.\n",
    "            # It is the same metric name that the model update part 2 trying to dump.\n",
    "            'objectiveMetric' : 'loss',\n",
    "            # Strategy as how to optimize the hyper-parameters, minimize means to find better hyper-parameters to\n",
    "            # make the above objectiveMetric as small as possible, maximize means the opposite.\n",
    "            'objective' : 'minimize',\n",
    "            # eta value to control the hyper-band search process\n",
    "            'hyperbandEta': 3.0,\n",
    "            #Additional parameters for the specified search algorithm and hyper-band get following too.\n",
    "            'algoParams' : \n",
    "                [\n",
    "                    {\n",
    "                        # Name of the the maximum amount of resource that can be allocated to a single configuration\n",
    "                        'name':'ResourceName', \n",
    "                        'value': 'epochs'\n",
    "                    },\n",
    "                    {\n",
    "                        # Value of the the maximum amount of resource that can be allocated to a single configuration\n",
    "                        'name':'ResourceValue',\n",
    "                        'value':'10'\n",
    "                    }\n",
    "                    # This resource parameter will change during hyperband searching phase and its value will be put\n",
    "                    # into the config.json for each sub-training too, here with the 'epoch' as key and value in the\n",
    "                    # range 1-10.\n",
    "                ]\n",
    "        },\n",
    "    \n",
    "        # Define the hyper-paremeters to search and the corresponding search space.            \n",
    "        'experiments':\n",
    "        [\n",
    "             {\n",
    "                 'id':1,\n",
    "                 'hyperParams': [\n",
    "                     {\n",
    "                         'name': 'learning_rate',\n",
    "                         'dataType': 'DOUBLE',\n",
    "                         'fixedVal': '0.1'\n",
    "                     },\n",
    "                     {\n",
    "                         'name': 'optimizer',\n",
    "                         'dataType': 'STRING',\n",
    "                         'fixedVal': 'Adam'\n",
    "                     },\n",
    "                     {\n",
    "                         'name': 'opt_decay',\n",
    "                         'dataType': 'DOUBLE',\n",
    "                         'fixedVal': '0.4882855458519536'\n",
    "                     },\n",
    "                     {\n",
    "                         'name': 'beta1',\n",
    "                         'dataType': 'DOUBLE',\n",
    "                         'fixedVal': '0.7'\n",
    "                     },\n",
    "                     {\n",
    "                         'name': 'beta2',\n",
    "                         'dataType': 'DOUBLE',\n",
    "                         'fixedVal': '0.8982816529517174'\n",
    "                     }\n",
    "                 ]\n",
    "             },\n",
    "            {\n",
    "                 'id':2,\n",
    "                 'hyperParams': [\n",
    "                     {\n",
    "                         'name': 'learning_rate',\n",
    "                         'dataType': 'DOUBLE',\n",
    "                         'fixedVal': '0.2'\n",
    "                     },\n",
    "                     {\n",
    "                         'name': 'optimizer',\n",
    "                         'dataType': 'STRING',\n",
    "                         'fixedVal': 'Adam'\n",
    "                     }\n",
    "                 ]\n",
    "             }\n",
    "        ]\n",
    "       }\n",
    "mydata={'data':json.dumps(data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit tune job succeed with hponame: Admin-hpo-9559865415941081\n"
     ]
    }
   ],
   "source": [
    "startTuneUrl='https://{}:49443/platform/rest/deeplearning/v1/hypersearch'.format(hostname)\n",
    "create = req.post(startTuneUrl, headers=commonHeaders, data=mydata, files=files, verify=False, auth=('Admin', 'Admin'))\n",
    "if not create.ok:\n",
    "   print('submit tune job failed: code=%s, %s'%(create.status_code, create.content))\n",
    "else:\n",
    "   print('submit tune job succeed with hponame: %s'%create.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hpo task Admin-hpo-9559865415941081 state RUNNING progress 0/2\n",
      "Hpo task Admin-hpo-9559865415941081 state RUNNING progress 0/2\n",
      "Hpo task Admin-hpo-9559865415941081 state RUNNING progress 0/2\n",
      "Hpo task Admin-hpo-9559865415941081 state RUNNING progress 0/2\n",
      "Hpo task Admin-hpo-9559865415941081 state RUNNING progress 1/2\n",
      "Hpo task Admin-hpo-9559865415941081 state RUNNING progress 1/2\n",
      "Hpo task Admin-hpo-9559865415941081 state RUNNING progress 1/2\n",
      "Hpo task Admin-hpo-9559865415941081 state RUNNING progress 1/2\n",
      "Hpo task Admin-hpo-9559865415941081 completes with state FINISHED\n",
      "{\n",
      "    \"best\": {\n",
      "        \"appId\": \"Admin-9559934187167434-1923606690\",\n",
      "        \"driverId\": \"driver-20191226032303-0292-75c6a513-1cc7-4984-965b-5b87eccd15c4\",\n",
      "        \"endTime\": \"2019-12-26 03:24:10\",\n",
      "        \"hyperParams\": [\n",
      "            {\n",
      "                \"dataType\": \"double\",\n",
      "                \"fixedVal\": \"0.2\",\n",
      "                \"name\": \"learning_rate\",\n",
      "                \"type\": \"fix\",\n",
      "                \"userDefined\": false\n",
      "            },\n",
      "            {\n",
      "                \"dataType\": \"string\",\n",
      "                \"fixedVal\": \"Adam\",\n",
      "                \"name\": \"optimizer\",\n",
      "                \"type\": \"fix\",\n",
      "                \"userDefined\": false\n",
      "            }\n",
      "        ],\n",
      "        \"id\": 1,\n",
      "        \"maxiteration\": 0,\n",
      "        \"metricVal\": 1.7660757303237915,\n",
      "        \"startTime\": \"2019-12-26 03:23:03\",\n",
      "        \"state\": \"FINISHED\"\n",
      "    },\n",
      "    \"complete\": 2,\n",
      "    \"createtime\": \"2019-12-26 03:21:54\",\n",
      "    \"creator\": \"Admin\",\n",
      "    \"duration\": \"00:02:16\",\n",
      "    \"experiments\": [\n",
      "        {\n",
      "            \"appId\": \"Admin-9559866397689955-959500026\",\n",
      "            \"driverId\": \"driver-20191226032155-0291-4ce0e3eb-c8bb-4ffd-b068-4e4f1bebaeb0\",\n",
      "            \"endTime\": \"2019-12-26 03:23:02\",\n",
      "            \"hyperParams\": [\n",
      "                {\n",
      "                    \"dataType\": \"double\",\n",
      "                    \"fixedVal\": \"0.7\",\n",
      "                    \"name\": \"beta1\",\n",
      "                    \"type\": \"fix\",\n",
      "                    \"userDefined\": false\n",
      "                },\n",
      "                {\n",
      "                    \"dataType\": \"double\",\n",
      "                    \"fixedVal\": \"0.8982816529517174\",\n",
      "                    \"name\": \"beta2\",\n",
      "                    \"type\": \"fix\",\n",
      "                    \"userDefined\": false\n",
      "                },\n",
      "                {\n",
      "                    \"dataType\": \"double\",\n",
      "                    \"fixedVal\": \"0.1\",\n",
      "                    \"name\": \"learning_rate\",\n",
      "                    \"type\": \"fix\",\n",
      "                    \"userDefined\": false\n",
      "                },\n",
      "                {\n",
      "                    \"dataType\": \"double\",\n",
      "                    \"fixedVal\": \"0.4882855458519536\",\n",
      "                    \"name\": \"opt_decay\",\n",
      "                    \"type\": \"fix\",\n",
      "                    \"userDefined\": false\n",
      "                },\n",
      "                {\n",
      "                    \"dataType\": \"string\",\n",
      "                    \"fixedVal\": \"Adam\",\n",
      "                    \"name\": \"optimizer\",\n",
      "                    \"type\": \"fix\",\n",
      "                    \"userDefined\": false\n",
      "                }\n",
      "            ],\n",
      "            \"id\": 0,\n",
      "            \"maxiteration\": 0,\n",
      "            \"metricVal\": 2.302612066268921,\n",
      "            \"startTime\": \"2019-12-26 03:21:55\",\n",
      "            \"state\": \"FINISHED\"\n",
      "        },\n",
      "        {\n",
      "            \"appId\": \"Admin-9559934187167434-1923606690\",\n",
      "            \"driverId\": \"driver-20191226032303-0292-75c6a513-1cc7-4984-965b-5b87eccd15c4\",\n",
      "            \"endTime\": \"2019-12-26 03:24:10\",\n",
      "            \"hyperParams\": [\n",
      "                {\n",
      "                    \"dataType\": \"double\",\n",
      "                    \"fixedVal\": \"0.2\",\n",
      "                    \"name\": \"learning_rate\",\n",
      "                    \"type\": \"fix\",\n",
      "                    \"userDefined\": false\n",
      "                },\n",
      "                {\n",
      "                    \"dataType\": \"string\",\n",
      "                    \"fixedVal\": \"Adam\",\n",
      "                    \"name\": \"optimizer\",\n",
      "                    \"type\": \"fix\",\n",
      "                    \"userDefined\": false\n",
      "                }\n",
      "            ],\n",
      "            \"id\": 1,\n",
      "            \"maxiteration\": 0,\n",
      "            \"metricVal\": 1.7660757303237915,\n",
      "            \"startTime\": \"2019-12-26 03:23:03\",\n",
      "            \"state\": \"FINISHED\"\n",
      "        }\n",
      "    ],\n",
      "    \"failed\": 0,\n",
      "    \"hpoName\": \"Admin-hpo-9559865415941081\",\n",
      "    \"progress\": \"2/2\",\n",
      "    \"running\": 0,\n",
      "    \"state\": \"FINISHED\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#Here we just use the hpo name returned of the previous POST call\n",
    "hpoName = create.json()\n",
    "\n",
    "getHpoUrl = 'https://{}:49443/platform/rest/deeplearning/v1/hypersearch/{}'.format(hostname, hpoName)\n",
    "res = req.get(getHpoUrl, headers=commonHeaders, verify=False, auth=('Admin', 'Admin'))\n",
    "if not res.ok:\n",
    "    print('get hpo task failed: code=%s, %s'%(res.status_code, res.content))\n",
    "else:\n",
    "    json_out=res.json()\n",
    "    \n",
    "    while json_out['state'] in ['SUBMITTED','RUNNING']:\n",
    "        print('Hpo task {} state {} progress {}'.format(hpoName, json_out['state'], json_out['progress']))\n",
    "        res = req.get(getHpoUrl, headers=commonHeaders, verify=False, auth=('Admin', 'Admin'))\n",
    "        json_out=res.json()\n",
    "        time.sleep(20)\n",
    "    \n",
    "    print('Hpo task %s completes with state %s'%(hpoName, json_out['state']))\n",
    "    #print('Best:%s'%json.dumps(json_out.get('best'), sort_keys=True, indent=4))\n",
    "    print(json.dumps(res.json(), sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hpo task: Admin-hpo-9551207096118021, State: FINISHED\n",
      "Hpo task: Admin-hpo-9559865415941081, State: FINISHED\n"
     ]
    }
   ],
   "source": [
    "getTuneStatusUrl = 'https://{}:49443/platform/rest/deeplearning/v1/hypersearch'.format(hostname)\n",
    "res = req.get(getTuneStatusUrl, headers=commonHeaders, verify=False, auth=('Admin', 'Admin'))\n",
    "if not res.ok:\n",
    "    print('check tune job status failed: code=%s, %s'%(res.status_code, res.content))\n",
    "else:\n",
    "    #print(json.dumps(r.json(), sort_keys=True, indent=4))\n",
    "    if len(res.json()) == 0:\n",
    "        print('There is no hpo task been created')\n",
    "    for item in res.json():\n",
    "        #print(item['hpoName'])\n",
    "        print('Hpo task: %s, State: %s'%(item['hpoName'], item['state']))\n",
    "        #print('Hpo tasks detail:%s'%json.dumps(item, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete hpo task succeeds\n"
     ]
    }
   ],
   "source": [
    "deleteHpoUrl = 'https://{}:49443/platform/rest/deeplearning/v1/hypersearch'.format(hostname)\n",
    "r=req.delete(deleteHpoUrl,headers=commonHeaders, verify=False, auth=('Admin','Admin'))\n",
    "if not r.ok:\n",
    "    print('delete hpo task failed: code=%s, %s'%(r.status_code, r.content))\n",
    "else:\n",
    "    print('delete hpo task succeeds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
