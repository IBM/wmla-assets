{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Common Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "DLPD_REST_BASE_URL_1: http://bjosm02.dli.com:55557\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "\n",
    "hostname='bjosm02.dli.com'\n",
    "dlpd_port='55557'\n",
    "dlpd_rest_base_url = 'http://{}:{}'.format(hostname, dlpd_port) # http or https\n",
    "print('DLPD_REST_BASE_URL_1: {}'.format(dlpd_rest_base_url))\n",
    "\n",
    "commonHeaders={'accept': 'application/json'}\n",
    "req = requests.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Health Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is any existing hpo algorithms and also verify the platform health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rest API: **GET platform/rest/deeplearning/v1/hypersearch/algorithm**\n",
    "- Description: Get all the hpo algorithm that the login user can access.\n",
    "- OUTPUT: A list of hpo algorithms and each one with the same format which can be found in the api doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hpo alogrithm: Random, Type: BUILD_IN\n",
      "Hpo alogrithm: TPE, Type: BUILD_IN\n",
      "Hpo alogrithm: Bayesian, Type: BUILD_IN\n",
      "Hpo alogrithm: Hyperband, Type: BUILD_IN\n",
      "Hpo alogrithm: ExperimentGridSearch, Type: BUILD_IN\n",
      "Hpo alogrithm: test-random-remote, Type: USER_PLUGIN\n",
      "Hpo alogrithm: test-random-info, Type: USER_PLUGIN\n"
     ]
    }
   ],
   "source": [
    "getAllAlogUrl = '{}/platform/rest/deeplearning/v1/hypersearch/algorithm'.format(dlpd_rest_base_url)\n",
    "r = req.get(getAllAlogUrl, headers=commonHeaders, verify=False, auth=('Admin', 'Admin'))\n",
    "if not r.ok:\n",
    "    print('check hpo algorithm failed: code=%s, %s'%(r.status_code, r.text))\n",
    "else:\n",
    "    if len(r.json()) == 0:\n",
    "        print('There is no hpo algorithm been created')\n",
    "    for item in r.json():\n",
    "        print('Hpo alogrithm: %s, Type: %s'%(item['name'], item['type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install a HPO user plugin algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 methods are supported for the plugin algorithm installation:\n",
    "- Local install: Use this way if the plugin algorithm scripts are allocated in the dlpd server, or in a shared folder that dlpd service can access.\n",
    "- Upload install: Use this way if you want to upload the plugin algorithm scrips from a client host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local install plugin algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REST API: POST **/platform/rest/deeplearning/v1/hypersearch/algorithm/install**\n",
    "\n",
    "Description: Install a new hpo plugin algorithm.  \n",
    "Content-type: Multi-Form\n",
    "\n",
    "Multi-Form Data:  \n",
    "- form-filed: {‘data’: ‘String json format of input parameters to install a hpo plugin algorithm’}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construct the POST request body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_algorithm_name = 'test-random-debug'\n",
    "data = {\n",
    "    # required, string, name/id for the plugin algorithm, should be unique.,\n",
    "    \"name\": create_algorithm_name,\n",
    "    \n",
    "    # required for local install, string, the path for plugin algorithm scripts on server.\n",
    "    \"path\": \"/opt/zhuangxy/hporfe/debug_work_dir/random_plugin_example/\", \n",
    "    \n",
    "    # optional, string, the CONDA_HOME to run the algorithm scripts.\n",
    "    # if not specified, it will use the DLI_CONDA_HOME.\n",
    "    \"condaHome\": \"/opt/anaconda3\", \n",
    "    \n",
    "    # optional, string, the conda environment to run the algorithm scripts.\n",
    "    # if not specified, it will use the DLI default conda environment (dlipy3).\n",
    "    \"condaEnv\": \"hpo\", \n",
    "    \n",
    "    # optional, boolean, whether to deploy algorithm execution remotely, the default value is false.\n",
    "    \"remoteExec\": False, \n",
    "    \n",
    "    # optional, string, the log level of the plugin algorithm, the default value is INFO.\n",
    "    \"logLevel\": \"DEBUG\"\n",
    "    }\n",
    "mydata={'data':json.dumps(data)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Submit the installtion request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "install plugin algorithm success: \n",
      "{\n",
      "    \"name\": \"test-random-debug\",\n",
      "    \"path\": \"/opt/zhuangxy/hporfe/share_fs/tools/tune/plugins/test-random-debug\",\n",
      "    \"condaHome\": \"/opt/anaconda3\",\n",
      "    \"condaEnv\": \"hpo\",\n",
      "    \"creator\": \"Admin\",\n",
      "    \"createtime\": \"2020-01-09 17:31:32\",\n",
      "    \"type\": \"USER_PLUGIN\",\n",
      "    \"remoteExec\": false,\n",
      "    \"logLevel\": \"DEBUG\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "installPluginAlgoURL = '{}/platform/rest/deeplearning/v1/hypersearch/algorithm/install'.format(dlpd_rest_base_url)\n",
    "install = req.post(installPluginAlgoURL, \n",
    "                   headers=commonHeaders, \n",
    "                   data=mydata, \n",
    "                   files=mydata, \n",
    "                   verify=False, \n",
    "                   auth=('Admin', 'Admin'))\n",
    "if not install.ok:\n",
    "    print('install plugin algorithm failed: code=%s, %s' % (install.status_code, install.text))\n",
    "else:\n",
    "    # query the new created plugin algorithm\n",
    "    getAlogUrl = '{}/platform/rest/deeplearning/v1/hypersearch/algorithm/{}'.format(\n",
    "        dlpd_rest_base_url, create_algorithm_name)\n",
    "    algoDesc = req.get(getAlogUrl, headers=commonHeaders, verify=False, auth=('Admin', 'Admin'))\n",
    "    print('install plugin algorithm success: \\n%s' % json.dumps(algoDesc.json(), indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload install plugin algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REST API: POST **/platform/rest/deeplearning/v1/hypersearch/algorithm/install**\n",
    "\n",
    "Description: Install a new hpo plugin algorithm.  \n",
    "Content-type: Multi-Form\n",
    "\n",
    "Multi-Form Data:\n",
    "- files: plugin algorithm scripts tar package, ending with .tar\n",
    "- form-filed: {'data': 'String json format of input parameters to install a hpo plugin algorithm'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare the upload tar file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source dir: /opt/zhuangxy/hporfe/debug_work_dir/random_plugin_example/\n",
      "tar added: /opt/zhuangxy/hporfe/debug_work_dir/random_plugin_example/optimizer.py\n",
      "plugin temp tar file: /tmp/tmp0j5_leuf.tar\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import tempfile\n",
    "import os\n",
    "def make_tarfile(output_filename, source_dir):\n",
    "    print('source dir: ' + source_dir)\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        for root, _, files in os.walk(source_dir):  \n",
    "            for file in files:  \n",
    "                fullpath=os.path.join(root, file) \n",
    "                print('tar added: ' + fullpath)\n",
    "                tar.add(fullpath, arcname=file)\n",
    "        \n",
    "MODEL_DIR_SUFFIX = \".tar\"\n",
    "tempFile = tempfile.mktemp(MODEL_DIR_SUFFIX)\n",
    "make_tarfile(tempFile, '/opt/zhuangxy/hporfe/debug_work_dir/random_plugin_example/')\n",
    "print('plugin temp tar file: {}'.format(tempFile))\n",
    "files = {'file': open(tempFile, 'rb')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construct the POST request body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_algorithm_name = 'test-random-uploadc'\n",
    "data = {\n",
    "    # required, string, name/id for the plugin algorithm, should be unique.,\n",
    "    \"name\": create_algorithm_name,\n",
    "    \n",
    "    # optional, string, the CONDA_HOME to run the algorithm scripts.\n",
    "    # if not specified, it will use the DLI_CONDA_HOME.\n",
    "    \"condaHome\": \"/opt/anaconda3\", \n",
    "    \n",
    "    # optional, string, the conda environment to run the algorithm scripts.\n",
    "    # if not specified, it will use the DLI default conda environment (dlipy3).\n",
    "    \"condaEnv\": \"hpo\", \n",
    "    \n",
    "    # optional, boolean, whether to deploy algorithm execution remotely, the default value is false.\n",
    "    \"remoteExec\": False, \n",
    "    \n",
    "    # optional, string, the log level of the plugin algorithm, the default value is INFO.\n",
    "    \"logLevel\": \"DEBUG\"\n",
    "    }\n",
    "mydata={'data':json.dumps(data)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Submit the installtion request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "install plugin algorithm success: \n",
      "{\n",
      "    \"name\": \"test-random-uploadc\",\n",
      "    \"path\": \"/opt/zhuangxy/hporfe/share_fs/tools/tune/plugins/test-random-uploadc\",\n",
      "    \"condaHome\": \"/opt/anaconda3\",\n",
      "    \"condaEnv\": \"hpo\",\n",
      "    \"creator\": \"Admin\",\n",
      "    \"createtime\": \"2020-01-08 17:11:29\",\n",
      "    \"type\": \"USER_PLUGIN\",\n",
      "    \"remoteExec\": false,\n",
      "    \"logLevel\": \"DEBUG\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "installPluginAlgoURL = '{}/platform/rest/deeplearning/v1/hypersearch/algorithm/install'.format(dlpd_rest_base_url)\n",
    "install = req.post(installPluginAlgoURL, \n",
    "                   headers=commonHeaders, \n",
    "                   data=mydata, \n",
    "                   files=files, \n",
    "                   verify=False, \n",
    "                   auth=('Admin', 'Admin'))\n",
    "if not install.ok:\n",
    "    print('install plugin algorithm failed: code=%s, %s' % (install.status_code, install.text))\n",
    "else:\n",
    "    # query the new created plugin algorithm\n",
    "    getAlogUrl = '{}/platform/rest/deeplearning/v1/hypersearch/algorithm/{}'.format(\n",
    "        dlpd_rest_base_url, create_algorithm_name)\n",
    "    algoDesc = req.get(getAlogUrl, headers=commonHeaders, verify=False, auth=('Admin', 'Admin'))\n",
    "    print('install plugin algorithm success: \\n%s' % json.dumps(algoDesc.json(), indent=4))\n",
    "    os.remove(tempFile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a HPO user plugin algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REST API: **DELETE /platform/rest/deeplearning/v1/hypersearch**\n",
    "\n",
    "Description: delete a hpo plugin algorithm by algorithm name.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete plugin algorithm test-random-debug success\n"
     ]
    }
   ],
   "source": [
    "delete_algorithm_name = 'test-random-debug'\n",
    "deleteAlogUrl = '{}/platform/rest/deeplearning/v1/hypersearch/algorithm/{}'.format(\n",
    "        dlpd_rest_base_url, delete_algorithm_name)\n",
    "delete = req.delete(deleteAlogUrl, \n",
    "                   headers=commonHeaders, \n",
    "                   verify=False, \n",
    "                   auth=('Admin', 'Admin'))\n",
    "if not delete.ok:\n",
    "    print('delete plugin algorithm failed: code=%s, %s' % (delete.status_code, delete.text))\n",
    "else:\n",
    "    print('delete plugin algorithm {} success'.format(delete_algorithm_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query a HPO user plugin algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query a HPO user plugin algorithm by name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rest API: **GET platform/rest/deeplearning/v1/hypersearch/algorithm/{algoName}**\n",
    "- Description: Get a hpo algorithm by name.\n",
    "- OUTPUT: A hpo algorithm with the same format which can be found in the api doc.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Full Response of a hpo algorithm description:**\n",
    "```\n",
    "HpoAlgorithmDesc {\n",
    "    name (string): 'The hpo algorithm name.' ,\n",
    "    path (string, optional): 'The hpo algorithm installation path. (only for plugin algorithm).' ,\n",
    "    condaHome (string, optional): 'The CONDA_HOME used to run hpo algorithm (only for plugin algorithm).' ,\n",
    "    condaEnv (string, optional): 'The conda environment used to run hpo algorithm (only for plugin algorithm).' ,\n",
    "    createtime (string, optional): 'The creation time of the hpo algorithm (only for plugin algorithm).' ,\n",
    "    type (string, optional): 'The type of the hpo algorithm.' ,\n",
    "    remoteExec (boolean, optional): 'The plugin algorithm execution mode is remoted or not (only for plugin algorithm).' ,\n",
    "    logLevel (string, optional): 'The log level for the plugin algorithm (only for plugin algorithm)'.\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query plugin algorithm success: {\n",
      "    \"name\": \"test-random-remote\",\n",
      "    \"path\": \"/opt/zhuangxy/hporfe/share_fs/tools/tune/plugins/test-random-remote\",\n",
      "    \"condaHome\": \"/opt/anaconda3\",\n",
      "    \"condaEnv\": \"hpo\",\n",
      "    \"creator\": \"Admin\",\n",
      "    \"createtime\": \"2019-12-27 15:47:20\",\n",
      "    \"type\": \"USER_PLUGIN\",\n",
      "    \"remoteExec\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query_algorithm_name = 'test-random-remote'\n",
    "getAlogUrl = '{}/platform/rest/deeplearning/v1/hypersearch/algorithm/{}'.format(\n",
    "        dlpd_rest_base_url, query_algorithm_name)\n",
    "query = req.get(getAlogUrl, \n",
    "                   headers=commonHeaders, \n",
    "                   verify=False, \n",
    "                   auth=('Admin', 'Admin'))\n",
    "if not query.ok:\n",
    "    print('query plugin algorithm failed: code=%s, %s' % (query.status_code, query.text))\n",
    "else:\n",
    "    if not query.json():\n",
    "        print('plugin algorithm {} does not exist'.format(query_algorithm_name))\n",
    "    else:\n",
    "        print('query plugin algorithm success: {}'.format(json.dumps(query.json(), indent=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query a HPO user plugin algorithm by type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rest API: **GET platform/rest/deeplearning/v1/hypersearch/algorithm?type={algo_type}**\n",
    "- Description: Get hpo algorithms by type. If the type is not specified, all hpo algorithms will be returned.\n",
    "- OUTPUT: A list hpo algorithms and each one with the same format which can be found in the api doc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query plugin algorithm success: [\n",
      "    {\n",
      "        \"name\": \"Random\",\n",
      "        \"type\": \"BUILD_IN\",\n",
      "        \"remoteExec\": false\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"TPE\",\n",
      "        \"type\": \"BUILD_IN\",\n",
      "        \"remoteExec\": false\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Bayesian\",\n",
      "        \"type\": \"BUILD_IN\",\n",
      "        \"remoteExec\": false\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Hyperband\",\n",
      "        \"type\": \"BUILD_IN\",\n",
      "        \"remoteExec\": false\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"ExperimentGridSearch\",\n",
      "        \"type\": \"BUILD_IN\",\n",
      "        \"remoteExec\": false\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "algo_type = 'BUILD_IN'\n",
    "# algo_type = 'USER_PLUGIN'\n",
    "getAlogUrl = '{}/platform/rest/deeplearning/v1/hypersearch/algorithm?type={}'.format(\n",
    "        dlpd_rest_base_url, algo_type)\n",
    "query = req.get(getAlogUrl, \n",
    "                   headers=commonHeaders, \n",
    "                   verify=False, \n",
    "                   auth=('Admin', 'Admin'))\n",
    "if not query.ok:\n",
    "    print('query plugin algorithm failed: code=%s, %s' % (query.status_code, query.text))\n",
    "else:\n",
    "    if not query.json():\n",
    "        print('plugin algorithm {} does not exist'.format(query_algorithm_name))\n",
    "    else:\n",
    "        print('query plugin algorithm success: {}'.format(json.dumps(query.json(), indent=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch a HPO task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Model file update to Run HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Model changes required from 2 perspective:\n",
    "- Inject hyper-parameters for the sub-training during search\n",
    "- Retrieve sub-training result metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Model update part 1 - Inject hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The hyper-parameters will be supplied in a file called **config.json** with JSON format,located in the current working directory and can be read direcly as the following example snippet.\n",
    "\n",
    "<pre>\n",
    "hyper_params = json.loads(open(\"<b>config.json</b>\").read())\n",
    "learning_rate = float(hyper_params.get(\"<b>learning_rate</b>\", \"0.01\"))\n",
    "</pre>\n",
    "\n",
    "After this, you can use these hyper-parameters during the model trainings. The **hyper-parameter name** and **value** type is defined through the search space part in body of REST call when launching a new hpo task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Model update part 2 - Retrieve sub-training result metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "At the end of your training run, your code will need to create a file called **val_dict_list.json** with test metrics generated during training. These metrics will be used by the search algorithm to propose new sets of hyper-parameters. Please note that **val_dict_list.json** should be created under the result directory which can be retrieved through the environment variable **RESULT_DIR**.\n",
    "\n",
    "<pre>\n",
    "with open('{}/val_dict_list.json'.format(os.environ['<b>RESULT_DIR</b>']), 'w') as f:\n",
    "    json.dump(test_metrics, f)\n",
    "</pre>\n",
    "\n",
    "The content of **val_dict_list.json** will be some thing as below, **step** is some thing optional meaning the training iteration or epochs, one of **loss** and **accuracy** can be the name of target metric to optimize, at least one metric need to be included here. The specific name of metric used to optimize (minimize or maximize) is defined in the body of REST call when launching a new hpo task. \n",
    "\n",
    "```\n",
    "[\n",
    "{‘step’: 1, ‘loss’:0.2487, ‘accuracy’: 0.4523},\n",
    "{‘step’: 2, ‘loss’:0.1487, ‘accuracy’: 0.5523},\n",
    "{‘step’: 3, ‘loss’:0.1087, ‘accuracy’: 0.6523},\n",
    "…\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Launch HPO task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REST API: **POST /platform/rest/deeplearning/v1/hypersearch**\n",
    "- Description: Start a new HPO task\n",
    "- Content-type: Multi-Form\n",
    "- Multi-Form Data:\n",
    "  - files: Model files tar package, ending with `.modelDir.tar`\n",
    "  - form-filed: {‘data’: ‘String format of input parameters to start hpo task, let’s call it as **hpo_input** and show its specification later’}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Package model files for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package the updated model files into a tar file ending with `.modelDir.tar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar model files: /tmp/tmph1fcrdqy.modelDir.tar\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import tempfile\n",
    "import os\n",
    "def make_tarfile(output_filename, source_dir):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        tar.add(source_dir, arcname=os.path.basename(source_dir))\n",
    "MODEL_DIR_SUFFIX = \".modelDir.tar\"\n",
    "\n",
    "tempFile = tempfile.mktemp(MODEL_DIR_SUFFIX)\n",
    "make_tarfile(tempFile, '/opt/zhuangxy/hporfe/tf-model')\n",
    "files = {'file': open(tempFile, 'rb')}\n",
    "print(\"tar model files: \" + tempFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construct POST request data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hpo_input** will be a Python dict or json format as below, convert to string when calling REST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data =  {\n",
    "        'modelSpec': # Define the model training related parameters\n",
    "        {\n",
    "            # Spark instance group which will be used to run the HPO sub-trainings. The Spark instance group selected\n",
    "            # here should match the sub-training args, for example, if the sub-training args try to run a EDT job,\n",
    "            # then we should put a Spark instance group with capability to run EDT job here.\n",
    "            'sigName': 'sig233',\n",
    "            \n",
    "            # These are the arguments we'll pass to the execution engine; they follow the same conventions\n",
    "            # of the dlicmd.py command line launcher\n",
    "            #\n",
    "            # See:\n",
    "            #   https://www.ibm.com/support/knowledgecenter/en/SSFHA8_1.2.1/cm/dlicmd.html\n",
    "            # In this example, args after --model-dir are all the required parameter for the original model itself.\n",
    "            'args': '--exec-start tensorflow --python-version 2.7 --cs-datastore-meta type=fs \\\n",
    "                     --gpuPerWorker 1 --model-main convolutional_network.py --model-dir tf-model\\\n",
    "                     --trainImagesFile /opt/zhuangxy/hporfe/tf-mnist/train-images-idx3-ubyte.gz \\\n",
    "                     --trainLabelsFile /opt/zhuangxy/hporfe/tf-mnist/train-labels-idx1-ubyte.gz \\\n",
    "                     --testImagesFile /opt/zhuangxy/hporfe/tf-mnist/t10k-images-idx3-ubyte.gz \\\n",
    "                     --testLabelsFile /opt/zhuangxy/hporfe/tf-mnist/t10k-labels-idx1-ubyte.gz'\n",
    "        },\n",
    "    \n",
    "        'algoDef': # Define the parameters for search algorithms\n",
    "        {\n",
    "            # Name of the plugin algorithm\n",
    "            'algorithm': 'test-random-debug', \n",
    "            # Max running time of the hpo task in minutes, -1 means unlimited\n",
    "            'maxRunTime': 60,  \n",
    "            # Max number of training job to submitted for hpo task, -1 means unlimited’,\n",
    "            'maxJobNum': 3,            \n",
    "            # Max number of training job to run in parallel, default 1. It depends on both the\n",
    "            # avaiable resource and if the search algorithm support to run in parallel, current only Random\n",
    "            # fully supports to run in parallel, Hyperband and Tpe supports to to in parellel in some phase,\n",
    "            # Bayesian runs in sequence now.\n",
    "            'maxParalleJobNum': 1, \n",
    "            # Name of the target metric that we are trying to optimize when searching hyper-parameters.\n",
    "            # It is the same metric name that the model update part 2 trying to dump.\n",
    "            'objectiveMetric' : 'loss',\n",
    "            # Strategy as how to optimize the hyper-parameters, minimize means to find better hyper-parameters to\n",
    "            # make the above objectiveMetric as small as possible, maximize means the opposite.\n",
    "            'objective' : 'minimize',\n",
    "            #Additional parameters for the specified search algorithm and hyper-band get following too.\n",
    "            'algoParams' : \n",
    "                [\n",
    "                    {\n",
    "                        # parameters passed to the plugin algorithm\n",
    "                        'name':'random_seed', \n",
    "                        'value': '2'\n",
    "                    }\n",
    "                ]\n",
    "        },\n",
    "    \n",
    "        # Define the hyper-paremeters to search and the corresponding search space.\n",
    "        'hyperParams':\n",
    "        [\n",
    "             {\n",
    "                 # Hyperparameter name, which will be the hyper-parameter key in config.json\n",
    "                 'name': 'learning_rate',\n",
    "                 # One of Range, Discrete\n",
    "                 'type': 'Range',\n",
    "                 # one of int, double, str\n",
    "                 'dataType': 'DOUBLE',\n",
    "                 # lower bound and upper bound when type=range and dataType=double\n",
    "                 'minDbVal': 0.001,\n",
    "                 'maxDbVal': 0.1,\n",
    "                 # lower bound and upper bound when type=range and dataType=int\n",
    "                 'minIntVal': 0,\n",
    "                 'maxIntVal': 0,\n",
    "                 # Discrete value list when type=discrete\n",
    "                 'discreteDbVal': [],\n",
    "                 'discreteIntVal': [],\n",
    "                 'discreateStrVal': [],\n",
    "                 #step size to split the Range space. ONLY valid when type is Range\n",
    "                 'step': '0.002',\n",
    "             }\n",
    "         ]\n",
    "    }\n",
    "mydata={'data':json.dumps(data)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Submit the Post request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit hpo task through the Post call and a hpo name/id as string format will get back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit tune job succeed with hponame: Admin-hpo-1132672298136969\n"
     ]
    }
   ],
   "source": [
    "startTuneUrl='{}/platform/rest/deeplearning/v1/hypersearch'.format(dlpd_rest_base_url)\n",
    "create = req.post(startTuneUrl, headers=commonHeaders, data=mydata, files=files, verify=False, auth=('Admin', 'Admin'))\n",
    "if not create.ok:\n",
    "   print('submit tune job failed: code=%s, %s'%(create.status_code, create.content))\n",
    "else:\n",
    "   print('submit tune job succeed with hponame: %s'%create.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check HPO task status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REST API: **GET /platform/rest/deeplearning/v1/hypersearch/{hponame}**\n",
    "- Description: Retrieve the hpo task details with the specified hpo task name/id in URL.\n",
    "- OUTPUT: A particular hpo task with details of the specified hponame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hpo task Admin-hpo-1132672298136969 state RUNNING progress 0/3\n",
      "Hpo task Admin-hpo-1132672298136969 state RUNNING progress 0/3\n",
      "Hpo task Admin-hpo-1132672298136969 state RUNNING progress 0/3\n",
      "Hpo task Admin-hpo-1132672298136969 state RUNNING progress 0/3\n",
      "Hpo task Admin-hpo-1132672298136969 state RUNNING progress 0/3\n",
      "Hpo task Admin-hpo-1132672298136969 state RUNNING progress 1/3\n",
      "Hpo task Admin-hpo-1132672298136969 state RUNNING progress 1/3\n",
      "Hpo task Admin-hpo-1132672298136969 state RUNNING progress 1/3\n",
      "Hpo task Admin-hpo-1132672298136969 state RUNNING progress 1/3\n",
      "Hpo task Admin-hpo-1132672298136969 state RUNNING progress 2/3\n",
      "Hpo task Admin-hpo-1132672298136969 state RUNNING progress 2/3\n",
      "Hpo task Admin-hpo-1132672298136969 state RUNNING progress 2/3\n",
      "Hpo task Admin-hpo-1132672298136969 state RUNNING progress 2/3\n",
      "Hpo task Admin-hpo-1132672298136969 completes with state FINISHED\n",
      "{\n",
      "    \"best\": {\n",
      "        \"appId\": \"Admin-1132760534098217-828876449\",\n",
      "        \"driverId\": \"driver-20200109173332-0048-71af7aef-b11e-4610-99c1-f7074b2b56e4\",\n",
      "        \"endTime\": \"2020-01-09 17:34:48\",\n",
      "        \"hyperParams\": [\n",
      "            {\n",
      "                \"dataType\": \"double\",\n",
      "                \"fixedVal\": \"0.031\",\n",
      "                \"name\": \"learning_rate\",\n",
      "                \"userDefined\": false\n",
      "            }\n",
      "        ],\n",
      "        \"id\": 1,\n",
      "        \"maxiteration\": 0,\n",
      "        \"metricVal\": 2.3008570671081543,\n",
      "        \"startTime\": \"2020-01-09 17:33:32\",\n",
      "        \"state\": \"FINISHED\"\n",
      "    },\n",
      "    \"complete\": 3,\n",
      "    \"createtime\": \"2020-01-09 17:32:03\",\n",
      "    \"creator\": \"Admin\",\n",
      "    \"duration\": \"00:04:02\",\n",
      "    \"experiments\": [\n",
      "        {\n",
      "            \"appId\": \"Admin-1132683570981379-513999867\",\n",
      "            \"driverId\": \"driver-20200109173215-0047-1422d7e7-faf5-4f2e-990c-bf01050ee60d\",\n",
      "            \"endTime\": \"2020-01-09 17:33:31\",\n",
      "            \"hyperParams\": [\n",
      "                {\n",
      "                    \"dataType\": \"double\",\n",
      "                    \"fixedVal\": \"0.081\",\n",
      "                    \"name\": \"learning_rate\",\n",
      "                    \"userDefined\": false\n",
      "                }\n",
      "            ],\n",
      "            \"id\": 0,\n",
      "            \"maxiteration\": 0,\n",
      "            \"metricVal\": 2.301335573196411,\n",
      "            \"startTime\": \"2020-01-09 17:32:15\",\n",
      "            \"state\": \"FINISHED\"\n",
      "        },\n",
      "        {\n",
      "            \"appId\": \"Admin-1132760534098217-828876449\",\n",
      "            \"driverId\": \"driver-20200109173332-0048-71af7aef-b11e-4610-99c1-f7074b2b56e4\",\n",
      "            \"endTime\": \"2020-01-09 17:34:48\",\n",
      "            \"hyperParams\": [\n",
      "                {\n",
      "                    \"dataType\": \"double\",\n",
      "                    \"fixedVal\": \"0.031\",\n",
      "                    \"name\": \"learning_rate\",\n",
      "                    \"userDefined\": false\n",
      "                }\n",
      "            ],\n",
      "            \"id\": 1,\n",
      "            \"maxiteration\": 0,\n",
      "            \"metricVal\": 2.3008570671081543,\n",
      "            \"startTime\": \"2020-01-09 17:33:32\",\n",
      "            \"state\": \"FINISHED\"\n",
      "        },\n",
      "        {\n",
      "            \"appId\": \"Admin-1132837709411661-1580048621\",\n",
      "            \"driverId\": \"driver-20200109173449-0049-ab6c6851-0142-4cab-8d7c-25e8fedbabb1\",\n",
      "            \"endTime\": \"2020-01-09 17:36:05\",\n",
      "            \"hyperParams\": [\n",
      "                {\n",
      "                    \"dataType\": \"double\",\n",
      "                    \"fixedVal\": \"0.091\",\n",
      "                    \"name\": \"learning_rate\",\n",
      "                    \"userDefined\": false\n",
      "                }\n",
      "            ],\n",
      "            \"id\": 2,\n",
      "            \"maxiteration\": 0,\n",
      "            \"metricVal\": 2.3022098541259766,\n",
      "            \"startTime\": \"2020-01-09 17:34:49\",\n",
      "            \"state\": \"FINISHED\"\n",
      "        }\n",
      "    ],\n",
      "    \"failed\": 0,\n",
      "    \"hpoName\": \"Admin-hpo-1132672298136969\",\n",
      "    \"progress\": \"3/3\",\n",
      "    \"running\": 0,\n",
      "    \"state\": \"FINISHED\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#Here we just use the hpo name returned of the previous POST call\n",
    "hpoName = create.json()\n",
    "\n",
    "getHpoUrl = '{}/platform/rest/deeplearning/v1/hypersearch/{}'.format(dlpd_rest_base_url, hpoName)\n",
    "res = req.get(getHpoUrl, headers=commonHeaders, verify=False, auth=('Admin', 'Admin'))\n",
    "if not res.ok:\n",
    "    print('get hpo task failed: code=%s, %s'%(res.status_code, res.content))\n",
    "else:\n",
    "    json_out=res.json()\n",
    "    \n",
    "    while json_out['state'] in ['SUBMITTED','RUNNING']:\n",
    "        print('Hpo task %s state %s progress %s'%(hpoName, json_out['state'], json_out['progress']))\n",
    "        res = req.get(getHpoUrl, headers=commonHeaders, verify=False, auth=('Admin', 'Admin'))\n",
    "        json_out=res.json()\n",
    "        time.sleep(20)\n",
    "    \n",
    "    print('Hpo task %s completes with state %s'%(hpoName, json_out['state']))\n",
    "    #print('Best:%s'%json.dumps(json_out.get('best'), sort_keys=True, indent=4))\n",
    "    print(json.dumps(res.json(), sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Full Response of a hpo task status.**\n",
    "\n",
    "```\n",
    "{\n",
    "\"hpoName\": \"string, name/id of the hpo task\",\n",
    "\"state\": \"string, hpo task state, SUBMITTED, RUNNING, FAILED, FINISHED, STOPPED\",\n",
    "\"running\": \"int, number of training that is under-going right now\",\n",
    "\"complete\": \"int, number of training that has completes, including both succeeded and failed trainings\",\n",
    "\"failed\": \"int, number of training that failed\",\n",
    "\"progress\": \"string, progress of a percentage value\",\n",
    "\"createtime\": \"string, time this task was created\",\n",
    "\"creator\": \"string, user name who created this hpo task\",\n",
    "\"duration\": \"string, how long the task been run with format hh-mm-ss\",\n",
    "\"experiments\": [\n",
    "                {\n",
    "                \"id\": \"int, counter id of the experiment training, start from 0\",\n",
    "                \"metricVal\": \"double, best metric value of the experiment training\",\n",
    "                \"state\": \"string, state of the BYOF training task\"\n",
    "                \"appId\": \"string, BYOF training task id\",\n",
    "                \"driverId\": \"string, for internal usage, the real job id for training, currently it is the spark driver id\",\n",
    "                \"hyperParams\": [\n",
    "                                {\n",
    "                                \"name\": \"string, name of the hyperparameter\",\n",
    "                                \"dataType\": \"string, data type of the hyperparameter\",\n",
    "                                \"fixedVal\": \"string, The hyperparamter value been used in this experiment training with the same datatype as input dataType\"\n",
    "                                }\n",
    "                                ],\n",
    "                }\n",
    "                ],\n",
    "\"best\": {\"one of the experiments with the best metric value, smallest or biggest one based on the original objective minimize or maximize\"}\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage HPO tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Check HPO tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Same REST api as the early health check one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hpo task: Admin-hpo-1132672298136969, State: FINISHED\n"
     ]
    }
   ],
   "source": [
    "getTuneStatusUrl = '{}/platform/rest/deeplearning/v1/hypersearch'.format(dlpd_rest_base_url)\n",
    "res = req.get(getTuneStatusUrl, headers=commonHeaders, verify=False, auth=('Admin', 'Admin'))\n",
    "if not res.ok:\n",
    "    print('check tune job status failed: code=%s, %s'%(res.status_code, res.content))\n",
    "else:\n",
    "    #print(json.dumps(r.json(), sort_keys=True, indent=4))\n",
    "    if len(res.json()) == 0:\n",
    "        print('There is no hpo task been created')\n",
    "    for item in res.json():\n",
    "        #print(item['hpoName'])\n",
    "        print('Hpo task: %s, State: %s'%(item['hpoName'], item['state']))\n",
    "        #print('Hpo tasks detail:%s'%json.dumps(item, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Stop Hpo task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "REST API: **PUT /platform/rest/deeplearning/v1/hypersearch/{hponame}**\n",
    "- Description: Stop the specified hpo job with name/di {hponame}\n",
    "- OUTPUT: success http return code\n",
    "\n",
    "Since the hpo job has already finished, so nothing to stop here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop hpo task failed: code=400, b'Error 400: Model tuning Admin-hpo-1132672298136969 is already stopped.\\n'\n"
     ]
    }
   ],
   "source": [
    "stopHpoUrl = '{}/platform/rest/deeplearning/v1/hypersearch/{}'.format(dlpd_rest_base_url, hpoName)\n",
    "r=req.put(stopHpoUrl,headers=commonHeaders, verify=False, auth=('Admin','Admin'))\n",
    "if not r.ok:\n",
    "    print('stop hpo task failed: code=%s, %s'%(r.status_code, r.content))\n",
    "else:\n",
    "    print('stop hpo task succeeds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete Hpo tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REST API: **DELETE /platform/rest/deeplearning/v1/hypersearch/{hponame}**\n",
    "- Description: Delete the specified hpo task with name/id {hponame}\n",
    "- OUTPUT: success http return code\n",
    "\n",
    "REST API: **DELETE /platform/rest/deeplearning/v1/hypersearch**\n",
    "- Description: Delete all the hpo task that the login user can access. But please be aware, the BYOF training been created by this hpo task will not be deleted.\n",
    "- OUTPUT: success http return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete hpo task succeeds\n"
     ]
    }
   ],
   "source": [
    "deleteHpoUrl = '{}/platform/rest/deeplearning/v1/hypersearch'.format(dlpd_rest_base_url)\n",
    "r=req.delete(deleteHpoUrl,headers=commonHeaders, verify=False, auth=('Admin','Admin'))\n",
    "if not r.ok:\n",
    "    print('delete hpo task failed: code=%s, %s'%(r.status_code, r.content))\n",
    "else:\n",
    "    print('delete hpo task succeeds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
