{"cells": [{"metadata": {"id": "ad3ace33-4bdf-4bd8-9cc6-11a50d85b560"}, "cell_type": "markdown", "source": "# Train a Linear Regression Model with Watson Machine Learning \n\nNotebook created by Zeming Zhao on June, 2021\n\nIn this notebook, you will learn how to use the Watson Machine Learning Accelerator (WML-A) API and accelerate the processing of Linear Regression model on GPU with Watson Machine Learning Accelerator.\n\nLinear Regression is a simple machine learning model where the response y is modelled by a linear combination of the predictors in X.\n\nIn this notebook we have three versions of Linear Regression model: scikit-learn version, cuML version and snapML version.\n\nAll three versions will be submitted onto WMLA. And we can compare the performance benifit of cuML and snapML version.\n\nThis notebook covers the following sections:\n\n1. [Generate dataset for Linear Regression](#dataset)<br>\n\n1. [Setup Linear Regression using SK-Learning](#skl-model)<br>\n\n1. [Training the SK-Learning model on CPU with Watson Machine Learning Accelerator](#skl-cpu)<br>\n\n1. [Setup Linear Regression using cuML](#cuml-model)<br>\n\n1. [Training the cuML model on GPU with Watson Machine Learning Accelerator](#cuml-gpu)<br>\n\n1. [Setup Linear Regression using snapML](#snapml-model)<br>\n\n1. [Training the SnapML model on CPU with Watson Machine Learning Accelerator](#snapml-cpu)<br>\n\n1. [Setup Linear Regression using snapML GPU](#snapml-model-gpu)<br>\n\n1. [Training the SnapML model on GPU with Watson Machine Learning Accelerator](#snapml-gpu)<br>"}, {"metadata": {"id": "b2fe19bd-b240-4bab-8faf-f40457cf071c"}, "cell_type": "markdown", "source": "## Preparations\n### Prepare directory and file for writing Linear Regression engine."}, {"metadata": {"id": "a7de9e24928d4327b9bd040221ac8416"}, "cell_type": "code", "source": "from pathlib import Path\ndataset_dir = f'/project_data/data_asset/dataset' \ndataset_base_name = f'linearRegression-dataset.py'\nPath(dataset_dir).mkdir(exist_ok=True)\nprint(\"create dataset directory done.\")", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "create dataset directory done.\n", "name": "stdout"}]}, {"metadata": {"id": "bfb28c11-2431-4c46-ba01-050e079dc434"}, "cell_type": "code", "source": "from pathlib import Path\nmodel_dir = f'/project_data/data_asset/models' \nmodel_base_name = f'linearRegression-main.py'\nPath(model_dir).mkdir(exist_ok=True)\nprint(\"create model directory done.\")", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "create model directory done.\n", "name": "stdout"}]}, {"metadata": {"id": "89cd0ff75bf14f558e51fb6ef32747f3"}, "cell_type": "markdown", "source": "<a id = \"dataset\"></a>\n## Step 1 : Generate dataset for Linear Regression"}, {"metadata": {"id": "6428d879c1ab4990b18f71cd972cb44a"}, "cell_type": "code", "source": "dataset_main='generate-'+dataset_base_name", "execution_count": 3, "outputs": []}, {"metadata": {"id": "2a4f8312bc79492ab6d8a1573173a2a7"}, "cell_type": "code", "source": "%%writefile {dataset_dir}/{dataset_main}\n\n# ```\n#(C) Copyright IBM Corp.  2019,2020. All Rights Reserved.\n# ```\n#\n# ```\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ```\n\n# Dataset preprocessing and training code based on the solution posted here:\n# https://www.kaggle.com/tsaustin/mercari-price-recommendation\n\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nimport argparse\nimport numpy as np\nimport scipy\n\nwork_dir = \"/gpfs/mydatafs/datasets\"\nsource_file = work_dir + \"/train.tsv\"\nthe_max_features = 0\n\n# Define output paths for the train and test datasets\nx_train_filename = work_dir +\"/dataset-lr/X_train.npz\"\nx_test_filename = work_dir +\"/dataset-lr/X_test.npz\"\ny_train_filename = work_dir +\"/dataset-lr/y_train.npy\"\ny_test_filename = work_dir +\"/dataset-lr/y_test.npy\"\n\n# Read the training dataset\ndf = pd.read_csv(source_file,sep=\"\\t\")\nprint(df.head())\n\n# Remove the train_id feature column\ndf.set_index('train_id',inplace=True)\nprint(df.head())\n\n# Compute the percentages of missing values\ndf_na = (df.isnull().sum() / len(df)) * 100\ndf_na = df_na.drop(df_na[df_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :df_na})\nmissing_data.head(20)\n\n# Compute the number of products with price 0\nlen(df[df['price'] == 0])\n\nprint(df['price'].unique())\n\n# Remove the products with price 0\ndf = df[df['price']>0]\n\n\n# Replace the missing values with a given word 'missing'\ndf['brand_name'] = df['brand_name'].fillna('missing')\ndf['category_name'] = df['category_name'].fillna('missing')\ndf['item_description'] = df['item_description'].fillna('missing')\nprint(df.head())\n\n# Change the data type for category_name, brand_name and item_condition_id\ndf['category_name'] = df['category_name'].astype('category')\ndf['item_condition_id'] = df['item_condition_id'].astype('category')\nprint(df.dtypes)\n\n# Words cleaning function for the columns with long text\ndef clean_text(col):\n    # remove non alpha characters\n    col = col.str.replace(\"[\\W]\", \" \") #a-zA-Z1234567890\n    # all lowercase\n    col = col.apply(lambda x: x.lower())\n    return col\n\n# Clean the text in the name, category name and item description features\ndf['name']=clean_text(df['name'])\ndf['category_name']=clean_text(df['category_name'])\ndf['item_description']=clean_text(df['item_description'])\nprint(df.head())\n\n\n# create feature matrix for name, category_name and item description features\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# The text will be replaced with a vector of word counts for each of the columns\n\nif the_max_features==0:\n    cv = CountVectorizer(min_df=0.0001, max_df=0.1, stop_words='english')\n    X_name = cv.fit_transform(df['name'])\n    print(X_name.shape)\n\n    cv = CountVectorizer()\n    X_category = cv.fit_transform(df['category_name'])\n    print(X_category.shape)\n\n    cv = CountVectorizer(min_df=0.0001, max_df=0.1, stop_words='english')\n    X_item_description = cv.fit_transform(df['item_description'])\n    print(X_item_description.shape)\n\nelse:\n    cv = CountVectorizer(min_df=0.0001, max_df=0.1, max_features=the_max_features, stop_words='english')\n    X_name = cv.fit_transform(df['name'])\n    print(X_name.shape)\n\n    cv = CountVectorizer(max_features=the_max_features)\n    X_category = cv.fit_transform(df['category_name'])\n    print(X_category.shape)\n\n    cv = CountVectorizer(min_df=0.0001, max_df=0.1, max_features=the_max_features, stop_words='english')\n    X_item_description = cv.fit_transform(df['item_description'])\n    print(X_item_description.shape)\n\n\n# the brand name is label binarizer\n# generate the feature matrix for the brand name feature\nfrom sklearn.preprocessing import LabelBinarizer\nif the_max_features==0:\n    lb = LabelBinarizer(sparse_output=True)\n    X_brand = lb.fit_transform(df['brand_name'])\nelse:\n    lb = LabelBinarizer(sparse_output=True)\n    X_brand = lb.fit_transform(df['brand_name'])\n\ny = df['price']\ndf = df.drop('price',axis=1)\nprint(df.head())\n\n# one-hot encoding for the item condition id (5 integer values) and shipping (2 integer values)\nfrom scipy.sparse import csr_matrix\ndf['shipping'] = df['shipping'].astype('category')\nX_condition_shipping = csr_matrix(pd.get_dummies(df[['item_condition_id','shipping']], sparse=True).values)\n\n# create the complete feature matrix by stacking the individual column transformations\nfrom scipy.sparse import hstack\n\nif the_max_features == 0:\n    X_all = hstack((X_brand, X_category, X_name, X_item_description, X_condition_shipping)).tocsr()\nelse:\n    X_all = hstack((X_brand, X_category, X_name, X_item_description, X_condition_shipping)).tocsr()\nprint(X_all.shape)\n\n# reduce the feature columns by removing all features with a document frequency smaller than 1\nimport numpy as np\nmask = np.array(np.clip(X_all.getnnz(axis=0) - 1, 0, 1), dtype=bool)\nX_all = X_all[:, mask]\nprint(X_all.shape)\n\n# target variable: the log of the price\ny_log = np.log1p(y)\n\n# perform standard scaling\nprint(\"Before Split\\n\")\nprint(\"X_all=\",X_all.shape)\nprint(\"y_log=\",y_log.shape)\n\n# split into test and train samples\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_all, y_log, random_state=42, test_size=0.2)\n\nprint(\"After Split\\n\")\nprint(\"X_train=\",X_train.shape)\nprint(\"X_test=\",X_test.shape)\nprint(\"y_train=\",y_train.shape)\nprint(\"y_test=\",y_test.shape)\n\nfrom sklearn.preprocessing import normalize\nX_train = normalize(X_train, axis=1, norm='l1')\nX_test = normalize(X_test, axis=1, norm='l1')\n\nprint(\"Saving X_train to \", x_train_filename)\nprint(\"Saving X_test to \", x_test_filename)\nprint(\"Saving y_train to \", y_train_filename)\nprint(\"Saving y_test to \", y_test_filename)\n\nscipy.sparse.save_npz(x_train_filename, X_train, compressed=False)\nscipy.sparse.save_npz(x_test_filename, X_test, compressed=False)\nnp.save(y_train_filename, y_train)\nnp.save(y_test_filename, y_test)\n", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "Overwriting /project_data/data_asset/dataset/generate-linearRegression-dataset.py\n", "name": "stdout"}]}, {"metadata": {"id": "0a1db31211e545188e57520e2b6c091d"}, "cell_type": "raw", "source": "dataset_main='linearregression-'+dataset_base_name"}, {"metadata": {"id": "a8c5f614d78448b39b97c7511d524f96"}, "cell_type": "raw", "source": "%%writefile {dataset_dir}/{dataset_main}\n\nimport os, datetime\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_sparse_uncorrelated\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import LinearRegression as skLinearRegression\nimport numpy as np\nfrom scipy.sparse import csr_matrix\nfrom scipy.sparse import save_npz\nfrom pathlib import Path\n\n# Define Parameters for a large regression\nn_samples = 2**19 #If you are running on a GPU with less than 16GB RAM, please change to 2**19 or you could run out of memory\nn_features = 699\nrandom_state = 42\n\n# Generate Data\nstart = datetime.datetime.now()\nX, y = make_sparse_uncorrelated(n_samples=n_samples, n_features=n_features, random_state=random_state)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\nend = datetime.datetime.now()\nprint (\"generate data timecost: %.2gs\" % ((end-start).total_seconds()))\n\nprint(\"Number of examples: %d\" % (X_train.shape[0]))\nprint(\"Number of features: %d\" % (X_train.shape[1]))\n\ndata_dir =  \"/gpfs/mydatafs/datasets/dataset-lr\"\nPath(data_dir).mkdir(exist_ok=True)\nstart = datetime.datetime.now()\nsave_npz(\"{0}/X_train.npz\".format(data_dir),csr_matrix(X_train))\nsave_npz(\"{0}/X_test.npz\".format(data_dir), csr_matrix(X_test))\nend = datetime.datetime.now()\nprint (\"convert samples to csr matrix and save, timecost: %.2gs\" % ((end-start).total_seconds()))\nstart = datetime.datetime.now()\nnp.save(\"{0}/X_train.npy\".format(data_dir),X_train) # for cuML only which does not support csr_matrix\nnp.save(\"{0}/X_test.npy\".format(data_dir), X_test)  # for cuML only which does not support csr_matrix\nend = datetime.datetime.now()\nprint (\"save samples as numpy array for cuML, timecost: %.2gs\" % ((end-start).total_seconds()))\nstart = datetime.datetime.now()\nnp.save(\"{0}/y_train.npy\".format(data_dir), y_train)\nnp.save(\"{0}/y_test.npy\".format(data_dir), y_test)\nend = datetime.datetime.now()\nprint (\"save labels as numpy array, timecost: %.2gs\" % ((end-start).total_seconds()))\n\nprint(\"Genearte datasets done:\")\nprint(*Path(data_dir).iterdir(), sep=\"\\n\")"}, {"metadata": {"id": "95e51f7a6346497aa1a9c153e72204ee"}, "cell_type": "markdown", "source": "### Prepare the model lib for job submission"}, {"metadata": {"id": "7057d0a0-3a8c-4e9b-8759-6bb24115a1f0"}, "cell_type": "code", "source": "import requests\nfrom requests.packages.urllib3.exceptions import InsecureRequestWarning\nrequests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n\nfrom matplotlib import pyplot as plt\n%pylab inline\n\nimport base64\nimport json\nimport time\nimport urllib", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "Populating the interactive namespace from numpy and matplotlib\n", "name": "stdout"}]}, {"metadata": {"id": "c484ca6a-0894-4b4f-a5cb-c90bc6efc546"}, "cell_type": "markdown", "source": "### Configuring your environment and project details\nTo set up your project details, provide your credentials in this cell. You must include your cluster URL, username, and password."}, {"metadata": {"id": "720deac1-005b-431e-a679-f4c10e2ff9e5"}, "cell_type": "code", "source": "# please enter Watson Machine Learning Accelerator host name\nhostname='wmla-console-wmla.apps.dse-perf.cpolab.ibm.com'\n# login='username:password' # please enter the login and password\nlogin='mluser1:mluser1'\nes = base64.b64encode(login.encode('utf-8')).decode(\"utf-8\")\n# print(es)\ncommonHeaders={'Authorization': 'Basic '+es}\nreq = requests.Session()\nauth_url = 'https://{}/auth/v1/logon'.format(hostname)\nprint(auth_url)\n\na=requests.get(auth_url,headers=commonHeaders, verify=False)\naccess_token=a.json()['accessToken']\n# print(\"Access_token: \", access_token)\n\ndl_rest_url = 'https://{}/platform/rest/deeplearning/v1'.format(hostname)\ncommonHeaders={'accept': 'application/json', 'X-Auth-Token': access_token}\nreq = requests.Session()\n\n# Health check\nconfUrl = 'https://{}/platform/rest/deeplearning/v1/conf'.format(hostname)\nr = req.get(confUrl, headers=commonHeaders, verify=False)", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "https://wmla-console-wmla.apps.dse-perf.cpolab.ibm.com/auth/v1/logon\n", "name": "stdout"}]}, {"metadata": {"id": "dd9dcc78-c9c3-4963-964d-67ab00539422"}, "cell_type": "markdown", "source": "### Define the status checking function"}, {"metadata": {"id": "cf7db32a-fa18-497c-8c01-10876052a30f"}, "cell_type": "code", "source": "import tarfile\nimport tempfile\nimport os\nimport json\nimport pprint\nimport pandas as pd\nfrom IPython.display import clear_output\n\ndef query_job_status(job_id,refresh_rate=3) :\n\n    execURL = dl_rest_url  +'/execs/'+ job_id['id']\n    pp = pprint.PrettyPrinter(indent=2)\n\n    keep_running=True\n    res=None\n    while(keep_running):\n        res = req.get(execURL, headers=commonHeaders, verify=False)\n        monitoring = pd.DataFrame(res.json(), index=[0])\n        pd.set_option('max_colwidth', 120)\n        clear_output()\n        print(\"Refreshing every {} seconds\".format(refresh_rate))\n        display(monitoring)\n        pp.pprint(res.json())\n        if(res.json()['state'] not in ['PENDING_CRD_SCHEDULER', 'SUBMITTED','RUNNING']) :\n            keep_running=False\n        time.sleep(refresh_rate)\n    return res", "execution_count": 7, "outputs": []}, {"metadata": {"id": "a27c9c1c-e348-44dd-898d-6214d83340bd"}, "cell_type": "markdown", "source": "### Define the submission function"}, {"metadata": {"id": "01943c6d-7ce8-4727-ac59-b5ceff6ef933"}, "cell_type": "code", "source": "def submit_job_to_wmla (args, files) :\n    starttime = datetime.datetime.now()\n    r = requests.post(dl_rest_url+'/execs?args='+args, files=files,\n                  headers=commonHeaders, verify=False)\n    if not r.ok:\n        print('submit job failed: code=%s, %s'%(r.status_code, r.content))\n    job_status = query_job_status(r.json(),refresh_rate=5)\n    endtime = datetime.datetime.now()\n    print(\"\\nTotallly training cost: \", (endtime - starttime).seconds, \" seconds.\")", "execution_count": 8, "outputs": []}, {"metadata": {"id": "e859de7b-e58d-415d-af45-bb05e22c019a"}, "cell_type": "markdown", "source": "<a id = \"cpu\"></a>\n### Define the submission parameters for scikit-learn version on cpu"}, {"metadata": {"id": "edbb5c0ffec24448842b1ef251bafe84"}, "cell_type": "code", "source": "# specify the model file, conda env, device type and device number\nargs = '--exec-start tensorflow --cs-datastore-meta type=fs \\\n--workerDeviceNum 1 \\\n--workerMemory 32G \\\n--workerDeviceType cpu \\\n--conda-env-name dlipy3-cpu  \\\n--model-main ' + dataset_main\n\nprint(args)", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType cpu --conda-env-name dlipy3-cpu  --model-main generate-linearRegression-dataset.py\n", "name": "stdout"}]}, {"metadata": {"id": "50e0df2f-9497-43c1-a9c8-6dc573939793"}, "cell_type": "markdown", "source": "### Submit WMLA Workload"}, {"metadata": {"id": "66a334887c1341708b517336d9b60f60"}, "cell_type": "code", "source": "files = {'file': open(\"{0}/{1}\".format(dataset_dir,dataset_main),'rb')}\nsubmit_job_to_wmla (args, files)", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "Refreshing every 5 seconds\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "          id  \\\n0  wmla-1291   \n\n                                                                                                                      args  \\\n0  --exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType cpu --...   \n\n  submissionId  creator     state      appId           schedulerUrl  \\\n0    wmla-1291  mluser1  FINISHED  wmla-1291  https://wmla-mss:9080   \n\n  modelFileOwnerName  \\\n0               wmla   \n\n                                                           workDir  \\\n0  /gpfs/myresultfs/mluser1/batchworkdir/wmla-1291/_submitted_code   \n\n                     appName            createTime  elastic nameSpace  \\\n0  SingleNodeTensorflowTrain  2021-08-06T10:10:26Z    False      wmla   \n\n   numWorker   framework  \n0          1  tensorflow  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>args</th>\n      <th>submissionId</th>\n      <th>creator</th>\n      <th>state</th>\n      <th>appId</th>\n      <th>schedulerUrl</th>\n      <th>modelFileOwnerName</th>\n      <th>workDir</th>\n      <th>appName</th>\n      <th>createTime</th>\n      <th>elastic</th>\n      <th>nameSpace</th>\n      <th>numWorker</th>\n      <th>framework</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>wmla-1291</td>\n      <td>--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType cpu --...</td>\n      <td>wmla-1291</td>\n      <td>mluser1</td>\n      <td>FINISHED</td>\n      <td>wmla-1291</td>\n      <td>https://wmla-mss:9080</td>\n      <td>wmla</td>\n      <td>/gpfs/myresultfs/mluser1/batchworkdir/wmla-1291/_submitted_code</td>\n      <td>SingleNodeTensorflowTrain</td>\n      <td>2021-08-06T10:10:26Z</td>\n      <td>False</td>\n      <td>wmla</td>\n      <td>1</td>\n      <td>tensorflow</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}, {"output_type": "stream", "text": "{ 'appId': 'wmla-1291',\n  'appName': 'SingleNodeTensorflowTrain',\n  'args': '--exec-start tensorflow --cs-datastore-meta type=fs '\n          '--workerDeviceNum 1 --workerMemory 32G --workerDeviceType cpu '\n          '--conda-env-name dlipy3-cpu  --model-main '\n          'generate-linearRegression-dataset.py ',\n  'createTime': '2021-08-06T10:10:26Z',\n  'creator': 'mluser1',\n  'elastic': False,\n  'framework': 'tensorflow',\n  'id': 'wmla-1291',\n  'modelFileOwnerName': 'wmla',\n  'nameSpace': 'wmla',\n  'numWorker': 1,\n  'schedulerUrl': 'https://wmla-mss:9080',\n  'state': 'FINISHED',\n  'submissionId': 'wmla-1291',\n  'workDir': '/gpfs/myresultfs/mluser1/batchworkdir/wmla-1291/_submitted_code'}\n\nTotallly training cost:  209  seconds.\n", "name": "stdout"}]}, {"metadata": {"id": "ddc68f9b-d9b0-4fc1-9c04-1c74b75014d6"}, "cell_type": "markdown", "source": "<a id = \"skl-model\"></a>\n## Step 2 : Setup Linear Regression using SK-Learning"}, {"metadata": {"id": "b098bbdc-cc82-4af8-b8a3-9ebf967f26e0"}, "cell_type": "code", "source": "model_main='sklean-'+model_base_name", "execution_count": 11, "outputs": []}, {"metadata": {"id": "d105d6d8-618f-419f-a841-5abe061bc5f3"}, "cell_type": "code", "source": "%%writefile {model_dir}/{model_main}\n\nimport os, datetime\n#from sklearn.datasets import make_regression\n#from sklearn.model_selection import train_test_split\n#from sklearn.datasets import make_sparse_uncorrelated\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import LinearRegression as skLinearRegression\nimport numpy as np\nfrom scipy.sparse import load_npz\n\n# load Data\ndata_dir =  \"/gpfs/mydatafs/datasets/dataset-lr\"\nstart = datetime.datetime.now()\nX_train = load_npz(data_dir + \"/X_train.npz\")\nX_test  = load_npz(data_dir + \"/X_test.npz\")\ny_train = np.load(data_dir + \"/y_train.npy\")\ny_test = np.load(data_dir + \"/y_test.npy\")\nend = datetime.datetime.now()\nprint (\"load data timecost: %.2gs\" % ((end-start).total_seconds()))\n\nprint(type(X_train))\nprint(\"Number of examples: %d\" % (X_train.shape[0]))\nprint(\"Number of features: %d\" % (X_train.shape[1]))\n\n# scikit-learn Model\nlr_model = skLinearRegression(fit_intercept=True,\n                            normalize=True,\n                            n_jobs=-1)\n\n# Fit\nstart = datetime.datetime.now()\nlr_model.fit(X_train, y_train)\nend = datetime.datetime.now()\nprint (\"train timecost: %.2gs\" % ((end-start).total_seconds()))\n\n# Predict\nstart = datetime.datetime.now()\npredict = lr_model.predict(X_test)\nend = datetime.datetime.now()\nprint (\"predict timecost: %.2gs\" % ((end-start).total_seconds()))\n\n# Evaluate\nstart = datetime.datetime.now()\nr2_score = r2_score(y_test, predict)\nend = datetime.datetime.now()\nprint (\"evaluate timecost: %.2gs\" % ((end-start).total_seconds()))\n\n#  print(\"R^2 score (SKL):  %s\" % r2_score_sk)\nprint(\"R^2 score (scikit-learn): %.4f\" % r2_score)", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "Overwriting /project_data/data_asset/models/sklean-linearRegression-main.py\n", "name": "stdout"}]}, {"metadata": {"id": "7ecb15ee-8867-4a1a-b476-d4088a9a6086"}, "cell_type": "markdown", "source": "<a id = \"skl-cpu\"></a>\n## Step 3 :  Training the SK-Learning model on CPU with Watson Machine Learning Accelerator\n"}, {"metadata": {"id": "32435afd-d3eb-43a6-83a4-4d9351819b92"}, "cell_type": "code", "source": "# specify the model file, conda env, device type and device number\nargs = '--exec-start tensorflow --cs-datastore-meta type=fs \\\n--workerDeviceNum 1 \\\n--workerMemory 16G \\\n--workerDeviceType cpu \\\n--conda-env-name dlipy3-cpu  \\\n--model-main ' + model_main\n\nprint(args)", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 16G --workerDeviceType cpu --conda-env-name dlipy3-cpu  --model-main sklean-linearRegression-main.py\n", "name": "stdout"}]}, {"metadata": {"id": "1ea493177d0a45db8e8c77293a4e4ccb"}, "cell_type": "code", "source": "files = {'file': open(\"{0}/{1}\".format(model_dir,model_main),'rb')}\nsubmit_job_to_wmla (args, files)", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "Refreshing every 5 seconds\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "          id  \\\n0  wmla-1292   \n\n                                                                                                                      args  \\\n0  --exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 16G --workerDeviceType cpu --...   \n\n  submissionId  creator     state      appId           schedulerUrl  \\\n0    wmla-1292  mluser1  FINISHED  wmla-1292  https://wmla-mss:9080   \n\n  modelFileOwnerName  \\\n0               wmla   \n\n                                                           workDir  \\\n0  /gpfs/myresultfs/mluser1/batchworkdir/wmla-1292/_submitted_code   \n\n                     appName            createTime  elastic nameSpace  \\\n0  SingleNodeTensorflowTrain  2021-08-06T10:13:56Z    False      wmla   \n\n   numWorker   framework  \n0          1  tensorflow  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>args</th>\n      <th>submissionId</th>\n      <th>creator</th>\n      <th>state</th>\n      <th>appId</th>\n      <th>schedulerUrl</th>\n      <th>modelFileOwnerName</th>\n      <th>workDir</th>\n      <th>appName</th>\n      <th>createTime</th>\n      <th>elastic</th>\n      <th>nameSpace</th>\n      <th>numWorker</th>\n      <th>framework</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>wmla-1292</td>\n      <td>--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 16G --workerDeviceType cpu --...</td>\n      <td>wmla-1292</td>\n      <td>mluser1</td>\n      <td>FINISHED</td>\n      <td>wmla-1292</td>\n      <td>https://wmla-mss:9080</td>\n      <td>wmla</td>\n      <td>/gpfs/myresultfs/mluser1/batchworkdir/wmla-1292/_submitted_code</td>\n      <td>SingleNodeTensorflowTrain</td>\n      <td>2021-08-06T10:13:56Z</td>\n      <td>False</td>\n      <td>wmla</td>\n      <td>1</td>\n      <td>tensorflow</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}, {"output_type": "stream", "text": "{ 'appId': 'wmla-1292',\n  'appName': 'SingleNodeTensorflowTrain',\n  'args': '--exec-start tensorflow --cs-datastore-meta type=fs '\n          '--workerDeviceNum 1 --workerMemory 16G --workerDeviceType cpu '\n          '--conda-env-name dlipy3-cpu  --model-main '\n          'sklean-linearRegression-main.py ',\n  'createTime': '2021-08-06T10:13:56Z',\n  'creator': 'mluser1',\n  'elastic': False,\n  'framework': 'tensorflow',\n  'id': 'wmla-1292',\n  'modelFileOwnerName': 'wmla',\n  'nameSpace': 'wmla',\n  'numWorker': 1,\n  'schedulerUrl': 'https://wmla-mss:9080',\n  'state': 'FINISHED',\n  'submissionId': 'wmla-1292',\n  'workDir': '/gpfs/myresultfs/mluser1/batchworkdir/wmla-1292/_submitted_code'}\n\nTotallly training cost:  161  seconds.\n", "name": "stdout"}]}, {"metadata": {"id": "be0e9a55-960b-4c32-9451-679609cc62f6"}, "cell_type": "markdown", "source": "<a id = \"cuml-model\"></a>\n## Step 4 :  Setup Linear Regression using cuML"}, {"metadata": {"id": "86dadf0d-afb6-43f4-a438-9294969b42f0"}, "cell_type": "code", "source": "model_main='cuML-'+model_base_name", "execution_count": 15, "outputs": []}, {"metadata": {"id": "cc1e1b51-283e-4325-9366-72d45b4422dd"}, "cell_type": "raw", "source": "%%writefile {model_dir}/{model_main}\n\nimport os, datetime\nimport cudf\n#from cuml import make_regression, train_test_split\n#from sklearn.datasets import make_sparse_uncorrelated\nfrom cuml.linear_model import LinearRegression as cuLinearRegression\nfrom cuml.metrics.regression import r2_score\nimport numpy as np\nfrom scipy.sparse import load_npz\nimport pandas as pd\nimport gc\n\n# specify the cache location to /gpfy since ~/.cache is not available\nos.environ[\"CUPY_CACHE_DIR\"]=\"/gpfs/mydatafs/models/cache/lr\"\n\n# load Data\nstart = datetime.datetime.now()\ndata_dir =  \"/gpfs/mydatafs/datasets/dataset-lr\"\nX_train = np.load(data_dir + \"/X_train.npy\")\nX_test  = np.load(data_dir + \"/X_test.npy\")\ny_train = np.load(data_dir + \"/y_train.npy\")\ny_test  = np.load(data_dir + \"/y_test.npy\")\nend = datetime.datetime.now()\nprint (\"load data timecost: %.2gs\" % ((end-start).total_seconds()))\n\nprint(X_train.shape)\nprint(y_train.shape)\n#print(\"Number of examples: %d\" % (X_train.shape))\n#print(\"Number of features: %d\" % (y_train.shape))\n\n\n# cuML Model\nlr_model = cuLinearRegression(fit_intercept=True,normalize=True,algorithm='eig')\n\n# Fit\nstart = datetime.datetime.now()\nlr_model.fit(X_train, y_train)\nend = datetime.datetime.now()\nprint (\"train timecost: %.2gs\" % ((end-start).total_seconds()))\n\n# Predict\nstart = datetime.datetime.now()\npredict_cuml = lr_model.predict(X_test)\nend = datetime.datetime.now()\nprint (\"predict timecost: %.2gs\" % ((end-start).total_seconds()))\n\n# Evaluate\nstart = datetime.datetime.now()\nr2_score_cuml = r2_score(y_test, predict_cuml)\nend = datetime.datetime.now()\nprint (\"evaluate timecost: %.2gs\" % ((end-start).total_seconds()))\n\nprint(\"R^2 score (cuML): %.4f\" % r2_score_cuml)"}, {"metadata": {"id": "dcdefbb3422c45418a034d3942d23f4b"}, "cell_type": "code", "source": "%%writefile {model_dir}/{model_main}\n####\n####  please reduce the dataset size if your GPU cannot handle the input dataset\n####\n\nimport os, datetime\nimport cudf\n#from cuml import make_regression, train_test_split\n#from sklearn.datasets import make_sparse_uncorrelated\nfrom cuml.linear_model import LinearRegression as cuLinearRegression\nfrom cuml.metrics.regression import r2_score\nimport numpy as np\nfrom scipy.sparse import load_npz\nimport pandas as pd\nimport gc\n\ncudf.set_allocator(\"managed\")\n\n# specify the cache location to /gpfy since ~/.cache is not available\nos.environ[\"CUPY_CACHE_DIR\"]=\"/gpfs/mydatafs/models/cache/lr\"\n\n# load Data\ndata_dir =  \"/gpfs/mydatafs/datasets/dataset-lr\"\nstart = datetime.datetime.now()\nX_train_ = load_npz(data_dir + \"/X_train.npz\")\nprint(X_train_.shape)\n#X_train__ = pd.DataFrame.sparse.from_spmatrix(X_train_)\nX_train = pd.DataFrame.sparse.from_spmatrix(X_train_)\ndel X_train_\ngc.collect()\n#X_train = cudf.DataFrame(X_train__[-200000:])\n#del X_train__\n#gc.collect()\nX_test_ = load_npz(data_dir + \"/X_test.npz\")\nprint(X_test_.shape)\n#X_test__ = pd.DataFrame.sparse.from_spmatrix(X_test_)\nX_test = pd.DataFrame.sparse.from_spmatrix(X_test_)\ndel X_test_\ngc.collect()\n#X_test = cudf.DataFrame(X_test__[-50000:])\n#del X_test__\n#gc.collect()\nend = datetime.datetime.now()\nprint (\"load data timecost: %.2gs\" % ((end-start).total_seconds()))\n\nprint(\"Number of examples: %d\" % (X_train.shape[0]))\nprint(\"Number of features: %d\" % (X_train.shape[1]))\n\nstart = datetime.datetime.now()\n# X_train = np.load(data_dir + \"/X_train.npy\")\n# X_test  = np.load(data_dir + \"/X_test.npy\")\ny_train = np.load(data_dir + \"/y_train.npy\")\n#y_train = y_train[-200000:]\ny_test = np.load(data_dir + \"/y_test.npy\")\n#y_test = y_test[-50000:]\nend = datetime.datetime.now()\nprint (\"load data timecost: %.2gs\" % ((end-start).total_seconds()))\n\n# cuML Model\nlr_model = cuLinearRegression(fit_intercept=True,normalize=True,algorithm='eig')\n\n# Fit\nstart = datetime.datetime.now()\nlr_model.fit(X_train, y_train)\nend = datetime.datetime.now()\nprint (\"train timecost: %.2gs\" % ((end-start).total_seconds()))\n\n# Predict\nstart = datetime.datetime.now()\npredict_cuml = lr_model.predict(X_test)\nend = datetime.datetime.now()\nprint (\"predict timecost: %.2gs\" % ((end-start).total_seconds()))\n\n# Evaluate\nstart = datetime.datetime.now()\nr2_score_cuml = r2_score(y_test, predict_cuml)\nend = datetime.datetime.now()\nprint (\"evaluate timecost: %.2gs\" % ((end-start).total_seconds()))\n\nprint(\"R^2 score (cuML): %.4f\" % r2_score_cuml)", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "Overwriting /project_data/data_asset/models/cuML-linearRegression-main.py\n", "name": "stdout"}]}, {"metadata": {"id": "260f712b-98e2-4cc6-af09-2acfbeca85d0"}, "cell_type": "markdown", "source": "<a id = \"cuml-gpu\"></a>\n## Step 5 :  Training the cuML model on GPU with Watson Machine Learning Accelerator\n### Re-define the submssion parameters"}, {"metadata": {"id": "4c9b9c9f-046c-4d08-b07c-4f1c97312fe9"}, "cell_type": "code", "source": "# specify the model file, conda env, device type and device number\nargs = '--exec-start tensorflow --cs-datastore-meta type=fs \\\n--workerDeviceNum 1 \\\n--workerMemory 16G \\\n--workerDeviceType gpu \\\n--conda-env-name rapids-21.06-new \\\n--model-main ' + model_main\n\nprint(args)", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 16G --workerDeviceType gpu --conda-env-name rapids-21.06-new --model-main cuML-linearRegression-main.py\n", "name": "stdout"}]}, {"metadata": {"id": "01f4efcc-215f-4f41-b05e-4ef7a36f8db4"}, "cell_type": "markdown", "source": "### Submit WMLA Workload"}, {"metadata": {"id": "ef75f049-a633-496b-a256-ab1511716d55"}, "cell_type": "code", "source": "files = {'file': open(\"{0}/{1}\".format(model_dir,model_main),'rb')}\nsubmit_job_to_wmla (args, files)", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "Refreshing every 5 seconds\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "          id  \\\n0  wmla-1293   \n\n                                                                                                                      args  \\\n0  --exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 16G --workerDeviceType gpu --...   \n\n  submissionId  creator  state      appId           schedulerUrl  \\\n0    wmla-1293  mluser1  ERROR  wmla-1293  https://wmla-mss:9080   \n\n  modelFileOwnerName  \\\n0               wmla   \n\n                                                           workDir  \\\n0  /gpfs/myresultfs/mluser1/batchworkdir/wmla-1293/_submitted_code   \n\n                     appName            createTime  elastic  \\\n0  SingleNodeTensorflowTrain  2021-08-06T10:16:37Z    False   \n\n                            events nameSpace  numWorker   framework  \n0  Job <wmla-1293> task <1> failed      wmla          1  tensorflow  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>args</th>\n      <th>submissionId</th>\n      <th>creator</th>\n      <th>state</th>\n      <th>appId</th>\n      <th>schedulerUrl</th>\n      <th>modelFileOwnerName</th>\n      <th>workDir</th>\n      <th>appName</th>\n      <th>createTime</th>\n      <th>elastic</th>\n      <th>events</th>\n      <th>nameSpace</th>\n      <th>numWorker</th>\n      <th>framework</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>wmla-1293</td>\n      <td>--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 16G --workerDeviceType gpu --...</td>\n      <td>wmla-1293</td>\n      <td>mluser1</td>\n      <td>ERROR</td>\n      <td>wmla-1293</td>\n      <td>https://wmla-mss:9080</td>\n      <td>wmla</td>\n      <td>/gpfs/myresultfs/mluser1/batchworkdir/wmla-1293/_submitted_code</td>\n      <td>SingleNodeTensorflowTrain</td>\n      <td>2021-08-06T10:16:37Z</td>\n      <td>False</td>\n      <td>Job &lt;wmla-1293&gt; task &lt;1&gt; failed</td>\n      <td>wmla</td>\n      <td>1</td>\n      <td>tensorflow</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}, {"output_type": "stream", "text": "{ 'appId': 'wmla-1293',\n  'appName': 'SingleNodeTensorflowTrain',\n  'args': '--exec-start tensorflow --cs-datastore-meta type=fs '\n          '--workerDeviceNum 1 --workerMemory 16G --workerDeviceType gpu '\n          '--conda-env-name rapids-21.06-new --model-main '\n          'cuML-linearRegression-main.py ',\n  'createTime': '2021-08-06T10:16:37Z',\n  'creator': 'mluser1',\n  'elastic': False,\n  'events': 'Job <wmla-1293> task <1> failed',\n  'framework': 'tensorflow',\n  'id': 'wmla-1293',\n  'modelFileOwnerName': 'wmla',\n  'nameSpace': 'wmla',\n  'numWorker': 1,\n  'schedulerUrl': 'https://wmla-mss:9080',\n  'state': 'ERROR',\n  'submissionId': 'wmla-1293',\n  'workDir': '/gpfs/myresultfs/mluser1/batchworkdir/wmla-1293/_submitted_code'}\n\nTotallly training cost:  62  seconds.\n", "name": "stdout"}]}, {"metadata": {"id": "2ce3b2f1-8b06-4806-ba0d-f5fe79eede57"}, "cell_type": "markdown", "source": "<a id = \"snapml-model\"></a>\n## Step 6:  Setup Linear Regression model using snapML"}, {"metadata": {"id": "5bf00ec9-fa8d-4446-a774-28fa9b9445d9"}, "cell_type": "code", "source": "model_main='snapML-'+model_base_name", "execution_count": 19, "outputs": []}, {"metadata": {"id": "1466279c-6fcf-4a52-806b-79c05aa186e4"}, "cell_type": "code", "source": "%%writefile {model_dir}/{model_main}\n\nimport datetime\n#from sklearn.datasets import make_regression\n#from sklearn.model_selection import train_test_split\n#from sklearn.datasets import make_sparse_uncorrelated\nfrom sklearn.metrics import r2_score\nfrom snapml import LinearRegression as SnapLinearRegression\nimport numpy as np\nfrom scipy.sparse import load_npz\n\n# load Data\ndata_dir =  \"/gpfs/mydatafs/datasets/dataset-lr\"\nstart = datetime.datetime.now()\nX_train = load_npz(data_dir + \"/X_train.npz\")\nX_test  = load_npz(data_dir + \"/X_test.npz\")\ny_train = np.load(data_dir + \"/y_train.npy\")\ny_test = np.load(data_dir + \"/y_test.npy\")\nend = datetime.datetime.now()\nprint (\"load data timecost: %.2gs\" % ((end-start).total_seconds()))\n\nprint(\"Number of examples: %d\" % (X_train.shape[0]))\nprint(\"Number of features: %d\" % (X_train.shape[1]))\n\n# snapML model\nlr_model = SnapLinearRegression(fit_intercept=True,normalize=True)\n\n# Fit\nstart = datetime.datetime.now()\nlr_model.fit(X_train, y_train)\nend = datetime.datetime.now()\nprint (\"train timecost: %.2gs\" % ((end-start).total_seconds()))\n\nr2_score_snapml = r2_score(y_test, lr_model.predict(X_test))\nprint(\"R^2 score (snapML): %.4f\" % r2_score_snapml)", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "Overwriting /project_data/data_asset/models/snapML-linearRegression-main.py\n", "name": "stdout"}]}, {"metadata": {"id": "759faabf-1fc4-4c50-aa9c-a2f698b79bb0"}, "cell_type": "markdown", "source": "<a id = \"snapml-cpu\"></a>\n## Step 7 :  Training the SnapML model on CPU with Watson Machine Learning Accelerator\n### Re-define the submission parameters"}, {"metadata": {"id": "c928a850-470d-4dcd-a8f4-0d52a5d1ee4e"}, "cell_type": "code", "source": "# specify the model file, conda env, device type and device number\nargs = '--exec-start tensorflow --cs-datastore-meta type=fs \\\n--workerDeviceNum 1 \\\n--workerMemory 16G \\\n--workerDeviceType cpu \\\n--conda-env-name snapml-177rc \\\n--model-main ' + model_main\nprint(args)", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 16G --workerDeviceType cpu --conda-env-name snapml-177rc --model-main snapML-linearRegression-main.py\n", "name": "stdout"}]}, {"metadata": {"id": "f921c773-d3c7-4be6-8403-47c1bbb8fe8d"}, "cell_type": "markdown", "source": "### Submit WMLA Workload"}, {"metadata": {"id": "b159bacf-8004-43e4-a148-563529e3136a"}, "cell_type": "code", "source": "files = {'file': open(\"{0}/{1}\".format(model_dir,model_main),'rb')}\nsubmit_job_to_wmla (args, files)", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "Refreshing every 5 seconds\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "          id  \\\n0  wmla-1294   \n\n                                                                                                                      args  \\\n0  --exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 16G --workerDeviceType cpu --...   \n\n  submissionId  creator     state      appId           schedulerUrl  \\\n0    wmla-1294  mluser1  FINISHED  wmla-1294  https://wmla-mss:9080   \n\n  modelFileOwnerName  \\\n0               wmla   \n\n                                                           workDir  \\\n0  /gpfs/myresultfs/mluser1/batchworkdir/wmla-1294/_submitted_code   \n\n                     appName            createTime  elastic nameSpace  \\\n0  SingleNodeTensorflowTrain  2021-08-06T10:17:40Z    False      wmla   \n\n   numWorker   framework  \n0          1  tensorflow  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>args</th>\n      <th>submissionId</th>\n      <th>creator</th>\n      <th>state</th>\n      <th>appId</th>\n      <th>schedulerUrl</th>\n      <th>modelFileOwnerName</th>\n      <th>workDir</th>\n      <th>appName</th>\n      <th>createTime</th>\n      <th>elastic</th>\n      <th>nameSpace</th>\n      <th>numWorker</th>\n      <th>framework</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>wmla-1294</td>\n      <td>--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 16G --workerDeviceType cpu --...</td>\n      <td>wmla-1294</td>\n      <td>mluser1</td>\n      <td>FINISHED</td>\n      <td>wmla-1294</td>\n      <td>https://wmla-mss:9080</td>\n      <td>wmla</td>\n      <td>/gpfs/myresultfs/mluser1/batchworkdir/wmla-1294/_submitted_code</td>\n      <td>SingleNodeTensorflowTrain</td>\n      <td>2021-08-06T10:17:40Z</td>\n      <td>False</td>\n      <td>wmla</td>\n      <td>1</td>\n      <td>tensorflow</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}, {"output_type": "stream", "text": "{ 'appId': 'wmla-1294',\n  'appName': 'SingleNodeTensorflowTrain',\n  'args': '--exec-start tensorflow --cs-datastore-meta type=fs '\n          '--workerDeviceNum 1 --workerMemory 16G --workerDeviceType cpu '\n          '--conda-env-name snapml-177rc --model-main '\n          'snapML-linearRegression-main.py ',\n  'createTime': '2021-08-06T10:17:40Z',\n  'creator': 'mluser1',\n  'elastic': False,\n  'framework': 'tensorflow',\n  'id': 'wmla-1294',\n  'modelFileOwnerName': 'wmla',\n  'nameSpace': 'wmla',\n  'numWorker': 1,\n  'schedulerUrl': 'https://wmla-mss:9080',\n  'state': 'FINISHED',\n  'submissionId': 'wmla-1294',\n  'workDir': '/gpfs/myresultfs/mluser1/batchworkdir/wmla-1294/_submitted_code'}\n\nTotallly training cost:  34  seconds.\n", "name": "stdout"}]}, {"metadata": {"id": "7b283663-5994-4b28-8bd2-115498da2d9f"}, "cell_type": "markdown", "source": "<a id = \"snapml-model-gpu\"></a>\n## Step 8 :  Setup Linear Regression model using snapML on GPU\n### Create a Linear Regression Model based on snapML "}, {"metadata": {"id": "bf306b28-f55d-4fdf-aa79-957188934a61"}, "cell_type": "code", "source": "model_main='snapML-GPU-'+model_base_name", "execution_count": 23, "outputs": []}, {"metadata": {"id": "ec8ffdcd-8fee-4b16-9a80-b8c5f29ce641"}, "cell_type": "code", "source": "%%writefile {model_dir}/{model_main}\n\nimport datetime\n#from sklearn.datasets import make_regression\n#from sklearn.model_selection import train_test_split\n#from sklearn.datasets import make_sparse_uncorrelated\nfrom sklearn.metrics import r2_score\nfrom snapml import LinearRegression as SnapLinearRegression\nimport numpy as np\nfrom scipy.sparse import load_npz\n\n# load Data\ndata_dir =  \"/gpfs/mydatafs/datasets/dataset-lr\"\nstart = datetime.datetime.now()\nX_train = load_npz(data_dir + \"/X_train.npz\")\nX_test  = load_npz(data_dir + \"/X_test.npz\")\ny_train = np.load(data_dir + \"/y_train.npy\")\ny_test = np.load(data_dir + \"/y_test.npy\")\nend = datetime.datetime.now()\nprint (\"load data timecost: %.2gs\" % ((end-start).total_seconds()))\n\nprint(\"Number of examples: %d\" % (X_train.shape[0]))\nprint(\"Number of features: %d\" % (X_train.shape[1]))\n\n# snapML model\nlr_model = SnapLinearRegression(use_gpu=True,\n                                fit_intercept=True,normalize=True)\n\n# Fit\nstart = datetime.datetime.now()\nlr_model.fit(X_train, y_train)\nend = datetime.datetime.now()\nprint (\"train timecost: %.2gs\" % ((end-start).total_seconds()))\n\nr2_score_snapml = r2_score(y_test, lr_model.predict(X_test))\nprint(\"R^2 score (snapML): %.4f\" % r2_score_snapml)", "execution_count": 24, "outputs": [{"output_type": "stream", "text": "Overwriting /project_data/data_asset/models/snapML-GPU-linearRegression-main.py\n", "name": "stdout"}]}, {"metadata": {"id": "7cf2fd02-3182-4f62-8b92-5da02c7d35fb"}, "cell_type": "markdown", "source": "<a id = \"snapml-gpu\"></a>\n## Step 9 :  Training the SnapML model on GPU with Watson Machine Learning Accelerator\n### Re-define the submission parameters"}, {"metadata": {"id": "856bd646-915c-4b19-b684-789501e9b770"}, "cell_type": "code", "source": "# specify the model file, conda env, device type and device number\nargs = '--exec-start tensorflow --cs-datastore-meta type=fs \\\n--workerDeviceNum 1 \\\n--workerMemory 16G \\\n--workerDeviceType gpu \\\n--conda-env-name snapml-177rc \\\n--model-main ' + model_main\nprint(args)", "execution_count": 25, "outputs": [{"output_type": "stream", "text": "--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 16G --workerDeviceType gpu --conda-env-name snapml-177rc --model-main snapML-GPU-linearRegression-main.py\n", "name": "stdout"}]}, {"metadata": {"id": "e4292f58-5039-489a-9586-fc5c35e2364d"}, "cell_type": "code", "source": "files = {'file': open(\"{0}/{1}\".format(model_dir,model_main),'rb')}\nsubmit_job_to_wmla (args, files)", "execution_count": 26, "outputs": [{"output_type": "stream", "text": "Refreshing every 5 seconds\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "          id  \\\n0  wmla-1295   \n\n                                                                                                                      args  \\\n0  --exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 16G --workerDeviceType gpu --...   \n\n  submissionId  creator     state      appId           schedulerUrl  \\\n0    wmla-1295  mluser1  FINISHED  wmla-1295  https://wmla-mss:9080   \n\n  modelFileOwnerName  \\\n0               wmla   \n\n                                                           workDir  \\\n0  /gpfs/myresultfs/mluser1/batchworkdir/wmla-1295/_submitted_code   \n\n                     appName            createTime  elastic nameSpace  \\\n0  SingleNodeTensorflowTrain  2021-08-06T10:18:14Z    False      wmla   \n\n   numWorker   framework  \n0          1  tensorflow  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>args</th>\n      <th>submissionId</th>\n      <th>creator</th>\n      <th>state</th>\n      <th>appId</th>\n      <th>schedulerUrl</th>\n      <th>modelFileOwnerName</th>\n      <th>workDir</th>\n      <th>appName</th>\n      <th>createTime</th>\n      <th>elastic</th>\n      <th>nameSpace</th>\n      <th>numWorker</th>\n      <th>framework</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>wmla-1295</td>\n      <td>--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 16G --workerDeviceType gpu --...</td>\n      <td>wmla-1295</td>\n      <td>mluser1</td>\n      <td>FINISHED</td>\n      <td>wmla-1295</td>\n      <td>https://wmla-mss:9080</td>\n      <td>wmla</td>\n      <td>/gpfs/myresultfs/mluser1/batchworkdir/wmla-1295/_submitted_code</td>\n      <td>SingleNodeTensorflowTrain</td>\n      <td>2021-08-06T10:18:14Z</td>\n      <td>False</td>\n      <td>wmla</td>\n      <td>1</td>\n      <td>tensorflow</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}, {"output_type": "stream", "text": "{ 'appId': 'wmla-1295',\n  'appName': 'SingleNodeTensorflowTrain',\n  'args': '--exec-start tensorflow --cs-datastore-meta type=fs '\n          '--workerDeviceNum 1 --workerMemory 16G --workerDeviceType gpu '\n          '--conda-env-name snapml-177rc --model-main '\n          'snapML-GPU-linearRegression-main.py ',\n  'createTime': '2021-08-06T10:18:14Z',\n  'creator': 'mluser1',\n  'elastic': False,\n  'framework': 'tensorflow',\n  'id': 'wmla-1295',\n  'modelFileOwnerName': 'wmla',\n  'nameSpace': 'wmla',\n  'numWorker': 1,\n  'schedulerUrl': 'https://wmla-mss:9080',\n  'state': 'FINISHED',\n  'submissionId': 'wmla-1295',\n  'workDir': '/gpfs/myresultfs/mluser1/batchworkdir/wmla-1295/_submitted_code'}\n\nTotallly training cost:  46  seconds.\n", "name": "stdout"}]}, {"metadata": {"id": "8856cb5b-c8ab-4cc7-81a9-6791beec5c4d"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"id": "cf89078162bb4f3e9231bebb1254d4c2"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"id": "40d24424be2741718cfb6a31cb2942f4"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 5}