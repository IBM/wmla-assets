{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8199ec9f",
   "metadata": {},
   "source": [
    "# Train a Random Forest Model with Watson Machine Learning \n",
    "\n",
    "Notebook created by Zeming Zhao on June, 2021\n",
    "\n",
    "The Random Forest algorithm is a classification method which builds several decision trees, and aggregates each of their outputs to make a prediction.\n",
    "\n",
    "In this notebook we will train a scikit-learn and a cuML Random Forest Classification model. Then we save the cuML model for future use with Python's pickling mechanism and demonstrate how to re-load it for prediction. We also compare the results of the scikit-learn, non-pickled and pickled cuML models.\n",
    "\n",
    "This notebook covers the following sections:\n",
    "\n",
    "1. [Setup Random Forest using cuML](#rbm-model)<br>\n",
    "\n",
    "1. [Training the model on GPU with Watson Machine Learning Accelerator](#gpu)<br>\n",
    "\n",
    "1. [Setup Random Forest using sklearning](#rbm-model)<br>\n",
    "\n",
    "1. [Training the model on CPU with Watson Machine Learning Accelerator](#cpu)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9564495",
   "metadata": {},
   "source": [
    "<a id = \"rbm-model\"></a>\n",
    "## Step 1 : Setup Random Forest model using cuML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df239ee",
   "metadata": {},
   "source": [
    "### Prepare directory and file for writing Random Forest engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7f35cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create model directory done.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "model_dir = f'/data/models' \n",
    "model_main = f'RandomForest_main.py'\n",
    "Path(model_dir).mkdir(exist_ok=True)\n",
    "print(\"create model directory done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15e5bde",
   "metadata": {},
   "source": [
    "### create a Random Forest Model based on cuML on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "061dd5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /data/models/RandomForest_main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {model_dir}/{model_main}\n",
    "\n",
    "import cudf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from cuml.ensemble import RandomForestClassifier as curfc\n",
    "from cuml.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as skrfc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# specify the cache location to /gpfy since ~/.cache is not available\n",
    "os.environ[\"CUPY_CACHE_DIR\"]=\"/gpfs/mydatafs/models/\"\n",
    "\n",
    "# Define Parameters for a large regression\n",
    "n_samples = 2**12\n",
    "n_features = 399\n",
    "n_info = 300\n",
    "data_type = np.float32\n",
    "\n",
    "# Generate Data\n",
    "X,y = make_classification(n_samples=n_samples,\n",
    "                          n_features=n_features,\n",
    "                          n_informative=n_info,\n",
    "                          random_state=123, n_classes=2)\n",
    "\n",
    "X = pd.DataFrame(X.astype(data_type))\n",
    "# cuML Random Forest Classifier requires the labels to be integers\n",
    "y = pd.Series(y.astype(np.int32))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                     test_size = 0.2,\n",
    "                                                     random_state=0)\n",
    "\n",
    "# cuML\n",
    "X_cudf_train = cudf.DataFrame.from_pandas(X_train)\n",
    "X_cudf_test = cudf.DataFrame.from_pandas(X_test)\n",
    "\n",
    "y_cudf_train = cudf.Series(y_train.values)\n",
    "\n",
    "# # SK model\n",
    "# sk_model = skrfc(n_estimators=40,\n",
    "#                  max_depth=16,\n",
    "#                  max_features=1.0,\n",
    "#                  random_state=10)\n",
    "\n",
    "# # Fit\n",
    "# start = datetime.datetime.now()\n",
    "# sk_model.fit(X_train, y_train)\n",
    "# end = datetime.datetime.now()\n",
    "# print (\"train timecost: %.2gs\" % ((end-start).total_seconds()))\n",
    "\n",
    "# # Evaluate\n",
    "# start = datetime.datetime.now()\n",
    "# sk_predict = sk_model.predict(X_test)\n",
    "# end = datetime.datetime.now()\n",
    "# print (\"evaluate timecost: %.2gs\" % ((end-start).total_seconds()))\n",
    "\n",
    "# sk_acc = accuracy_score(y_test, sk_predict)\n",
    "\n",
    "             \n",
    "# cuML Model\n",
    "cuml_model = curfc(n_estimators=40,\n",
    "                   max_depth=16,\n",
    "                   max_features=1.0,\n",
    "                   random_state=10)\n",
    "# Fit\n",
    "start = datetime.datetime.now()\n",
    "cuml_model.fit(X_cudf_train, y_cudf_train)\n",
    "end = datetime.datetime.now()\n",
    "print (\"train timecost: %.2gs\" % ((end-start).total_seconds()))\n",
    "\n",
    "# Evaluate\n",
    "start = datetime.datetime.now()\n",
    "fil_preds_orig = cuml_model.predict(X_cudf_test)\n",
    "end = datetime.datetime.now()\n",
    "print (\"evaluate timecost: %.2gs\" % ((end-start).total_seconds()))\n",
    "\n",
    "fil_acc_orig = accuracy_score(y_test.to_numpy(), fil_preds_orig)\n",
    "\n",
    "filename = './cuml_random_forest_model.sav'\n",
    "# save the trained cuml model into a file\n",
    "pickle.dump(cuml_model, open(filename, 'wb'))\n",
    "# delete the previous model to ensure that there is no leakage of pointers.\n",
    "# this is not strictly necessary but just included here for demo purposes.\n",
    "del cuml_model\n",
    "# load the previously saved cuml model from a file\n",
    "pickled_cuml_model = pickle.load(open(filename,  'rb'))\n",
    "                                      \n",
    "pred_after_pickling = pickled_cuml_model.predict(X_cudf_test)\n",
    "\n",
    "fil_acc_after_pickling = accuracy_score(y_test.to_numpy(), pred_after_pickling)                                      \n",
    "                                      \n",
    "print(\"CUML accuracy of the RF model before pickling: %s\" % fil_acc_orig)\n",
    "print(\"CUML accuracy of the RF model after pickling: %s\" % fil_acc_after_pickling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a4aae",
   "metadata": {},
   "source": [
    "## Step 2 :  Training the model on GPU with Watson Machine Learning Accelerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d686a",
   "metadata": {},
   "source": [
    "<a id = \"gpu\"></a>\n",
    "#### Prepare the model lib for running on GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f43d349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1860fe",
   "metadata": {},
   "source": [
    "#### Configuring your environment and project details\n",
    "To set up your project details, provide your credentials in this cell. You must include your cluster URL, username, and password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88b1025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wmla-console-wmla.apps.wml1x180.ma.platformlab.ibm.com/auth/v1/logon\n"
     ]
    }
   ],
   "source": [
    "hostname='wmla-console-wmla.apps.wml1x180.ma.platformlab.ibm.com'  # please enter Watson Machine Learning Accelerator host name\n",
    "# login='username:password' # please enter the login and password\n",
    "login='admin:p7PMrMMknVQzEb3ptyj0D6XRTO5PQjYL'\n",
    "es = base64.b64encode(login.encode('utf-8')).decode(\"utf-8\")\n",
    "# print(es)\n",
    "commonHeaders={'Authorization': 'Basic '+es}\n",
    "req = requests.Session()\n",
    "auth_url = 'https://{}/auth/v1/logon'.format(hostname)\n",
    "print(auth_url)\n",
    "\n",
    "a=requests.get(auth_url,headers=commonHeaders, verify=False)\n",
    "access_token=a.json()['accessToken']\n",
    "# print(\"Access_token: \", access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02640387",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_rest_url = 'https://{}/platform/rest/deeplearning/v1'.format(hostname)\n",
    "commonHeaders={'accept': 'application/json', 'X-Auth-Token': access_token}\n",
    "req = requests.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c61761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Health check\n",
    "confUrl = 'https://{}/platform/rest/deeplearning/v1/conf'.format(hostname)\n",
    "r = req.get(confUrl, headers=commonHeaders, verify=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9e71b",
   "metadata": {},
   "source": [
    "#### define the status checking fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73532b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import tempfile\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def query_job_status(job_id,refresh_rate=3) :\n",
    "\n",
    "    execURL = dl_rest_url  +'/execs/'+ job_id['id']\n",
    "    pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "    keep_running=True\n",
    "    res=None\n",
    "    while(keep_running):\n",
    "        res = req.get(execURL, headers=commonHeaders, verify=False)\n",
    "        monitoring = pd.DataFrame(res.json(), index=[0])\n",
    "        pd.set_option('max_colwidth', 120)\n",
    "        clear_output()\n",
    "        print(\"Refreshing every {} seconds\".format(refresh_rate))\n",
    "        display(monitoring)\n",
    "        pp.pprint(res.json())\n",
    "        if(res.json()['state'] not in ['PENDING_CRD_SCHEDULER', 'SUBMITTED','RUNNING']) :\n",
    "            keep_running=False\n",
    "        time.sleep(refresh_rate)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b300299",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = model_dir+\"/\"+model_main\n",
    "files = {'file': open(model_file , 'rb')}\n",
    "\n",
    "args = '--exec-start tensorflow --cs-datastore-meta type=fs \\\n",
    "                     --workerDeviceNum 1 \\\n",
    "                     --conda-env-name rapids-21.06  \\\n",
    "                     --model-main /gpfs/mydatafs/models/RandomForest_main.py --workerDeviceType gpu'\n",
    "                    # --epochs 5 --batch-size 10000 --workerDeviceType gpu'\n",
    "                    # --model-main '+  \"/gpfs/mydatafs/\" + model_file + ' --epochs 5 --batch-size 10000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b0853ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refreshing every 5 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>args</th>\n",
       "      <th>submissionId</th>\n",
       "      <th>creator</th>\n",
       "      <th>state</th>\n",
       "      <th>appId</th>\n",
       "      <th>schedulerUrl</th>\n",
       "      <th>modelFileOwnerName</th>\n",
       "      <th>workDir</th>\n",
       "      <th>appName</th>\n",
       "      <th>createTime</th>\n",
       "      <th>elastic</th>\n",
       "      <th>nameSpace</th>\n",
       "      <th>numWorker</th>\n",
       "      <th>framework</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wmla-209</td>\n",
       "      <td>--exec-start tensorflow --cs-datastore-meta type=fs                      --workerDeviceNum 1                      --...</td>\n",
       "      <td>wmla-209</td>\n",
       "      <td>admin</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>wmla-209</td>\n",
       "      <td>https://wmla-mss:9080</td>\n",
       "      <td>wmla</td>\n",
       "      <td>/gpfs/myresultfs/admin/batchworkdir/wmla-209/_submitted_code</td>\n",
       "      <td>SingleNodeTensorflowTrain</td>\n",
       "      <td>2021-07-02T07:46:08Z</td>\n",
       "      <td>False</td>\n",
       "      <td>wmla</td>\n",
       "      <td>1</td>\n",
       "      <td>tensorflow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "0  wmla-209   \n",
       "\n",
       "                                                                                                                      args  \\\n",
       "0  --exec-start tensorflow --cs-datastore-meta type=fs                      --workerDeviceNum 1                      --...   \n",
       "\n",
       "  submissionId creator     state     appId           schedulerUrl  \\\n",
       "0     wmla-209   admin  FINISHED  wmla-209  https://wmla-mss:9080   \n",
       "\n",
       "  modelFileOwnerName  \\\n",
       "0               wmla   \n",
       "\n",
       "                                                        workDir  \\\n",
       "0  /gpfs/myresultfs/admin/batchworkdir/wmla-209/_submitted_code   \n",
       "\n",
       "                     appName            createTime  elastic nameSpace  \\\n",
       "0  SingleNodeTensorflowTrain  2021-07-02T07:46:08Z    False      wmla   \n",
       "\n",
       "   numWorker   framework  \n",
       "0          1  tensorflow  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'appId': 'wmla-209',\n",
      "  'appName': 'SingleNodeTensorflowTrain',\n",
      "  'args': '--exec-start tensorflow --cs-datastore-meta '\n",
      "          'type=fs                      --workerDeviceNum '\n",
      "          '1                      --conda-env-name '\n",
      "          'rapids-21.06                       --model-main '\n",
      "          '/gpfs/mydatafs/models/RandomForest_main.py --workerDeviceType gpu ',\n",
      "  'createTime': '2021-07-02T07:46:08Z',\n",
      "  'creator': 'admin',\n",
      "  'elastic': False,\n",
      "  'framework': 'tensorflow',\n",
      "  'id': 'wmla-209',\n",
      "  'modelFileOwnerName': 'wmla',\n",
      "  'nameSpace': 'wmla',\n",
      "  'numWorker': 1,\n",
      "  'schedulerUrl': 'https://wmla-mss:9080',\n",
      "  'state': 'FINISHED',\n",
      "  'submissionId': 'wmla-209',\n",
      "  'workDir': '/gpfs/myresultfs/admin/batchworkdir/wmla-209/_submitted_code'}\n",
      "\n",
      "Training cost:  32  seconds.\n"
     ]
    }
   ],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "\n",
    "r = requests.post(dl_rest_url+'/execs?args='+args, files=files,\n",
    "                  headers=commonHeaders, verify=False)\n",
    "if not r.ok:\n",
    "    print('submit job failed: code=%s, %s'%(r.status_code, r.content))\n",
    "        \n",
    "job_status = query_job_status(r.json(),refresh_rate=5)\n",
    "\n",
    "endtime = datetime.datetime.now()\n",
    "\n",
    "print(\"\\nTraining cost: \", (endtime - starttime).seconds, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26acd96a",
   "metadata": {},
   "source": [
    "## Step 3 :  Setup Random Forest model using SK-Learning\n",
    "### create a Random Forest Model based on sk-learning on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c7a402c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /data/models/RandomForest_main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {model_dir}/{model_main}\n",
    "\n",
    "# import cudf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# from cuml.ensemble import RandomForestClassifier as curfc\n",
    "# from cuml.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier as skrfc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# specify the cache location to /gpfy since ~/.cache is not available\n",
    "os.environ[\"CUPY_CACHE_DIR\"]=\"/gpfs/mydatafs/models/\"\n",
    "\n",
    "# Define Parameters for a large regression\n",
    "n_samples = 2**12\n",
    "n_features = 399\n",
    "n_info = 300\n",
    "data_type = np.float32\n",
    "\n",
    "# Generate Data\n",
    "# SK\n",
    "X,y = make_classification(n_samples=n_samples,\n",
    "                          n_features=n_features,\n",
    "                          n_informative=n_info,\n",
    "                          random_state=123, n_classes=2)\n",
    "\n",
    "X = pd.DataFrame(X.astype(data_type))\n",
    "# cuML Random Forest Classifier requires the labels to be integers\n",
    "y = pd.Series(y.astype(np.int32))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# SK model\n",
    "sk_model = skrfc(n_estimators=40,\n",
    "                 max_depth=16,\n",
    "                 max_features=1.0,\n",
    "                 random_state=10)\n",
    "\n",
    "# Fit\n",
    "start = datetime.datetime.now()\n",
    "sk_model.fit(X_train, y_train)\n",
    "end = datetime.datetime.now()\n",
    "print (\"train timecost: %.2gs\" % ((end-start).total_seconds()))\n",
    "\n",
    "# Evaluate\n",
    "start = datetime.datetime.now()\n",
    "sk_predict = sk_model.predict(X_test)\n",
    "end = datetime.datetime.now()\n",
    "print (\"evaluate timecost: %.2gs\" % ((end-start).total_seconds()))\n",
    "\n",
    "sk_acc = accuracy_score(y_test, sk_predict)\n",
    "\n",
    "filename = './cuml_random_forest_model.sav'\n",
    "# save the trained cuml model into a file\n",
    "pickle.dump(sk_model, open(filename, 'wb'))\n",
    "# delete the previous model to ensure that there is no leakage of pointers.\n",
    "# this is not strictly necessary but just included here for demo purposes.\n",
    "del sk_model\n",
    "# load the previously saved cuml model from a file\n",
    "pickled_sk_model = pickle.load(open(filename,  'rb'))\n",
    "                                      \n",
    "pred_after_pickling = pickled_sk_model.predict(X_test)\n",
    "\n",
    "fil_acc_after_pickling = accuracy_score(y_test.to_numpy(), pred_after_pickling)                                      \n",
    "                                      \n",
    "print(\"CUML accuracy of the RF model before pickling: %s\" % sk_acc)\n",
    "print(\"CUML accuracy of the RF model after pickling: %s\" % fil_acc_after_pickling)\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d77981",
   "metadata": {},
   "source": [
    "## Step 4 :  Training the SK-Learning model on CPU with Watson Machine Learning Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5fc69887",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = model_dir+\"/\"+model_main\n",
    "files = {'file': open(model_file , 'rb')}\n",
    "\n",
    "args = '--exec-start tensorflow --cs-datastore-meta type=fs \\\n",
    "                     --workerDeviceNum 1 \\\n",
    "                     --conda-env-name rapids-21.06  \\\n",
    "                     --model-main /gpfs/mydatafs/models/RandomForest_main.py --workerDeviceType cpu'\n",
    "                    # --epochs 5 --batch-size 10000 --workerDeviceType gpu'\n",
    "                    # --model-main '+  \"/gpfs/mydatafs/\" + model_file + ' --epochs 5 --batch-size 10000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76e749fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refreshing every 5 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>args</th>\n",
       "      <th>submissionId</th>\n",
       "      <th>creator</th>\n",
       "      <th>state</th>\n",
       "      <th>appId</th>\n",
       "      <th>schedulerUrl</th>\n",
       "      <th>modelFileOwnerName</th>\n",
       "      <th>workDir</th>\n",
       "      <th>appName</th>\n",
       "      <th>createTime</th>\n",
       "      <th>elastic</th>\n",
       "      <th>nameSpace</th>\n",
       "      <th>numWorker</th>\n",
       "      <th>framework</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wmla-211</td>\n",
       "      <td>--exec-start tensorflow --cs-datastore-meta type=fs                      --workerDeviceNum 1                      --...</td>\n",
       "      <td>wmla-211</td>\n",
       "      <td>admin</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>wmla-211</td>\n",
       "      <td>https://wmla-mss:9080</td>\n",
       "      <td>wmla</td>\n",
       "      <td>/gpfs/myresultfs/admin/batchworkdir/wmla-211/_submitted_code</td>\n",
       "      <td>SingleNodeTensorflowTrain</td>\n",
       "      <td>2021-07-02T07:49:54Z</td>\n",
       "      <td>False</td>\n",
       "      <td>wmla</td>\n",
       "      <td>1</td>\n",
       "      <td>tensorflow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "0  wmla-211   \n",
       "\n",
       "                                                                                                                      args  \\\n",
       "0  --exec-start tensorflow --cs-datastore-meta type=fs                      --workerDeviceNum 1                      --...   \n",
       "\n",
       "  submissionId creator     state     appId           schedulerUrl  \\\n",
       "0     wmla-211   admin  FINISHED  wmla-211  https://wmla-mss:9080   \n",
       "\n",
       "  modelFileOwnerName  \\\n",
       "0               wmla   \n",
       "\n",
       "                                                        workDir  \\\n",
       "0  /gpfs/myresultfs/admin/batchworkdir/wmla-211/_submitted_code   \n",
       "\n",
       "                     appName            createTime  elastic nameSpace  \\\n",
       "0  SingleNodeTensorflowTrain  2021-07-02T07:49:54Z    False      wmla   \n",
       "\n",
       "   numWorker   framework  \n",
       "0          1  tensorflow  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'appId': 'wmla-211',\n",
      "  'appName': 'SingleNodeTensorflowTrain',\n",
      "  'args': '--exec-start tensorflow --cs-datastore-meta '\n",
      "          'type=fs                      --workerDeviceNum '\n",
      "          '1                      --conda-env-name '\n",
      "          'rapids-21.06                       --model-main '\n",
      "          '/gpfs/mydatafs/models/RandomForest_main.py --workerDeviceType cpu ',\n",
      "  'createTime': '2021-07-02T07:49:54Z',\n",
      "  'creator': 'admin',\n",
      "  'elastic': False,\n",
      "  'framework': 'tensorflow',\n",
      "  'id': 'wmla-211',\n",
      "  'modelFileOwnerName': 'wmla',\n",
      "  'nameSpace': 'wmla',\n",
      "  'numWorker': 1,\n",
      "  'schedulerUrl': 'https://wmla-mss:9080',\n",
      "  'state': 'FINISHED',\n",
      "  'submissionId': 'wmla-211',\n",
      "  'workDir': '/gpfs/myresultfs/admin/batchworkdir/wmla-211/_submitted_code'}\n",
      "Training cost:  58  seconds.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "# ! python {model_dir}/{model_main} # --no-cuda --epochs 5 --batch-size 10000\n",
    "r = requests.post(dl_rest_url+'/execs?args='+args, files=files,\n",
    "                  headers=commonHeaders, verify=False)\n",
    "if not r.ok:\n",
    "    print('submit job failed: code=%s, %s'%(r.status_code, r.content))\n",
    "        \n",
    "job_status = query_job_status(r.json(),refresh_rate=5)\n",
    "\n",
    "endtime = datetime.datetime.now()\n",
    "print(\"Training cost: \", (endtime - starttime).seconds, \" seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe957809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 Single GPU Kernel",
   "language": "python",
   "name": "python_single_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
