{
    "cells": [
        {
            "metadata": {
                "id": "cf808d4e-1d29-4dcf-ad91-c440f5640fed"
            }, 
            "cell_type": "markdown", 
            "source": "# Train a Xgboost Model with Watson Machine Learning 

Notebook created by Zeming Zhao on June, 2021

XGBoost is an implementation of gradient boosted decision trees designed for speed and performance. which is an algorithm that has recently been dominating applied machine learning and Kaggle competitions for structured or tabular data.

SnapBoost implements a boosting machine that can be used to construct an ensemble of decision trees. It can be used for both clasification and regression tasks. In constrast to other boosting frameworks, Snap ML's boosting machine dose not utilize a fixed maximal tree depth at each boosting iteration. Instead, the tree depth is sampled at each boosting iteration according to a discrete uniform distribution. The fit and predict functions accept numpy.ndarray data structures.

This notebook covers the following sections:

1. [Setup Xgboost Model using xgboost lib](#xgboost-model)<br>

1. [Training the model on CPU with Watson Machine Learning Accelerator](#xgboost-cpu)<br>

1. [Training the model on GPU with Watson Machine Learning Accelerator](#xgboost-gpu)<br>

1. [Setup SnapBoost Model using snapML lib on CPU](#snapml-model)<br>

1. [Training the model on CPU with Watson Machine Learning Accelerator](#snapml-cpu)<br>

1. [Setup SnapBoost Model using snapML lib on GPU](#snapml-model-gpu)<br>

1. [Training the model on GPU with Watson Machine Learning Accelerator](#snapml-gpu)<br>"
        }, 
        {
            "metadata": {
                "id": "416eaf5f-f861-4960-aea0-bf024d8c97f5"
            }, 
            "cell_type": "markdown", 
            "source": "## Preparations
### Prepare directory and file for writing Xgboost engine."
        }, 
        {
            "metadata": {
                "id": "68eedf75ddc048478358fdeecbd4ce80"
            }, 
            "cell_type": "code", 
            "source": "from pathlib import Path
model_dir = f'/project_data/data_asset/models' 
model_base_name = f'main.py'
Path(model_dir).mkdir(exist_ok=True)
print(\"create model directory done.\")", 
            "execution_count": 11, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "create model directory done.
", 
                    "name": "stdout"
                }
            ]
        }, 
        {
            "metadata": {
                "id": "9328d48f-df30-4aaa-83b3-e45185310f77"
            }, 
            "cell_type": "markdown", 
            "source": "<a id = \"xgboost-model\"></a>
## Step 1 : Setup Xgboost model
### create a Xgboost Model based on Xgboost lib "
        }, 
        {
            "metadata": {
                "id": "d92eef792a5e4b818df48a2d4361ee13"
            }, 
            "cell_type": "code", 
            "source": "model_main='xgboost-'+model_base_name", 
            "execution_count": 12, 
            "outputs": [ ]
        }, 
        {
            "metadata": {
                "id": "ac5837a67b7441b296dac5f925124df8"
            }, 
            "cell_type": "code", 
            "source": "%%writefile {model_dir}/{model_main}

import os, datetime
import numpy as np
import pandas as pd
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, accuracy_score
import xgboost as xgb

os.environ['KMP_DUPLICATE_LIB_OK']='True'

# Define Parameters for a large regression
n_samples = 2**13 
n_features = 899 
n_info = 600 
data_type = np.float32

# Generate Data using scikit-learn
X,y = make_classification(n_samples=n_samples,
                          n_features=n_features,
                          n_informative=n_info,
                          random_state=123, n_classes=2)

X = pd.DataFrame(X.astype(data_type))
y = pd.Series(y.astype(np.int32))

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size = 0.2,
                                                    random_state=0)

print(\"Number of examples: %d\" % (X_train.shape[0]))
print(\"Number of features: %d\" % (X_train.shape[1]))
print(\"Number of classes:  %d\" % (len(np.unique(y_train))))

D_train = xgb.DMatrix(X_train, label=y_train)
D_test = xgb.DMatrix(X_test, label=y_test)

# set parameters
param = {
    'eta': 0.3, 
    'max_depth': 6,  
    'objective': 'multi:softprob',  
    'num_class': 3} 

steps = 20  # The number of training iterations

# setup model and train
start = datetime.datetime.now()
model = xgb.train(param, D_train, steps)
end = datetime.datetime.now()
print (\"Xgboost train timecost: %.2gs\" % ((end-start).total_seconds()))

# predict
start = datetime.datetime.now()
preds = model.predict(D_test)
end = datetime.datetime.now()
print (\"Xgboost predict timecost: %.2gs\" % ((end-start).total_seconds()))

# check result
best_preds = np.asarray([np.argmax(line) for line in preds])
print(\"Precision = {}\".format(precision_score(y_test, best_preds, average='macro')))
print(\"Recall = {}\".format(recall_score(y_test, best_preds, average='macro')))
print(\"Accuracy = {}\".format(accuracy_score(y_test, best_preds)))

# save the xgboost model into a file
import pickle
filename = './xgboost_model.pkl'
pickle.dump(model, open(filename, 'wb'))              
print(\"Xgboost model saved successfully.\")", 
            "execution_count": 13, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Overwriting /project_data/data_asset/models/xgboost-main.py
", 
                    "name": "stdout"
                }
            ]
        }, 
        {
            "metadata": {
                "id": "f595d528-5042-4e02-a882-c3509720227d"
            }, 
            "cell_type": "markdown", 
            "source": "<a id = \"xgboost-cpu\"></a>
## Step 2 :  Training the Xgboost model on CPU with Watson Machine Learning Accelerator
### Prepare the libs for job submission"
        }, 
        {
            "metadata": {
                "id": "e3e9ce96ff4a4adaa583c9e2805c4230"
            }, 
            "cell_type": "code", 
            "source": "import requests
from requests.packages.urllib3.exceptions import InsecureRequestWarning
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

from matplotlib import pyplot as plt
%pylab inline

import base64
import json
import time
import urllib", 
            "execution_count": 4, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Populating the interactive namespace from numpy and matplotlib
", 
                    "name": "stdout"
                }
            ]
        }, 
        {
            "metadata": {
                "id": "4e5592c1-07c1-47d4-9bae-aff94e1d832f"
            }, 
            "cell_type": "markdown", 
            "source": "### Configuring your environment and project details
To set up your project details, provide your credentials in this cell. You must include your cluster URL, username, and password."
        }, 
        {
            "metadata": {
                "id": "047097811f624ed0825c37b6f976c587"
            }, 
            "cell_type": "code", 
            "source": "# please enter Watson Machine Learning Accelerator host name
hostname='wmla-console-wmla.apps.dse-perf.cpolab.ibm.com'
# login='username:password' # please enter the login and password
login='mluser1:mluser1'
es = base64.b64encode(login.encode('utf-8')).decode(\"utf-8\")
# print(es)
commonHeaders={'Authorization': 'Basic '+es}
req = requests.Session()
auth_url = 'https://{}/auth/v1/logon'.format(hostname)
print(auth_url)
a=requests.get(auth_url,headers=commonHeaders, verify=False)
access_token=a.json()['accessToken']
# print(\"Access_token: \", access_token)
dl_rest_url = 'https://{}/platform/rest/deeplearning/v1'.format(hostname)
commonHeaders={'accept': 'application/json', 'X-Auth-Token': access_token}
req = requests.Session()
# Health check
confUrl = 'https://{}/platform/rest/deeplearning/v1/conf'.format(hostname)
r = req.get(confUrl, headers=commonHeaders, verify=False)", 
            "execution_count": 5, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "https://wmla-console-wmla.apps.dse-perf.cpolab.ibm.com/auth/v1/logon
", 
                    "name": "stdout"
                }
            ]
        }, 
        {
            "metadata": {
                "id": "32dd7b79-25d6-4711-b17c-a68e348a7c2f"
            }, 
            "cell_type": "markdown", 
            "source": "### Define the status checking fuction"
        }, 
        {
            "metadata": {
                "id": "af36db350d6146438eedf16cdb01f946"
            }, 
            "cell_type": "code", 
            "source": "import tarfile
import tempfile
import os
import json
import pprint
import pandas as pd
from IPython.display import clear_output

def query_job_status(job_id,refresh_rate=3) :

    execURL = dl_rest_url  +'/execs/'+ job_id['id']
    pp = pprint.PrettyPrinter(indent=2)

    keep_running=True
    res=None
    while(keep_running):
        res = req.get(execURL, headers=commonHeaders, verify=False)
        monitoring = pd.DataFrame(res.json(), index=[0])
        pd.set_option('max_colwidth', 120)
        clear_output()
        print(\"Refreshing every {} seconds\".format(refresh_rate))
        display(monitoring)
        pp.pprint(res.json())
        if(res.json()['state'] not in ['PENDING_CRD_SCHEDULER', 'SUBMITTED','RUNNING']) :
            keep_running=False
        time.sleep(refresh_rate)
    return res", 
            "execution_count": 6, 
            "outputs": [ ]
        }, 
        {
            "metadata": {
                "id": "2dd02856-0eaa-4a02-89c4-028d2c96fd13"
            }, 
            "cell_type": "markdown", 
            "source": "### Define the job submission fuction"
        }, 
        {
            "metadata": {
                "id": "c04969af3a414ba9a7658390822c4f97"
            }, 
            "cell_type": "code", 
            "source": "def submit_job_to_wmla (args, files) :
    starttime = datetime.datetime.now()
    r = requests.post(dl_rest_url+'/execs?args='+args, files=files,
                  headers=commonHeaders, verify=False)
    if not r.ok:
        print('submit job failed: code=%s, %s'%(r.status_code, r.content))
    job_status = query_job_status(r.json(),refresh_rate=5)
    endtime = datetime.datetime.now()
    print(\"\\nTotallly training cost: \", (endtime - starttime).seconds, \" seconds.\")", 
            "execution_count": 14, 
            "outputs": [ ]
        }, 
        {
            "metadata": {
                "id": "113dc391-bb92-45f0-a684-c5dbb761e7d9"
            }, 
            "cell_type": "markdown", 
            "source": "### Define the submittion parameters"
        }, 
        {
            "metadata": {
                "id": "c3e3aa23-34ce-4bd6-aa1c-96d1952a1bf2"
            }, 
            "cell_type": "code", 
            "source": "# specify the model file, conda env, device type and device number
args = '--exec-start tensorflow --cs-datastore-meta type=fs \\
--workerDeviceNum 1 \\
--workerMemory 32G \\
--workerDeviceType cpu \\
--conda-env-name rapids-21.06-new \\
--model-main ' + model_main
print(args)", 
            "execution_count": 15, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType cpu --conda-env-name rapids-21.06-new --model-main xgboost-main.py
", 
                    "name": "stdout"
                }
            ]
        }, 
        {
            "metadata": {
                "id": "7e5ea0c21e2b4c39908849a71a556005"
            }, 
            "cell_type": "code", 
            "source": "files = {'file': open(\"{0}/{1}\".format(model_dir,model_main),'rb')}
submit_job_to_wmla (args, files)", 
            "execution_count": 16, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Refreshing every 5 seconds
", 
                    "name": "stdout"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "         id  \\
0  wmla-858   

                                                                                                                      args  \\
0  --exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType cpu --...   

  submissionId  creator     state     appId           schedulerUrl  \\
0     wmla-858  mluser1  FINISHED  wmla-858  https://wmla-mss:9080   

  modelFileOwnerName  \\
0               wmla   

                                                          workDir  \\
0  /gpfs/myresultfs/mluser1/batchworkdir/wmla-858/_submitted_code   

                     appName            createTime  elastic nameSpace  \\
0  SingleNodeTensorflowTrain  2021-07-27T08:41:21Z    False      wmla   

   numWorker   framework  
0          1  tensorflow  ", 
                        "text/html": "<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border=\"1\" class=\"dataframe\">
  <thead>
    <tr style=\"text-align: right;\">
      <th></th>
      <th>id</th>
      <th>args</th>
      <th>submissionId</th>
      <th>creator</th>
      <th>state</th>
      <th>appId</th>
      <th>schedulerUrl</th>
      <th>modelFileOwnerName</th>
      <th>workDir</th>
      <th>appName</th>
      <th>createTime</th>
      <th>elastic</th>
      <th>nameSpace</th>
      <th>numWorker</th>
      <th>framework</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>wmla-858</td>
      <td>--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType cpu --...</td>
      <td>wmla-858</td>
      <td>mluser1</td>
      <td>FINISHED</td>
      <td>wmla-858</td>
      <td>https://wmla-mss:9080</td>
      <td>wmla</td>
      <td>/gpfs/myresultfs/mluser1/batchworkdir/wmla-858/_submitted_code</td>
      <td>SingleNodeTensorflowTrain</td>
      <td>2021-07-27T08:41:21Z</td>
      <td>False</td>
      <td>wmla</td>
      <td>1</td>
      <td>tensorflow</td>
    </tr>
  </tbody>
</table>
</div>"
                    }, 
                    "metadata": { }
                }, 
                {
                    "output_type": "stream", 
                    "text": "{ 'appId': 'wmla-858',
  'appName': 'SingleNodeTensorflowTrain',
  'args': '--exec-start tensorflow --cs-datastore-meta type=fs '
          '--workerDeviceNum 1 --workerMemory 32G --workerDeviceType cpu '
          '--conda-env-name rapids-21.06-new --model-main xgboost-main.py ',
  'createTime': '2021-07-27T08:41:21Z',
  'creator': 'mluser1',
  'elastic': False,
  'framework': 'tensorflow',
  'id': 'wmla-858',
  'modelFileOwnerName': 'wmla',
  'nameSpace': 'wmla',
  'numWorker': 1,
  'schedulerUrl': 'https://wmla-mss:9080',
  'state': 'FINISHED',
  'submissionId': 'wmla-858',
  'workDir': '/gpfs/myresultfs/mluser1/batchworkdir/wmla-858/_submitted_code'}

Totallly training cost:  2840  seconds.
", 
                    "name": "stdout"
                }
            ]
        }, 
        {
            "metadata": {
                "id": "6bbd43d9-c684-435c-bc22-969e61774bf4"
            }, 
            "cell_type": "markdown", 
            "source": "<a id = \"xgboost-gpu\"></a>
## Step 3 :  Training the Xgboost model on GPU with Watson Machine Learning Accelerator
### Define the submittion parameters using conda env with GPU version XGBoost"
        }, 
        {
            "metadata": {
                "id": "b80d40d9b455473d88a7ef3739ef4b26"
            }, 
            "cell_type": "code", 
            "source": "# specify the conda env of xgboost and worker device type
args = '--exec-start tensorflow --cs-datastore-meta type=fs \\
--workerDeviceNum 1 \\
--workerMemory 32G \\
--workerDeviceType gpu \\
--conda-env-name dlipy3  \\
--model-main ' + model_main
print(args)", 
            "execution_count": 29, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType gpu --conda-env-name dlipy3  --model-main xgboost-main.py
", 
                    "name": "stdout"
                }
            ]
        }, 
        {
            "metadata": {
                "id": "9624643563f94c8a89f7426c75e4e508"
            }, 
            "cell_type": "code", 
            "source": "files = {'file': open(\"{0}/{1}\".format(model_dir,model_main),'rb')}
submit_job_to_wmla (args, files)", 
            "execution_count": 30, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Refreshing every 5 seconds
", 
                    "name": "stdout"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "         id  \\
0  wmla-860   

                                                                                                                      args  \\
0  --exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType gpu --...   

  submissionId  creator     state     appId           schedulerUrl  \\
0     wmla-860  mluser1  FINISHED  wmla-860  https://wmla-mss:9080   

  modelFileOwnerName  \\
0               wmla   

                                                          workDir  \\
0  /gpfs/myresultfs/mluser1/batchworkdir/wmla-860/_submitted_code   

                     appName            createTime  elastic nameSpace  \\
0  SingleNodeTensorflowTrain  2021-07-27T09:47:24Z    False      wmla   

   numWorker   framework  
0          1  tensorflow  ", 
                        "text/html": "<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border=\"1\" class=\"dataframe\">
  <thead>
    <tr style=\"text-align: right;\">
      <th></th>
      <th>id</th>
      <th>args</th>
      <th>submissionId</th>
      <th>creator</th>
      <th>state</th>
      <th>appId</th>
      <th>schedulerUrl</th>
      <th>modelFileOwnerName</th>
      <th>workDir</th>
      <th>appName</th>
      <th>createTime</th>
      <th>elastic</th>
      <th>nameSpace</th>
      <th>numWorker</th>
      <th>framework</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>wmla-860</td>
      <td>--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType gpu --...</td>
      <td>wmla-860</td>
      <td>mluser1</td>
      <td>FINISHED</td>
      <td>wmla-860</td>
      <td>https://wmla-mss:9080</td>
      <td>wmla</td>
      <td>/gpfs/myresultfs/mluser1/batchworkdir/wmla-860/_submitted_code</td>
      <td>SingleNodeTensorflowTrain</td>
      <td>2021-07-27T09:47:24Z</td>
      <td>False</td>
      <td>wmla</td>
      <td>1</td>
      <td>tensorflow</td>
    </tr>
  </tbody>
</table>
</div>"
                    }, 
                    "metadata": { }
                }, 
                {
                    "output_type": "stream", 
                    "text": "{ 'appId': 'wmla-860',
  'appName': 'SingleNodeTensorflowTrain',
  'args': '--exec-start tensorflow --cs-datastore-meta type=fs '
          '--workerDeviceNum 1 --workerMemory 32G --workerDeviceType gpu '
          '--conda-env-name dlipy3  --model-main xgboost-main.py ',
  'createTime': '2021-07-27T09:47:24Z',
  'creator': 'mluser1',
  'elastic': False,
  'framework': 'tensorflow',
  'id': 'wmla-860',
  'modelFileOwnerName': 'wmla',
  'nameSpace': 'wmla',
  'numWorker': 1,
  'schedulerUrl': 'https://wmla-mss:9080',
  'state': 'FINISHED',
  'submissionId': 'wmla-860',
  'workDir': '/gpfs/myresultfs/mluser1/batchworkdir/wmla-860/_submitted_code'}

Totallly training cost:  62  seconds.
", 
                    "name": "stdout"
                }
            ]
        }, 
        {
            "metadata": {
                "id": "ce60c5cd-0b6f-4e1f-9289-6c3bed269e0c"
            }, 
            "cell_type": "markdown", 
            "source": "<a id = \"snapml-model\"></a>
## Step 4 :  Setup Snap Boosting model using snapML
### Create a Snap Boosting model based on snapML "
        }, 
        {
            "metadata": {
                "id": "5085334eb3ea416c8bbfb628de2d9e3f"
            }, 
            "cell_type": "code", 
            "source": "model_main='snapboost-'+model_base_name", 
            "execution_count": 31, 
            "outputs": [ ]
        }, 
        {
            "metadata": {
                "id": "28afe9b5f1334c8e8baa26ae07a27e37"
            }, 
            "cell_type": "code", 
            "source": "%%writefile {model_dir}/{model_main}

import os, datetime
import numpy as np
import pandas as pd
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, accuracy_score
from snapml import BoostingMachineClassifier as SnapBoostingMachineClassifier

os.environ['KMP_DUPLICATE_LIB_OK']='True'

# Define Parameters for a large regression
n_samples = 2**13 
n_features = 899 
n_info = 600 
data_type = np.float32

# Generate Data using scikit-learn
X,y = make_classification(n_samples=n_samples,
                          n_features=n_features,
                          n_informative=n_info,
                          random_state=123, n_classes=2)

X = pd.DataFrame(X.astype(data_type))
y = pd.Series(y.astype(np.int32))

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size = 0.2,
                                                    random_state=0)

print(\"Number of examples: %d\" % (X_train.shape[0]))
print(\"Number of features: %d\" % (X_train.shape[1]))
print(\"Number of classes:  %d\" % (len(np.unique(y_train))))

snap_model = SnapBoostingMachineClassifier(random_state=42, 
                                    n_jobs=1,
                                    hist_nbins=256,
                                    num_round=20)  # same interations number with xgboost

# setup model and train
start = datetime.datetime.now()
snap_model.fit(X_train.values, y_train.values)  #.train(param, D_train, steps)
end = datetime.datetime.now()
print (\"Xgboost train timecost: %.2gs\" % ((end-start).total_seconds()))

# predict
start = datetime.datetime.now()
preds = snap_model.predict(X_test.values)
end = datetime.datetime.now()
print (\"Xgboost predict timecost: %.2gs\" % ((end-start).total_seconds()))

# check result
best_preds = np.asarray([np.argmax(line) for line in preds])
print(\"Precision = {}\".format(precision_score(y_test, best_preds, average='macro')))
print(\"Recall = {}\".format(recall_score(y_test, best_preds, average='macro')))
print(\"Accuracy = {}\".format(accuracy_score(y_test, best_preds)))

# save the xgboost model into a file
import pickle
filename = './snapboost_model.pkl'
pickle.dump(snap_model, open(filename, 'wb'))              
print(\"Snapboost model saved successfully.\")", 
            "execution_count": 39, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Overwriting /project_data/data_asset/models/snapboost-gpu-main.py
", 
                    "name": "stdout"
                }
            ]
        }, 
        {
            "metadata": {
                "id": "6a68124b-55d5-4f04-8a7e-cdae0c6ee5a2"
            }, 
            "cell_type": "markdown", 
            "source": "<a id = \"snapml-cpu\"></a>
## Step 5 :  Training the SnapML model on CPU with Watson Machine Learning Accelerator
### Re-define the submission parameters"
        }, 
        {
            "metadata": {
                "id": "bd9fa3aafcab483789c59a94d991bd18"
            }, 
            "cell_type": "code", 
            "source": "# specify the model file, conda env, device type and device number
args = '--exec-start tensorflow --cs-datastore-meta type=fs \\
--workerDeviceNum 1 \\
--workerMemory 32G \\
--workerDeviceType cpu \\
--conda-env-name snapml-177rc \\
--model-main ' + model_main
print(args)", 
            "execution_count": 40, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType cpu --conda-env-name snapml-177rc --model-main snapboost-gpu-main.py
", 
                    "name": "stdout"
                }
            ]
        }, 
        {
            "metadata": {
                "id": "74798908fbb04804a484e4f4a8cf7f7c"
            }, 
            "cell_type": "code", 
            "source": "files = {'file': open(\"{0}/{1}\".format(model_dir,model_main),'rb')}
submit_job_to_wmla (args, files)", 
            "execution_count": 41, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Refreshing every 5 seconds
", 
                    "name": "stdout"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "         id  \\
0  wmla-863   

                                                                                                                      args  \\
0  --exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType cpu --...   

  submissionId  creator     state     appId           schedulerUrl  \\
0     wmla-863  mluser1  FINISHED  wmla-863  https://wmla-mss:9080   

  modelFileOwnerName  \\
0               wmla   

                                                          workDir  \\
0  /gpfs/myresultfs/mluser1/batchworkdir/wmla-863/_submitted_code   

                     appName            createTime  elastic nameSpace  \\
0  SingleNodeTensorflowTrain  2021-07-27T09:58:06Z    False      wmla   

   numWorker   framework  
0          1  tensorflow  ", 
                        "text/html": "<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border=\"1\" class=\"dataframe\">
  <thead>
    <tr style=\"text-align: right;\">
      <th></th>
      <th>id</th>
      <th>args</th>
      <th>submissionId</th>
      <th>creator</th>
      <th>state</th>
      <th>appId</th>
      <th>schedulerUrl</th>
      <th>modelFileOwnerName</th>
      <th>workDir</th>
      <th>appName</th>
      <th>createTime</th>
      <th>elastic</th>
      <th>nameSpace</th>
      <th>numWorker</th>
      <th>framework</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>wmla-863</td>
      <td>--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType cpu --...</td>
      <td>wmla-863</td>
      <td>mluser1</td>
      <td>FINISHED</td>
      <td>wmla-863</td>
      <td>https://wmla-mss:9080</td>
      <td>wmla</td>
      <td>/gpfs/myresultfs/mluser1/batchworkdir/wmla-863/_submitted_code</td>
      <td>SingleNodeTensorflowTrain</td>
      <td>2021-07-27T09:58:06Z</td>
      <td>False</td>
      <td>wmla</td>
      <td>1</td>
      <td>tensorflow</td>
    </tr>
  </tbody>
</table>
</div>"
                    }, 
                    "metadata": { }
                }, 
                {
                    "output_type": "stream", 
                    "text": "{ 'appId': 'wmla-863',
  'appName': 'SingleNodeTensorflowTrain',
  'args': '--exec-start tensorflow --cs-datastore-meta type=fs '
          '--workerDeviceNum 1 --workerMemory 32G --workerDeviceType cpu '
          '--conda-env-name snapml-177rc --model-main snapboost-gpu-main.py ',
  'createTime': '2021-07-27T09:58:06Z',
  'creator': 'mluser1',
  'elastic': False,
  'framework': 'tensorflow',
  'id': 'wmla-863',
  'modelFileOwnerName': 'wmla',
  'nameSpace': 'wmla',
  'numWorker': 1,
  'schedulerUrl': 'https://wmla-mss:9080',
  'state': 'FINISHED',
  'submissionId': 'wmla-863',
  'workDir': '/gpfs/myresultfs/mluser1/batchworkdir/wmla-863/_submitted_code'}

Totallly training cost:  61  seconds.
", 
                    "name": "stdout"
                }
            ]
        }, 
        {
            "metadata": {
                "id": "4444f281-ca59-4b4d-85e1-791eae0f5436"
            }, 
            "cell_type": "markdown", 
            "source": "<a id = \"snapml-model-gpu\"></a>
## Step 6 :  Setup SnapBoost model using snapML on GPU
### Create a SnapBoost model based on snapML "
        }, 
        {
            "metadata": {
                "id": "1c95468cf1f647209aa395d05d26519b"
            }, 
            "cell_type": "code", 
            "source": "model_main='snapboost-gpu-'+model_base_name", 
            "execution_count": 35, 
            "outputs": [ ]
        }, 
        {
            "metadata": {
                "id": "a2ef99b080954c04a5fc8630f34998a9"
            }, 
            "cell_type": "code", 
            "source": "%%writefile {model_dir}/{model_main}

import os, datetime
import numpy as np
import pandas as pd
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, accuracy_score
from snapml import BoostingMachineClassifier as SnapBoostingMachineClassifier

os.environ['KMP_DUPLICATE_LIB_OK']='True'

# Define Parameters for a large regression
n_samples = 2**13 
n_features = 899 
n_info = 600 
data_type = np.float32

# Generate Data using scikit-learn
X,y = make_classification(n_samples=n_samples,
                          n_features=n_features,
                          n_informative=n_info,
                          random_state=123, n_classes=2)

X = pd.DataFrame(X.astype(data_type))
y = pd.Series(y.astype(np.int32))

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size = 0.2,
                                                    random_state=0)

print(\"Number of examples: %d\" % (X_train.shape[0]))
print(\"Number of features: %d\" % (X_train.shape[1]))
print(\"Number of classes:  %d\" % (len(np.unique(y_train))))

snap_model = SnapBoostingMachineClassifier(use_gpu=True,   # use gpu
                                    random_state=42, 
                                    n_jobs=1,
                                    hist_nbins=256,
                                    num_round=20)  # same interations number with xgboost

# setup model and train
start = datetime.datetime.now()
snap_model.fit(X_train.values, y_train.values)  #.train(param, D_train, steps)
end = datetime.datetime.now()
print (\"Xgboost train timecost: %.2gs\" % ((end-start).total_seconds()))

# predict
start = datetime.datetime.now()
preds = snap_model.predict(X_test.values)
end = datetime.datetime.now()
print (\"Xgboost predict timecost: %.2gs\" % ((end-start).total_seconds()))

# check result
best_preds = np.asarray([np.argmax(line) for line in preds])
print(\"Precision = {}\".format(precision_score(y_test, best_preds, average='macro')))
print(\"Recall = {}\".format(recall_score(y_test, best_preds, average='macro')))
print(\"Accuracy = {}\".format(accuracy_score(y_test, best_preds)))

# save the xgboost model into a file
import pickle
filename = './snapboost_model.pkl'
pickle.dump(snap_model, open(filename, 'wb'))              
print(\"Snapboost model saved successfully.\")", 
            "execution_count": 36, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Overwriting /project_data/data_asset/models/snapboost-gpu-main.py
", 
                    "name": "stdout"
                }
            ]
        }, 
        {
            "metadata": {
                "id": "d468ab99-da17-47c8-b20e-725734bfefb6"
            }, 
            "cell_type": "markdown", 
            "source": "<a id = \"snapml-gpu\"></a>
## Step 7 :  Training the SnapML model on GPU with Watson Machine Learning Accelerator
### Re-define the submission parameters"
        }, 
        {
            "metadata": {
                "id": "f3ca85d2cbc14984b9edf4f62d7a55b5"
            }, 
            "cell_type": "code", 
            "source": "# specify the model file, conda env, device type and device number
args = '--exec-start tensorflow --cs-datastore-meta type=fs \\
--workerDeviceNum 1 \\
--workerMemory 32G \\
--workerDeviceType gpu \\
--conda-env-name snapml-177rc \\
--model-main ' + model_main
# --msd-env CUDA_FORCE_PTX_JIT=1 \\
print(args)", 
            "execution_count": 37, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType gpu --conda-env-name snapml-177rc --model-main snapboost-gpu-main.py
", 
                    "name": "stdout"
                }
            ]
        }, 
        {
            "metadata": {
                "id": "7d9d8546a7184268900d330e1ac5b87c"
            }, 
            "cell_type": "code", 
            "source": "#files = {'file': open('/project_data/data_asset/models/snapboost-gpu-main.py', 'rb')}
files = {'file': open(\"{0}/{1}\".format(model_dir,model_main),'rb')}
submit_job_to_wmla (args, files)", 
            "execution_count": 38, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Refreshing every 5 seconds
", 
                    "name": "stdout"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "         id  \\
0  wmla-862   

                                                                                                                      args  \\
0  --exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType gpu --...   

  submissionId  creator     state     appId           schedulerUrl  \\
0     wmla-862  mluser1  FINISHED  wmla-862  https://wmla-mss:9080   

  modelFileOwnerName  \\
0               wmla   

                                                          workDir  \\
0  /gpfs/myresultfs/mluser1/batchworkdir/wmla-862/_submitted_code   

                     appName            createTime  elastic nameSpace  \\
0  SingleNodeTensorflowTrain  2021-07-27T09:55:56Z    False      wmla   

   numWorker   framework  
0          1  tensorflow  ", 
                        "text/html": "<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border=\"1\" class=\"dataframe\">
  <thead>
    <tr style=\"text-align: right;\">
      <th></th>
      <th>id</th>
      <th>args</th>
      <th>submissionId</th>
      <th>creator</th>
      <th>state</th>
      <th>appId</th>
      <th>schedulerUrl</th>
      <th>modelFileOwnerName</th>
      <th>workDir</th>
      <th>appName</th>
      <th>createTime</th>
      <th>elastic</th>
      <th>nameSpace</th>
      <th>numWorker</th>
      <th>framework</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>wmla-862</td>
      <td>--exec-start tensorflow --cs-datastore-meta type=fs --workerDeviceNum 1 --workerMemory 32G --workerDeviceType gpu --...</td>
      <td>wmla-862</td>
      <td>mluser1</td>
      <td>FINISHED</td>
      <td>wmla-862</td>
      <td>https://wmla-mss:9080</td>
      <td>wmla</td>
      <td>/gpfs/myresultfs/mluser1/batchworkdir/wmla-862/_submitted_code</td>
      <td>SingleNodeTensorflowTrain</td>
      <td>2021-07-27T09:55:56Z</td>
      <td>False</td>
      <td>wmla</td>
      <td>1</td>
      <td>tensorflow</td>
    </tr>
  </tbody>
</table>
</div>"
                    }, 
                    "metadata": { }
                }, 
                {
                    "output_type": "stream", 
                    "text": "{ 'appId': 'wmla-862',
  'appName': 'SingleNodeTensorflowTrain',
  'args': '--exec-start tensorflow --cs-datastore-meta type=fs '
          '--workerDeviceNum 1 --workerMemory 32G --workerDeviceType gpu '
          '--conda-env-name snapml-177rc --model-main snapboost-gpu-main.py ',
  'createTime': '2021-07-27T09:55:56Z',
  'creator': 'mluser1',
  'elastic': False,
  'framework': 'tensorflow',
  'id': 'wmla-862',
  'modelFileOwnerName': 'wmla',
  'nameSpace': 'wmla',
  'numWorker': 1,
  'schedulerUrl': 'https://wmla-mss:9080',
  'state': 'FINISHED',
  'submissionId': 'wmla-862',
  'workDir': '/gpfs/myresultfs/mluser1/batchworkdir/wmla-862/_submitted_code'}

Totallly training cost:  51  seconds.
", 
                    "name": "stdout"
                }
            ]
        }, 
        {
            "metadata": {
                "id": "625057ff-e88e-4671-b35c-3753677373d8"
            }, 
            "cell_type": "code", 
            "source": "", 
            "execution_count": null, 
            "outputs": [ ]
        }
    ], 
    "metadata": {
        "kernelspec": {
            "name": "python3", 
            "display_name": "Python 3.7", 
            "language": "python"
        }, 
        "language_info": {
            "name": "python", 
            "version": "3.7.10", 
            "mimetype": "text/x-python", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 3
            }, 
            "pygments_lexer": "ipython3", 
            "nbconvert_exporter": "python", 
            "file_extension": ".py"
        }
    }, 
    "nbformat": 4, 
    "nbformat_minor": 5
}