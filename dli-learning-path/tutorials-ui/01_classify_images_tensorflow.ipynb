{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer vision image classification with WMLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Upload this notebook to your environment](#Upload-notebook)\n",
    "- [Download dataset and model](#Download-dataset-model)\n",
    "- [Import dataset](#Import-dataset)\n",
    "- [Build the model](#Build-the-model)\n",
    "- [Tune Hyper-parameter](#Tune-hyper-parameter)\n",
    "- [Run Training](#Run-training)\n",
    "- [Inspect Training Run](#Inspect-training-run)\n",
    "- [Create an inference model](#Create-an-inference-model)\n",
    "- [Test it out](#Test-it-out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "[Back to top](#Contents)\n",
    "\n",
    "This notebook details the process of performing a basic computer vision image classification example using the Deep Learning Impact functionality within Watson Machine Learning Accelerator.  \n",
    "\n",
    "Please visit [Watson Machine Learning Accelerator Learning Path](https://developer.ibm.com/series/learning-path-get-started-with-watson-machine-learning-accelerator/) for further insight of Watson ML Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T17:32:51.153348Z",
     "start_time": "2020-06-24T17:32:51.146896Z"
    }
   },
   "outputs": [],
   "source": [
    "# Project settings \n",
    "def getconfig(cfg_in={}):\n",
    "    cfg = {}\n",
    "    cfg[\"training_path\"] = \"/gpfs/home/s4s004/vanstee/2020-05-wmla/CIFAR-10-images/train\"\n",
    "    cfg[\"testing_path\"]  = \"/gpfs/home/s4s004/vanstee/2020-05-wmla/CIFAR-10-images/test\"   \n",
    "    cfg[\"model_path\"]    = \"/gpfs/home/s4s004/vanstee/2020-05-wmla/dli-1.2.3-tensorflow-samples/tensorflow-1.13.1/cifar10\"\n",
    "    \n",
    "    # overwrite configs if passed\n",
    "    for (k,v) in cfg_in.items() :\n",
    "        nprint(\"Overriding Config {}:{} with {}\".format(k,cfg[k],v))\n",
    "        cfg[k] = v\n",
    "    return cfg\n",
    "\n",
    "cfg = getconfig()\n",
    "# bs = 16   # uncomment this line if you run out of memory even after clicking Kernel->Restart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset and model\n",
    "For this example, we will be using the CIFAR10 dataset and a model that has been implemented for the DLI framework using Tensorflow.  Other models for **object detection** or **nlp** can be found here.\n",
    "\n",
    "[DLI Models](https://us-south.git.cloud.ibm.com/ibmconductor-deep-learning-impact/dli-1.2.3-tensorflow-samples/tree/master/tensorflow-1.13.1)\n",
    "\n",
    "<a id='Download-dataset-model'></a>\n",
    "\n",
    "\n",
    "### Identify dataset location\n",
    "This data has been downloaded for our class lab, but in general for custom tasks you would need to bring your own dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T17:32:56.761921Z",
     "start_time": "2020-06-24T17:32:56.758046Z"
    }
   },
   "outputs": [],
   "source": [
    "print ('training_path: ' + cfg[\"training_path\"])\n",
    "print ('testing_path:' + cfg[\"testing_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model location\n",
    "This model has already been downloaded from the DLI Models hyperlink above and unzipped (see below).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T17:33:01.969704Z",
     "start_time": "2020-06-24T17:33:01.966275Z"
    }
   },
   "outputs": [],
   "source": [
    "print ('model_path: '+ cfg[\"model_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset\n",
    "<a id='Import-dataset'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "**Data Scientist could bring in their dataset and transform data set as common output format in Watson ML Accelerator.  In this scenario raw images are converted into TensorflowRecord format.**\n",
    "\n",
    "1. Lets swtich back to the browse:  https://IP_address:8443/platform\n",
    "2. At the top Left select **Workload** > **Deep Learning**\n",
    "3. Select the **Datasets** tab, and click **New**\n",
    "4. Retrieve dataset training_path and dataset testing_path\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T17:33:13.691912Z",
     "start_time": "2020-06-24T17:33:13.688039Z"
    }
   },
   "outputs": [],
   "source": [
    "print ('training_path: ' + cfg[\"training_path\"])\n",
    "print ('testing_path:' + cfg[\"testing_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Click **Images for Object Classification**. When presented with a dialog box, provide a unique name (lets use \"Cifar10\"!!!) and select the TFRecords for 'Dataset stores images in',  and then set the value of \"Training folder\" and \"Testing folder\" with the folder that contains the images obtained in the previous step (\"**/tmp/CIFAR-10-images/train**\" + \"**/tmp/CIFAR-10-images/train**\").  The other fields are fine to use with the default settings. When you're ready, click Create.\n",
    "\n",
    "<br>\n",
    "\n",
    "![](./shared-images/ImportDataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "<a id='Build-the-model'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "1. Select the Models tab and click **New** > **Add Location**\n",
    "2. Retrieve the model path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T17:33:17.334012Z",
     "start_time": "2020-06-24T17:33:17.198155Z"
    }
   },
   "outputs": [],
   "source": [
    "print ('model_path: '+ cfg[\"model_path\"])\n",
    "print()\n",
    "!ls {cfg[\"model_path\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. When presented with a diaglog box,  enter following attributes and click **Add**:\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/modelcreation3.png)\n",
    "<br>\n",
    "4. Select the **Tensorflow-cifar10-yourname** and click **Next**.\n",
    "\n",
    "5. When presented with a dialog box, ensure that the Training engine is set to singlenode and that the data set points to the one you just created\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/modelcreation1.png)\n",
    "<br>\n",
    "6. Set the following parameters and click **Add**\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/modelcreation2.png)\n",
    "<br>\n",
    "7.  The model is now ready to be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Hyper-parameter\n",
    "\n",
    "**Watson ML Accelerator automates the search for optimal hyperpamater by automating tuning jobs in parallel with four out-of-box search algorithm: Random Search, Bayesian, TPE, Hyperband,  prior to the commencement of the training process.** \n",
    "\n",
    "<a id='Tune-hyper-parameter'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "1. You could search optimal hyperparameter by leveraging automated Hyper-parameter Tuning.\n",
    "1. Back at the **Models** tab, **click** on the model \n",
    "1. Navigate from the **Overview panel** to the **Hyperparameter Tuning** panel\n",
    "1. Click **New**\n",
    "1. When presented with a dialog box, enter following value and click **Start Tuning**\n",
    "<br> Note : for learning rate vary it from 0.0001 to 0.01\n",
    "\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/modeltune1.png)\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/modeltune5.png)\n",
    "1. Under the **Hyperparameter Tuning** panel, click on the hyperparameter search job \n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/modeltune3.png)\n",
    "1. Navigate from the **Input panel** to the **Progress panel** and **Best panel** to review the optimal set of hyperparameter\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/modeltune4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training\n",
    "\n",
    "<a id='Run-training'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "1. Back at the **Models** tab, select the model you created in previous step and click **Train**\n",
    "1. When presented with a dialog box, keep default parameter and click **Start Training**\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/modeltrain1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Training Run\n",
    "\n",
    "<a id='Inspect-training-run'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "**Spectrum Deep Learning Impact Insight offers Data Scientist the visualization to monitor training metric including loss rate and accuracy as epochs continue to execute.  With this insight Data Scientist could decide to terminate the model training if there is no further gain in accuracy and no further drop in loss rate.**\n",
    "\n",
    "1. From the **Train** submenu of the **Models** tab, select the model that is training by clicking the link.\n",
    "1. Navigate from the **Overview panel** to the **Training** panel, and click the most recent link. You can watch as the results roll in.\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/modeltrain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an inference model\n",
    "\n",
    "**You are now ready to validate your training result by deploying your trained model as inference service.   \n",
    "You can submit inference request to inference restapi end point**\n",
    "\n",
    "<a id='Create-an-inference-model'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "\n",
    "1. From the Training view, click Create Inference Model.\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/inference1.png)\n",
    "1. This creates a new model in the Models tab. You can view it by going to the Inference submenu.\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/inference2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it out\n",
    "<a id='Test-it-out'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "1. Download [inference test image](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/car.jpg) to your laptop\n",
    "\n",
    "1. Go back to the Models tab, select the new inference model, and click Test. At the new Testing overview screen, select New Test.\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/inference3.png)\n",
    "\n",
    "1.  When presented with a dialog box, click **Choose File** to load the inference test image.  Click **Start Test**\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/inference4.png)\n",
    "\n",
    "1. Wait for the test state to change from RUNNING to FINISHED.  Click the link to view the results of the test.\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/inference5.png)\n",
    "\n",
    "1. As you can see, the images are available as a thumbnail preview along with their classified label and probability.\n",
    "\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/image-classification-with-WMLA-UI/Shared-images/inference6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is version 1.0 and its content is copyright of IBM.   All rights reserved.   \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
