{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using WMLA Elastic Distributed Training via API - a sample notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "\n",
    "### Contents\n",
    "\n",
    "- [The big picture](#The-big-picture)\n",
    "- [Changes to your code](#Changes-to-your-code)\n",
    "- [Making dataset available](#Making-dataset-available)\n",
    "- [Set up API end point and log on](#Set-up-API-end-point-and-log-on)\n",
    "- [Submit job via API](#Submit-job-via-API)\n",
    "- [Monitor running job](#Monitor-running-job)\n",
    "- [Retrieve output and saved models](#Retrieve-output-and-saved-models)\n",
    "  - [Output - Retrieve training output](#Output:--Retrieve-Training-Metric)\n",
    "  - [Save Models](#Save-Model)\n",
    "- [Debugging any issues](#Debugging-any-issues)\n",
    "- [Further information and useful links](#Further-information-and-useful-links)\n",
    "- [Appendix](#Appendix)\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Final things to do:\n",
    "- add link to Learning Journey blog in sections: \"The big picture\" and \"Changes to your code\"\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The big picture\n",
    "[Back to top](#Contents)\n",
    "\n",
    "This notebook details the process of taking your existing model training code and making the changes required to run the code using [IBM Watson Machine Learning](https://developer.ibm.com/linuxonpower/deep-learning-powerai/powerai-enterprise/) (WMLA) using Elastic Distributed Training. \n",
    "\n",
    "<span style='color:deeppink'>**TODO:** Link to Learning Journey Blog</span>\n",
    "\n",
    "The image below shows the various elements required to use EDT. In this notebook we will step through each of these elements in more detail. Through this process you will offload your code to a WMLA cluster, monitor the running job, retrieve the output and debug any issues seen. A [static version](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/shared-images/5_running_job.png) is also available.\n",
    "\n",
    "![overall](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/shared-images/5_running_job.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes to your code\n",
    "[Back to top](#Contents)\n",
    "\n",
    "In this section we will take existing sample code and make the relevant changes required for use with EDT. An overview of these changes can be seen in the diagram below. A [static version](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/shared-images/2_code_adaptations.png) is also available.\n",
    "\n",
    "![code](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/shared-images/2_code_adaptations.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key changes to your code in order to use EDT are the following:\n",
    "- Importing libraries and setting up environment variables\n",
    "- Data loading function for EDT\n",
    "- Extract parameters for training\n",
    "- Replace training and testing loops with EDT equivalents\n",
    "\n",
    "For the purpose of this tutorial we have adapted the following RestNet18 model for use with EDT: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "Please see the blog associated with this notebook with more detailed explanation of the above changes.\n",
    "\n",
    "<span style='color:deeppink'>**TODO:** Add link to Learning Journey blog in line above</span>\n",
    "\n",
    "You can find the original code `pytorch_mnist.py` and the updated code `pytorch_mnist_EDT.py` in the zip file `pytorch_edt.tar.gz` contained in the [tutorial repository](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/elastic-distributed-training-module/pytorch_edt.tar.gz).\n",
    "\n",
    "You can run the following command to observe relative changes:\n",
    "`diff -U4 pytorch_mnist.py pytorch_mnist_EDT.py`\n",
    "\n",
    "Your modified code should be made available in a directory which also contains the EDT helper scripts: `edtcallback.py`, `emetrics.py` and `elog.py`. Sample versions can be found in the tarball in the tutorial repository; additionally they can be downloaded from http://ibm.biz/WMLA-samples.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making dataset available\n",
    "[Back to top](#Contents)\n",
    "\n",
    "Next we will make our dataset available to the WMLA cluster as seen in the diagram below. \n",
    "\n",
    "![data](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/shared-images/3_dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ask your system admin the path of $DLI_DATA_FS directory\n",
    "\n",
    "2. ssh to WMLA-server and get access to $DLI_DATA_FS\n",
    "\n",
    "\n",
    "\n",
    "3. Download dataset\n",
    "\n",
    "```\n",
    "[WMLA-server dlidata]# wget https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/elastic-distributed-training-module/pytorch-mnist-dataset.zip\n",
    "--2020-05-12 22:27:07--  https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/elastic-distributed-training-module/pytorch-mnist-dataset.zip\n",
    "Resolving github.com (github.com)... 140.82.114.3\n",
    "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
    "HTTP request sent, awaiting response... 302 Found\n",
    "Location: https://raw.githubusercontent.com/IBM/wmla-assets/master/WMLA-learning-journey/elastic-distributed-training-module/pytorch-mnist-dataset.zip [following]\n",
    "--2020-05-12 22:27:07--  https://raw.githubusercontent.com/IBM/wmla-assets/master/WMLA-learning-journey/elastic-distributed-training-module/pytorch-mnist-dataset.zip\n",
    "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.36.133\n",
    "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.36.133|:443... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: 23006288 (22M) [application/zip]\n",
    "Saving to: ‘pytorch-mnist-dataset.zip’\n",
    "\n",
    "100%[=============================================================================================================================================>] 23,006,288  67.4MB/s   in 0.3s\n",
    "\n",
    "2020-05-12 22:27:08 (67.4 MB/s) - ‘pytorch-mnist-dataset.zip’ saved [23006288/23006288]\n",
    "\n",
    "[WMLA-server dlidata]# unzip pytorch-mnist-dataset.zip\n",
    "\n",
    "```\n",
    "\n",
    "4. Unzip the zip file and modify file owner/group, that is equivalent to Instance Group Execution User (in this case it is egoadmin)\n",
    "```\n",
    "[WMLA-server dlidata]# chown -R egoadmin:egoadmin pytorch-mnist/\n",
    "[WMLA-server hymenopteradata]# pwd\n",
    "/dlidata/pytorch-mnist\n",
    "[WMLA-server hymenopteradata]# ls -lt\n",
    "total 0\n",
    "drwxr-x--- 4 egoadmin egoadmin 34 Jan  7 23:54 MNIST\n",
    "\n",
    "```\n",
    "\n",
    "5. Take note of the path name of this dataset, note that your path will likely be different that seen here.\n",
    "```\n",
    "/dlidata/pytorch-mnist\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up API end point and log on\n",
    "[Back to top](#Contents)\n",
    "\n",
    "In this section we set up the API endpoint which will be used in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Source the environment\n",
    "\n",
    "$EGO_TOP is the installation directory.  The default value is /opt/ibm/spectrumcomputing\n",
    "\n",
    "```\n",
    ". $EGO_TOP/profile.platform\n",
    "\n",
    "```\n",
    "2. Login\n",
    "\n",
    "```\n",
    "egosh user logon -u <wmla_user>\n",
    "Logged on successfully\n",
    "\n",
    "```\n",
    "\n",
    "3. Retrieve Conductor Rest API Port\n",
    "\n",
    "```\n",
    "egosh client view |grep -A 3 ASCD_REST_BASE_URL_1\n",
    "CLIENT NAME: ASCD_REST_BASE_URL_1\n",
    "DESCRIPTION: http://<WMLA-server>:8280/platform/rest/\n",
    "\n",
    "```\n",
    "\n",
    "4.  Retrieve DLI (Deep Learning Impact) Rest API Port\n",
    "\n",
    "```\n",
    "egosh client view |grep -A 3 DLPD_REST_BASE_URL_1\n",
    "CLIENT NAME: DLPD_REST_BASE_URL_1\n",
    "DESCRIPTION: http://<WMLA-server>:9280/platform/rest/\n",
    "\n",
    "```\n",
    "\n",
    "5.  Note that the port numbers in your URL will depend on whether SSL has been enabled or not\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job via API\n",
    "[Back to top](#Contents)\n",
    "\n",
    "Now we need to structure our API job submission. There are various elements to this process as seen in the diagram below. Note that **this** jupyter notebook is the one referred to below. A [static version](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/shared-images/4_api_setup.png) is also available.\n",
    "\n",
    "![code](https://github.com/IBM/wmla-assets/raw/master/WMLA-learning-journey/shared-images/4_api_setup.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sections use the Watson ML Accelerator API to complete the various tasks required. \n",
    "We've given examples of a number of tasks but you should refer to the documentation at to see more details \n",
    "of what is possible and sample output you might expect.\n",
    "\n",
    "- https://www.ibm.com/support/knowledgecenter/SSFHA8_1.2.1/cm/deeplearning.html\n",
    "- https://www.ibm.com/support/knowledgecenter/SSZU2E_2.4.0/reference_s/api_references.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "# from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "# plt.rcParams['figure.figsize'] = [24, 8.0]\n",
    "#import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('max_colwidth', 300)\n",
    "\n",
    "import tarfile\n",
    "import tempfile\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://haswell01.eng.platformlab.ibm.com:8643/platform/rest/conductor/v1\n",
      "https://haswell01.eng.platformlab.ibm.com:55557/platform/rest/deeplearning/v1\n"
     ]
    }
   ],
   "source": [
    "# Environment details:\n",
    "\n",
    "model_path = '/Users/kelvinlui/Github/wmla-assets/dli-learning-path/datasets/pytorch-mnist-edt-model'\n",
    "\n",
    "protocol = 'https'\n",
    "\n",
    "#master_host = 'colonia05.platform'\n",
    "master_host = 'haswell01.eng.platformlab.ibm.com'\n",
    "\n",
    "dli_rest_port = '55557'\n",
    "sc_rest_port = '8643'\n",
    "\n",
    "\n",
    "sc_rest_url =  protocol+'://'+master_host+':'+sc_rest_port+'/platform/rest/conductor/v1'\n",
    "dl_rest_url = protocol+'://'+master_host+':'+dli_rest_port+'/platform/rest/deeplearning/v1'\n",
    "\n",
    "print (sc_rest_url)\n",
    "print (dl_rest_url)\n",
    "# User login details\n",
    "\n",
    "wmla_user = 'Admin'\n",
    "wmla_pwd = 'Admin'\n",
    "\n",
    "\n",
    "myauth = (wmla_user, wmla_pwd)\n",
    "\n",
    "# Spark instance group details\n",
    "#sig_name = '**** ADD HERE ****'\n",
    "#sigName = 'ClaimsDamageDetection-IG'\n",
    "sigName = 'EDT-IG'\n",
    "\n",
    "# REST call variables\n",
    "headers = {'Accept': 'application/json'}\n",
    "\n",
    "\n",
    "#startTuneUrl='%s://%s:%s/platform/rest/deeplearning/v1/hypersearch' % (protocol, master_host, dli_rest_port)\n",
    "#sc_rest_url ='%s://%s:%d/platform/rest/conductor/v1' % (protocol, hostname, conductorport)\n",
    "\n",
    "req = requests.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_dir = f'./resnet-wmla' \n",
    "model_main = f'elastic-main.py'\n",
    "model_callback = f'edtcallback.py'\n",
    "model_elog = f'elog.py'\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./resnet-wmla/elastic-main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {model_dir}/{model_main}\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from callbacks import Callback\n",
    "from fabric_model import FabricModel\n",
    "import os\n",
    "\n",
    "\n",
    "def get_max_worker():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='EDT Example')\n",
    "    parser.add_argument('--numWorker', type=int, default='16', help='input the max number ')\n",
    "    parser.add_argument('--gpuPerWorker', type=int, default='1', help='input the path of initial weight file')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    num_worker = args.numWorker * args.gpuPerWorker\n",
    "    return num_worker\n",
    "\n",
    "BATCH_SIZE_PER_DEVICE = 64\n",
    "NUM_EPOCHS = 20\n",
    "MAX_NUM_WORKERS = get_max_worker()\n",
    "\n",
    "START_LEARNING_RATE = 0.4\n",
    "LR_STEP_SIZE = 30\n",
    "LR_GAMMA = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "print(\"DATA_DIR: \" + os.getenv(\"DATA_DIR\"))\n",
    "DATA_DIR = os.getenv(\"DATA_DIR\")\n",
    "TRAIN_DATA = DATA_DIR + \"/cifar10\"\n",
    "TEST_DATA = DATA_DIR + \"/cifar10\"\n",
    "\n",
    "class LRScheduleCallback(Callback):\n",
    "    def __init__(self, step_size, gamma):\n",
    "        super(LRScheduleCallback, self).__init__()\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def on_epoch_begin(self, epoch):\n",
    "        if (epoch != 0) and (epoch % self.step_size == 0):\n",
    "            for param_group in self.params['optimizer'].param_groups:\n",
    "                param_group['lr'] *= self.gamma\n",
    "\n",
    "        print(\"LRScheduleCallback epoch={}, learning_rate={}\".format(epoch,\n",
    "              self.params['optimizer'].param_groups[0]['lr']))\n",
    "\n",
    "def getDatasets():\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    return (torchvision.datasets.CIFAR10(root=TRAIN_DATA, train=True, download=True, transform=transform_train),\n",
    "            torchvision.datasets.CIFAR10(root=TEST_DATA, train=False, download=True, transform=transform_test))\n",
    "\n",
    "def main(model_type):\n",
    "    print('==> Building model..' + str(model_type))\n",
    "    model = models.__dict__[model_type]()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=START_LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "    edt_m = FabricModel(model, getDatasets, F.cross_entropy, optimizer, user_callback=[LRScheduleCallback(LR_STEP_SIZE, LR_GAMMA)])\n",
    "    print('==> epochs:' + str(NUM_EPOCHS) + ', batchsize:' + str(BATCH_SIZE_PER_DEVICE) + ', engines_number:' + str(MAX_NUM_WORKERS))\n",
    "    edt_m.train(NUM_EPOCHS, BATCH_SIZE_PER_DEVICE, MAX_NUM_WORKERS, num_dataloader_threads=4, validation_freq=10, checkpoint_freq=0)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(\"resnet50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./resnet-wmla/edtcallback.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {model_dir}/{model_callback}\n",
    "#! /usr/bin/env python\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from callbacks import LoggerCallback\n",
    "from emetrics import EMetrics\n",
    "from elog import ELog\n",
    "\n",
    "class EDTLoggerCallback(LoggerCallback):\n",
    "    def __init__(self):\n",
    "        self.gs =0\n",
    "\n",
    "    def log_train_metrics(self, loss, acc, completed_batch,  worker=0):\n",
    "        acc = acc/100.0\n",
    "        self.gs += 1\n",
    "        with EMetrics.open() as em:\n",
    "            em.record(EMetrics.TEST_GROUP,completed_batch,{'loss': loss, 'accuracy': acc})\n",
    "        with ELog.open() as log:\n",
    "            log.recordTrain(\"Train\", completed_batch, self.gs, loss, acc, worker)\n",
    "\n",
    "    def log_test_metrics(self, loss, acc, completed_batch, worker=0):\n",
    "        acc = acc/100.0\n",
    "        with ELog.open() as log:\n",
    "            log.recordTest(\"Test\", loss, acc, worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./resnet-wmla/elog.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {model_dir}/{model_elog}\n",
    "import time\n",
    "import os\n",
    "\n",
    "class ELog(object):\n",
    "\n",
    "    def __init__(self,subId,f):\n",
    "        if \"TRAINING_ID\" in os.environ:\n",
    "            self.trainingId = os.environ[\"TRAINING_ID\"]\n",
    "        elif \"DLI_EXECID\" in os.environ:\n",
    "            self.trainingId = os.environ[\"DLI_EXECID\"]\n",
    "        else:\n",
    "            self.trainingId = \"\"\n",
    "        self.subId = subId\n",
    "        self.f = f\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, tb):\n",
    "        self.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def open(subId=None):\n",
    "        if \"LOG_DIR\" in os.environ:\n",
    "            folder = os.environ[\"LOG_DIR\"]\n",
    "        elif \"JOB_STATE_DIR\" in os.environ:\n",
    "            folder = os.path.join(os.environ[\"JOB_STATE_DIR\"],\"logs\")\n",
    "        else:\n",
    "            folder = \"/tmp\"\n",
    "\n",
    "        if subId is not None:\n",
    "            folder = os.path.join(folder, subId)\n",
    "\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "        f = open(os.path.join(folder, \"stdout\"), \"a\")\n",
    "        return ELog(subId,f)\n",
    "\n",
    "    def recordText(self,text):\n",
    "        timestr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        timestr = \"[\"+ timestr + \"]\"\n",
    "        if self.f:\n",
    "            self.f.write(timestr + \" \" + text + \"\\n\")\n",
    "            self.f.flush()\n",
    "\n",
    "    def recordTrain(self,title,iteration,global_steps,loss,accuracy,worker):\n",
    "        text = title\n",
    "        text = text + \",\tTimestamp: \" + str(int(round(time.time() * 1000)))\n",
    "        text = text + \",\tGlobal steps: \" + str(global_steps)\n",
    "        text = text + \",\tIteration: \" + str(iteration)\n",
    "        text = text + \",\tLoss: \" + str(float('%.5f' % loss) )\n",
    "        text = text + \",\tAccuracy: \" + str(float('%.5f' % accuracy) )\n",
    "        self.recordText(text)\n",
    "\n",
    "    def recordTest(self,title,loss,accuracy,worker):\n",
    "        text = title\n",
    "        text = text + \",\tTimestamp: \" + str(int(round(time.time() * 1000)))\n",
    "        text = text + \",\tLoss: \" + str(float('%.5f' % loss) )\n",
    "        text = text + \",\tAccuracy: \" + str(float('%.5f' % accuracy) )\n",
    "        self.recordText(text)\n",
    "\n",
    "    def close(self):\n",
    "        if self.f:\n",
    "            self.f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kelvinlui/Github/wmla-assets/dli-learning-path/tutorials-notebook\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR_SUFFIX = \".modelDir.tar\"\n",
    "tempFile = tempfile.mktemp(MODEL_DIR_SUFFIX)\n",
    "\n",
    "#DATA_DIR=os.getenv('DATA_DIR')\n",
    "make_tarfile(tempFile, './resnet-wmla')\n",
    "files = {'file': open(tempFile, 'rb')}\n",
    "\n",
    "#sig_name='fakesig'\n",
    "#--msd-task12n-device-type cpu --conda-env-name dlipy36-cpu\n",
    "args = '--exec-start edtPyTorch --cs-datastore-meta type=fs \\\n",
    "                     --numWorker 1 \\\n",
    "                     --model-main elastic-main.py --model-dir resnet-wmla'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package model files for training\n",
    "Package the updated model files into a tar file ending with `.modelDir.tar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/project_data/data_asset/pytorch-resnet/resnet-wmla'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d9e2a45c09ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mMODEL_DIR_SUFFIX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\".modelDir.tar\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtempFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmktemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR_SUFFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmake_tarfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtempFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/project_data/data_asset/pytorch-resnet/resnet-wmla'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" tempFile: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtempFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtempFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-d9e2a45c09ea>\u001b[0m in \u001b[0;36mmake_tarfile\u001b[0;34m(output_filename, source_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_tarfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w:gz\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   1926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;31m# Create a TarInfo object from the file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettarinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mgettarinfo\u001b[0;34m(self, name, arcname, fileobj)\u001b[0m\n\u001b[1;32m   1805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lstat\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdereference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                 \u001b[0mstatres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                 \u001b[0mstatres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/project_data/data_asset/pytorch-resnet/resnet-wmla'"
     ]
    }
   ],
   "source": [
    "def make_tarfile(output_filename, source_dir):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        tar.add(source_dir, arcname=os.path.basename(source_dir))\n",
    "\n",
    "\n",
    "MODEL_DIR_SUFFIX = \".modelDir.tar\"\n",
    "tempFile = tempfile.mktemp(MODEL_DIR_SUFFIX)\n",
    "make_tarfile(tempFile, '/project_data/data_asset/pytorch-resnet/resnet-wmla')\n",
    "print(\" tempFile: \" + tempFile)\n",
    "files = {'file': open(tempFile, 'rb')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log on\n",
    "\n",
    "\n",
    "Obtain login session tokens to be used for session authentication within the RESTful API. Tokens are valid for 8 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logon succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelvinlui/opt/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(sc_rest_url+'/auth/logon', verify=False, auth=myauth, headers=headers) \n",
    "\n",
    "if r.ok:\n",
    "    print ('\\nLogon succeeded')\n",
    "    \n",
    "else: \n",
    "    print('\\nLogon failed with code={}, {}'. format(r.status_code, r.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check DL Frameworks details\n",
    "\n",
    "Check what framework plugins are available and see example execution commands.  In this demonstration we will use **edtPyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"name\": \"disttensorflow\",\n",
      "        \"description\": \"\",\n",
      "        \"desc\": [\n",
      "            \"Distributed TensorFlow\",\n",
      "            \"Instead of passing parameters such as ps_hosts, worker_hosts, specify --numPs\",\n",
      "            \"as in example below. Parameter servers (ps) and worker hosts will be allocated\",\n",
      "            \"dynamically.\",\n",
      "            \"Use --gpuPerWorker flag to specify number of GPUs per worker.\",\n",
      "            \"The maximum number of worker is 2.\",\n",
      "            \"The maximum number of GPUs per worker is 2.\",\n",
      "            \"Examples:\",\n",
      "            \"$ python dlicmd.py --exec-start disttensorflow <connection-options> --ig <ig> --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py --numPs 1 --numWorker 1 --gpuPerWorker 1\",\n",
      "            \"$ python dlicmd.py --exec-start disttensorflow <connection-options> --ig <ig> --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py --numPs 1 --numWorker 2 --gpuPerWorker 1\"\n",
      "        ],\n",
      "        \"distributeStrategy\": \"MultiWorkerMirroredStrategy\",\n",
      "        \"numPs\": 1,\n",
      "        \"frameworkVersion\": \"2.1\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"disttensorflow_v1\",\n",
      "        \"description\": \"\",\n",
      "        \"desc\": [\n",
      "            \"Distributed TensorFlow\",\n",
      "            \"Instead of passing parameters such as ps_hosts, worker_hosts, specify --numPs\",\n",
      "            \"as in example below. Parameter servers (ps) and worker hosts will be allocated\",\n",
      "            \"dynamically.\",\n",
      "            \"Use --gpuPerWorker flag to specify number of GPUs per worker.\",\n",
      "            \"The maximum number of worker is 2.\",\n",
      "            \"The maximum number of GPUs per worker is 2.\",\n",
      "            \"Examples:\",\n",
      "            \"$ python dlicmd.py --exec-start disttensorflow_v1 <connection-options> --ig <ig> --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py --numPs 1 --numWorker 1 --gpuPerWorker 1\",\n",
      "            \"$ python dlicmd.py --exec-start disttensorflow_v1 <connection-options> --ig <ig> --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py --numPs 1 --numWorker 2 --gpuPerWorker 1\"\n",
      "        ],\n",
      "        \"distributeStrategy\": \"ParameterServerStrategy\",\n",
      "        \"numPs\": 1,\n",
      "        \"frameworkVersion\": \"1.15\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"edtTensorflow\",\n",
      "        \"description\": \"\",\n",
      "        \"desc\": [\n",
      "            \"Tensorflow - IBM Elastic Distributed Training (EDT)\",\n",
      "            \"Examples:\",\n",
      "            \"$ python dlicmd.py --exec-start edtTensorflow <connection-options> --ig <ig> --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\"\n",
      "        ],\n",
      "        \"frameworkVersion\": \"2.1\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"PyTorch\",\n",
      "        \"description\": \"\",\n",
      "        \"desc\": [\n",
      "            \"PyTorch\",\n",
      "            \"Examples:\",\n",
      "            \"$ python dlicmd.py --exec-start PyTorch <connection-options> --ig <ig> --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\"\n",
      "        ],\n",
      "        \"frameworkVersion\": \"1.3.1\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"PowerAICaffeIBM\",\n",
      "        \"description\": \"\",\n",
      "        \"desc\": [\n",
      "            \"IBM PowerAI IBM Caffe\",\n",
      "            \"NOTES:\",\n",
      "            \"-You must specify --model-dir flag to point to a directory containing both solver\",\n",
      "            \" and network files, and in the solver file, the path for the network file must not be \",\n",
      "            \" a full path.\",\n",
      "            \"-Other paths such as snapshot, data source, in solver and network files must be\",\n",
      "            \" on a shared file system.\",\n",
      "            \"-Caffe's --gpu option will be overriden with 'all' since DLI allocates \",\n",
      "            \" and manages GPUs. Use --gpuPerWorker option as shown below to request for number of GPUs.\",\n",
      "            \" Currently max gpuPerWorker is set to 2.\",\n",
      "            \"Examples:\",\n",
      "            \"$ python dlicmd.py --exec-start PowerAICaffeIBM <connection-options> --ig <ig> --cs-datastore-meta type=fs,data_path=mnist --model-dir <model-dir> --model-main lenet_solver.prototxt train\",\n",
      "            \"$ python dlicmd.py --exec-start PowerAICaffeIBM <connection-options> --ig <ig> --cs-datastore-meta type=fs,data_path=mnist --gpuPerWorker 2 --model-dir <model-dir> --model-main lenet_solver.prototxt train\"\n",
      "        ],\n",
      "        \"frameworkVersion\": \"1.0.0\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"tensorflow\",\n",
      "        \"description\": \"\",\n",
      "        \"desc\": [\n",
      "            \"Single-node TensorFlow\",\n",
      "            \"NOTES:\",\n",
      "            \"- Since DLI manages GPU allocation, if you explicitly assign devices using\",\n",
      "            \"  calls such as `tf.device`, you should use Tensorflow configuration flag\",\n",
      "            \"  `allow_soft_placement=True`\",\n",
      "            \"Examples:\",\n",
      "            \"$ python dlicmd.py --exec-start tensorflow <connection-options> --ig <ig> --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\"\n",
      "        ],\n",
      "        \"frameworkVersion\": \"2.1\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"edtKeras\",\n",
      "        \"description\": \"\",\n",
      "        \"desc\": [\n",
      "            \"Keras - IBM Elastic Distributed Training (EDT) for WML CE 1.6.1\",\n",
      "            \"Examples:\",\n",
      "            \"$ python dlicmd.py --exec-start edtKeras <connection-options> --ig <ig> --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\"\n",
      "        ],\n",
      "        \"frameworkVersion\": \"2.2.5\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"tensorflow_v1\",\n",
      "        \"description\": \"\",\n",
      "        \"desc\": [\n",
      "            \"Single-node TensorFlow. Tested for Tensorflow 1.15.0.\",\n",
      "            \"NOTES:\",\n",
      "            \"- Since DLI manages GPU allocation, if you explicitly assign devices using\",\n",
      "            \"  calls such as `tf.device`, you should use Tensorflow configuration flag\",\n",
      "            \"  `allow_soft_placement=True`\",\n",
      "            \"Examples:\",\n",
      "            \"$ python dlicmd.py --exec-start tensorflow1100 <connection-options> --ig <ig> --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\"\n",
      "        ],\n",
      "        \"frameworkVersion\": \"1.15\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"edtPyTorch\",\n",
      "        \"description\": \"\",\n",
      "        \"desc\": [\n",
      "            \"PyTorch - IBM Elastic Distributed Training (EDT)\",\n",
      "            \"Examples:\",\n",
      "            \"$ python dlicmd.py --exec-start edtPyTorch <connection-options> --ig <ig> --cs-datastore-meta type=fs,data_path=mnist --model-main mnist.py\"\n",
      "        ],\n",
      "        \"frameworkVersion\": \"1.3.1\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"keras\",\n",
      "        \"description\": \"\",\n",
      "        \"desc\": [\n",
      "            \"Keras\",\n",
      "            \"Examples:\",\n",
      "            \"$ python dlicmd.py --exec-start keras <connection-options> --ig <ig> --cs-datastore-meta type=fs,data_path=mnist --model-main keras_mnist_cnn.py\"\n",
      "        ],\n",
      "        \"frameworkVersion\": \"2.3.1\"\n",
      "    }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelvinlui/opt/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(dl_rest_url+'/execs/frameworks', auth=myauth, headers=headers, verify=False).json()\n",
    "# Using the raw json, easier to see the examples given\n",
    "print(json.dumps(r, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments for API call\n",
    "Equivalent of flags used if running command directly on WMLA CLI, including:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: --exec-start edtPyTorch         --cs-datastore-meta type=fs,data_path=pytorch-mnist         --model-dir resnet-wmla         --edt-options maxWorkers=4         --model-main elastic-main.py         --epochs 5          \n"
     ]
    }
   ],
   "source": [
    "framework_name = 'edtPyTorch' # DL Framework to use, from list given above\n",
    "dataset_location = 'pytorch-mnist' # relative path of your data set under $DLI_DATA_FS\n",
    "local_dir_containing_your_code = 'resnet-wmla'\n",
    "number_of_GPU = '4' # number of GPUs for elastic distribution\n",
    "name_of_your_code_file = 'elastic-main.py' # Main model file as opened locally above\n",
    "\n",
    "\n",
    "args = '--exec-start {} \\\n",
    "        --cs-datastore-meta type=fs,data_path={} \\\n",
    "        --model-dir {} \\\n",
    "        --edt-options maxWorkers={} \\\n",
    "        --model-main {} \\\n",
    "        --epochs 5  \\\n",
    "        '.format(framework_name, dataset_location, local_dir_containing_your_code, number_of_GPU, name_of_your_code_file)\n",
    "\n",
    "print (\"args: \" + args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelvinlui/opt/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model submission failed with code=400, b'Error 400: Instance group name dli-edt not found.\\n'\n"
     ]
    }
   ],
   "source": [
    "r = requests.post(dl_rest_url+'/execs?sigName='+sigName+'&args='+args, files=files,\n",
    "                  auth=myauth, headers=headers, verify=False)\n",
    "\n",
    "if r.ok:\n",
    "    exec_id = r.json()['id']\n",
    "    sig_id = r.json()['sigId']\n",
    "    driver_id = r.json()['submissionId']\n",
    "    print ('\\nModel submitted successfully \\Driver ID: {}'.format(driver_id))\n",
    "    print ('Exec ID: {}'.format(exec_id))\n",
    "    print ('SIG ID: {}'.format(sig_id))\n",
    "else: \n",
    "    print('\\nModel submission failed with code={}, {}'. format(r.status_code, r.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor running job\n",
    "[Back to top](#Contents)\n",
    "\n",
    "Once the job is submitted successfully we can monitor the running job. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status of all RUNNING jobs in SIG (rerun cell to refresh)\n",
    "\n",
    "monitor = []\n",
    "monitor_output = []\n",
    "\n",
    "r = requests.get(sc_rest_url+'/instances/'+sig_id+'/applications?state=RUNNING', \n",
    "                auth=myauth, headers=headers, verify=False).json()\n",
    "\n",
    "\n",
    "       \n",
    "if (len(r) == 0):\n",
    "    print ('No jobs running')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Filter out the relevant information\n",
    "    monitor.append([(\n",
    "        job['driver']['id'],\n",
    "        job['driver']['state'],\n",
    "        job['apprunduration'],\n",
    "        job['gpuslots'],\n",
    "        job['gpumemused']['total'],\n",
    "        job['gpudevutil']['total'],\n",
    "    ) for job in r])\n",
    "\n",
    "    monitor_output = pd.DataFrame([item for monitor in monitor for item in monitor])\n",
    "    monitor_output.columns = [\n",
    "        'Driver ID', \n",
    "        'State', \n",
    "        'Run duration (mins)',\n",
    "        'GPU slots',\n",
    "        'Total GPU memory used',\n",
    "        'Total GPU utilsation (%) ',\n",
    "    ]\n",
    "    \n",
    "    for job in r:\n",
    "        executors = job['executors']\n",
    "        \n",
    "\n",
    "monitor_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve output and saved models\n",
    "[Back to top](#Contents)\n",
    "\n",
    "After the job completes then we can retrieve the output, logs and saved models. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output:  Retrieve Training Metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(dl_rest_url+'/execs/'+exec_id+'/log', auth=myauth, headers=headers, verify=False).json()\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "cols = ['timestamp','global_steps','iteration','loss','accuracy']\n",
    "final_data = pd.read_csv(StringIO(r.replace(':',',')), \n",
    "                 usecols=[4,6,8,10,12], \n",
    "                 names=cols)\n",
    "final_data['timestamp2'] = final_data.timestamp.apply(pd.to_datetime, unit='ms')\n",
    "final_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "# plt.rcParams['figure.figsize'] = [24, 8.0]\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize = (15,10))\n",
    "\n",
    "\n",
    "sns.lineplot(final_data.timestamp2,final_data.global_steps, color=\"g\", ax=axes[0,0])\n",
    "axes[0,0].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "axes[0,0].set_xlabel(\"Time\")\n",
    "\n",
    "sns.lineplot(final_data.global_steps,final_data.loss, color=\"r\", ax=axes[0,1])\n",
    "sns.lineplot(final_data.global_steps,final_data.accuracy, color=\"b\", ax=axes[1,0])\n",
    "\n",
    "axes[1,1].axes.get_xaxis().set_visible(False)\n",
    "axes[1,1].axes.get_yaxis().set_visible(False)\n",
    "axes[1,1].text(0.05, 0.8, 'ID: '+exec_id, size=14)\n",
    "axes[1,1].text(0.05, 0.65, 'SIG: '+sig_name, size=14)\n",
    "#axes[1,1].text(0.05, 0.55, 'Status: '+status, size=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model from training job - downloads zip file (with progress bar) of saved model to directory local to this notebook\n",
    "# (note that you need to save model in your code using the environment variable for location)\n",
    "\n",
    "import requests, zipfile, io\n",
    "#from tqdm.notebook import tqdm\n",
    "import tqdm\n",
    "\n",
    "\n",
    "r = requests.get(dl_rest_url+'/execs/'+'exec_id'+'/result', auth=myauth, stream=True)\n",
    "\n",
    "total_size = int(r.headers.get('Content-Disposition').split('size=')[1])\n",
    "block_size = 1024 #1 Kibibyte\n",
    "t=tqdm(total=total_size, unit='iB', unit_scale=True)\n",
    "\n",
    "with open('model.zip', 'wb') as f:\n",
    "    for data in r.iter_content(block_size):\n",
    "        t.update(len(data))\n",
    "        f.write(data)\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging any issues\n",
    "[Back to top](#Contents)\n",
    "\n",
    "In the case where you have issues during the process detailed above, there are a number of detailed logs that you can view to understand what is happening on the WMLA cluster.\n",
    "\n",
    "WMLA leverages Spark architecture for distributing Deep Learning/Machine Learning jobs.  In Spark,  when an item of processing has to be done, there is a “driver” process that is in charge of taking the user’s code and converting it into a set of multiple tasks. There are also “executor” processes, each operating on a separate node in the cluster, that are in charge of running the tasks, as delegated by the driver.\n",
    "\n",
    "You can monitor Deep Learning/Machine Learning application activity,  performance and resource usage in Driver Log & Executor Log.\n",
    "- Driver Log captures issues related to dependencies and environment variable,  for example,  missing dataset or invalid execution parameter flags.\n",
    "- Executor Log records Deep Learning/Machine Learning training process. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Training Driver Stdout Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "retrieve_stdout_url =  dl_rest_url + '/execs/'+exec_id+'/log?logType=' + 'outlog'\n",
    "print (\"retrieve_stdout_url: \" + str(retrieve_stdout_url))\n",
    "res = requests.get(retrieve_stdout_url, auth=('dse_user', 'cpd4ever'), headers={'Accept': 'application/json'}, verify=False)\n",
    "\n",
    "pp.pprint(res.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_stderr_url =  dl_rest_url + '/execs/'+exec_id+'/log?logType=' + 'errlog'\n",
    "print (\"retrieve_stderr_url: \" + str(retrieve_stderr_url))\n",
    "res = requests.get(retrieve_stderr_url, auth=myauth, headers={'Accept': 'application/octet-stream'}, verify=False)\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "print(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Spectrum Conductor logs for training run - shows various information including environment variables\n",
    "\n",
    "r = requests.get(sc_rest_url+'/instances/'+sig_id+'/applications/'+driver_id+'/logs/stdout/download',\n",
    "                 auth=myauth, headers={'Accept': 'application/octet-stream'}, verify=False)\n",
    "\n",
    "print(r.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output from the training can be found in the `$DLI_WORK_DIR` referenced in this log, in the directory *under* `batchworkdir`. The structure of the files contained in this directory (which you will access via the API) are the following.\n",
    "\n",
    "```\n",
    "$ tree -h\n",
    ".\n",
    "├── [   6]  checkpoint\n",
    "├── [ 247]  log\n",
    "│   ├── [   6]  0-97eb84d4-6e4b-4bb7-95e0-fc7bfda461dc.<wmla_server>\n",
    "│   ├── [   6]  1-a111dd6d-c406-48f2-89ce-1ef526d5b34b.<wmla_server>\n",
    "│   └── [  50]  driver-20200227104231-0007-3655c5b5-5d81-43ac-a8c6-c243635f60df.<wmla_server>\n",
    "│       ├── [ 19K]  evaluation-metrics.txt\n",
    "│       └── [7.1K]  stdout\n",
    "├── [  19]  model\n",
    "│   └── [ 214]  train\n",
    "│       ├── [4.7K]  model_epoch_10_optimizer_state.pth\n",
    "│       ├── [ 43M]  model_epoch_10.pth\n",
    "│       ├── [4.7K]  model_epoch_5_optimizer_state.pth\n",
    "│       ├── [ 43M]  model_epoch_5.pth\n",
    "│       ├── [4.7K]  model_epoch_final_optimizer_state.pth\n",
    "│       └── [ 43M]  model_epoch_final.pth\n",
    "├── [  25]  _submitted_code\n",
    "│   └── [ 133]  pytorch_edt\n",
    "│       ├── [1.6K]  edtcallback.py\n",
    "│       ├── [2.0K]  elog.py\n",
    "│       ├── [4.1K]  emetrics.py\n",
    "│       ├── [  67]  __pycache__\n",
    "│       │   ├── [2.0K]  edtcallback.cpython-36.pyc\n",
    "│       │   └── [2.4K]  elog.cpython-36.pyc\n",
    "│       ├── [3.1K]  pytorch_mnist_EDT.py\n",
    "│       └── [4.4K]  pytorch_mnist.py\n",
    "└── [2.5K]  val_dict_list.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Training Driver Stderr Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows various information including environment variables\n",
    "import pprint\n",
    "r = requests.get(sc_rest_url+'/instances/'+sig_id+'/applications/'+driver_id+'/logs/stderr/download',\n",
    "                 auth=myauth, headers={'Accept': 'application/octet-stream'}, verify=False)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Training Executor Log\n",
    "#### Retrieve Executor ID\n",
    "- The deep learning training log per GPU is written in executor log\n",
    "- Execute following code to retrieve list of executor ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in executors:    \n",
    "    print ('executors: ' + key['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Executor Stdout log\n",
    "- set the parameter executor_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor_id = '0-ee39e183-f4af-4b72-9bd2-89e09cbef18d'\n",
    "\n",
    "r = requests.get(sc_rest_url+'/instances/'+sig_id+'/applications/'+driver_id +'/'+executor_id+'/logs/stdout/download',\n",
    "                 auth=myauth, headers={'Accept': 'application/octet-stream'}, verify=False)\n",
    "\n",
    "print(r.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Executor Stderr log\n",
    "- set the parameter executor_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor_id = '0-ee39e183-f4af-4b72-9bd2-89e09cbef18d'\n",
    "\n",
    "r = requests.get(sc_rest_url+'/instances/'+sig_id+'/applications/'+driver_id +'/'+executor_id+'/logs/stderr/download',\n",
    "                 auth=myauth, headers={'Accept': 'application/octet-stream'}, verify=False)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further information and useful links\n",
    "[Back to top](#Contents)\n",
    "\n",
    "**WMLA Introductory videos:**\n",
    "- WMLA overview video (6 mins): http://ibm.biz/WMLA-video\n",
    "- WMLA getting started (3 mins): http://ibm.biz/WMLA-start\n",
    "- Overview of adapting your code for Elastic Distributed Training via API: [video](https://youtu.be/RnZtYNX6meM) | [PDF](docs/wmla_api_pieces.pdf) (screenshot below)\n",
    "\n",
    "**Further WMLA information & documentation**\n",
    "- [Power Developer Portal (WMLCE frameworks information)](https://developer.ibm.com/linuxonpower/deep-learning-powerai/releases/)\n",
    "- WMLA tutorials: http://ibm.biz/WMLA-blog\n",
    "- Knowledge Centre links:\n",
    "  - [IBM Watson Machine Learning Accelerator](https://www.ibm.com/support/knowledgecenter/SSFHA8)\n",
    "  - [IBM Spectrum Conductor](https://www.ibm.com/support/knowledgecenter/en/SSZU2E/product_welcome_conductorspark.html)\n",
    "  - [IBM Spectrum Conductor Deep Learning Impact](https://www.ibm.com/support/knowledgecenter/SSWQ2D)\n",
    "\n",
    "**Further Power Systems information**\n",
    "- [AI on Power Systems Redbook (PDF)](https://www.redbooks.ibm.com/redbooks/pdfs/sg248435.pdf) (deep dive technical information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "[Back to top](#Contents)\n",
    "\n",
    "#### This notebook requires Watson ML Accelerator 1.2.1 + Interim Fix 527174 & 536919 to run.\n",
    "For details please refer to following link:\n",
    "https://www.ibm.com/support/knowledgecenter/en/SSFHA8_1.2.1/wmla_fix_pack.html\n",
    "\n",
    "#### This is version 1.0 and its content is copyright of IBM.   All rights reserved.   \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
